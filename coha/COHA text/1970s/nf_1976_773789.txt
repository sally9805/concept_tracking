@@773789

txt // paired . He therefore concluded that the sequential pattern of speech was a significant aspect of emotional expression ; but subsequent research has by and large failed to follow this lead in defining the particular sequences of vocal cues that are associated with the communication of various meanings . If the sequence of cues is an important component of speech that carries emotional meaning , the next step in research would seem to be specification of the vocal characteristics that are involved in this sequential pattern . Two studies suggest that the rate , pitch , and timing of pauses in a vocal utterance are consistently related to the meanings expressed . Fairbanks and Hoaglin ( 1941 ) reported that the expression of feelings such as anger , grief , and contempt may be differentiated in terms of rate , ratio of pause time to phonation time , and aspects of pitch such as range and the rate of range . For example , anger tends to be expressed at a relatively fast rate ; grief at a high ratio of pause time to phonation time @ @ @ @ @ @ @ @ @ @ findings notwithstanding , feelings can apparently be communicated accurately even when the range and specificity of the vocal stimulus is markedly reduced . Knower ( 1941 ) , for example , found that even when speakers whispered ( which eliminates . the fundamental frequency of the normal voice ) , the accuracy of listeners in identifying emotions was four times that to be expected by chance . Pollack et al . ( 1960 ) also reported that the emotional meanings expressed by samples of whispered speech , played under increasing ratios of noise to signal , were identified at above chance levels of accuracy . Perhaps even more striking , they found that speech samples as short as 60 milliseconds could communicate emotion . Thus , regardless of the technique used , all studies so far reported agree that adults can communicate emotional meaning accurately by vocal expression . The research to date also offers a few limited clues about the vocal characEXPRESSIVE // teristics of emotional expression , but these clues have not been consistently helpful in identifying the speech correlates of particular emotional states . Dimitrovsky ( 1962 ) @ @ @ @ @ @ @ @ @ @ vocal communication of emotion during childhood . Her subjects were children aged from five to twelve . They were asked to identify vocal expressions of four categories of emotion : love , happiness , sadness , and anger . The subjects heard tapes and were then asked to point to one of four stick-figure drawings which represented the above four categories . The subjects were , in addition , given a test of verbal intelligence . Dimitrovsky found that the children 's ability to identify correctly the emotional meaning of vocal expression increased with age , as was to be expected . Yet there was no marked , consistent difference in the pattern of correct and incorrect responses made by the subjects at the various age levels from five to twelve . In addition , she found that " children at all age levels favored the emotions with negative valence , giving the responses sad ' and angry ' more , than the responses happy ' and loving ' . " From this she concluded that " the tendency to respond in terms of negative emotional meaning appears to be peculiarly @ @ @ @ @ @ @ @ @ @ conclusions on the grounds that negative emotions are perhaps simply easier to identify , given the experimenter 's statement that " expressions of sadness were most frequently identified . " This was followed in frequency by the identification of expressions of anger . It seems , then , that rather than favoring emotions with negative content , the children perhaps only found them easier to identify . One wishes that Dimitrovsky had followed this study by a similar experiment with adults , to determine whether they , too , identified the negative emotions more frequently . Data of this kind would permit some evaluation of her statement that the tendency to re102 LANGUAGE IN BEHAVIOR spond in terms of negative emotional meaning is peculiarly characteristic of children . A number of studies have used electronic filtering techniques that decrease the verbal content of the utterances without destroying the emotional communication provided by the vocal characteristics of speech . Among these studies is one by Kramer ( 1963 ) . Paragraphs were read and taped by American actors , who tried to portray five different emotions . Japanese actors also tried to @ @ @ @ @ @ @ @ @ @ of the emotions presented in normal recordings of the test passage in English , recordings in filtered English , and recordings in Japanese . Kramer concludes that : ... the over-all percentage of correct matches was approximately the same for normal filtered recordings of portrayals by the American actors . The previous literature has assumed that the only difference in judgment between normal and filtered speech was due to the absence of words in the latter . Present study shows that this is not true ; knowledge of how a person judges normal speech permits no prediction of how he will judge filtered speech . Kramer also found that the judges were able to match emotions correctly with those that were portrayed in Japanese , though not all emotions were as easy for Americans to recognize in Japanese . This study not only shows the type of thing that can be done with electronic equipment , it also indicates the interest that has been shown in cross-cultural studies in this area . Adams ( 1964 ) , for example , made a cross-cultural study of expressive communication in an Egyptian village @ @ @ @ @ @ @ @ @ @ other emotional attitudes were conveyed by subtle qualities of tone , pitch , and melody . Content had little to do with expressive communication , since content was often rote . In addition , Adams discovered that the " presentational meanings " in one culture differ greatly in another . For example , the // speech melody and rhythm that connote " sincerity " in Egypt usually seem to an American to sound " cross " or " belligerent . " SENSITIVITY TO VOCAL EXPRESSIONS OF EMOTION Research focused on the factors that determine the accuracy of recognition of vocal expressions of emotion is rather limited . There are , nonetheless , a few studies that suggest some possible correlates of sensitivity to vocal expression . Gates ( 1927 ) noted that the age and intelligence of children were both positively correlated with their accuracy in identifying the emotional expression of one speaker . Dimitrovsky ( 1962 ) found that girls were more accurate than boys in judging vocal expression of feeling . This raises the question of whether there are differences between the sexes in the ability to perceive and @ @ @ @ @ @ @ @ @ @ significant differences between the sexes in either ability . Her original hypothesis was that women show greater accuracy in these judgments than men , yet this contention was not supported by the experimental evidence . Dusenberry and Knower ( 1939 ) found that the women in their sample were superior to the men in the accuracy of their judgments , but the difference was not statistically significant . Pfaff ( 1954 ) reported a statistically significant difference in college women , who showed greater accuracy than an equivalent sample of men . Fay and Middleton ( 1940 ) , on the other hand , failed to find reliable differences in sensitivity between men and women . Thus the studies concerned with differences between the sexes in the ability to recognize vocal expressions of emotion present , on the whole , a confusing and contradictory picture . // Beldoch ( 1961 ) conducted research on the possible interrelations between various modes of emotional communication . He raised the question of whether there is a general factor of sensitivity to emotional expression , or whether people may be sensitive to one mode of @ @ @ @ @ @ @ @ @ @ Although he reported finding significant correlations between the abilities to identify the expression of emotion in three different media ( music , abstract art , and tape-recorded recitations ) , he concluded that the abilities are independent of each other in many ways . Levitt ( 1962 ) also discounted the possibility that the identification of emotional meaning in various expressive modes could be explained in terms of some general factor . In his examination of the comparative communicative efficiency of vocal , facial , and combined vocal-facial modes , he determined that feelings were communicated more effectively by the facial than by the vocal mode . RESEARCH BY DAVITZ In a study by Davitz ( 1964 ) , an attempt was made to identify the perceptual and cognitive processes likely to be involved in recognition of the emotional meaning of a vocal expression . To begin with the vocal expression itself : it seems obvious that emotional meaning must be conveyed by auditory cues in vocal expressions . Therefore , it was assumed that in order to understand the meanings expressed , the listener must first be able to discriminate @ @ @ @ @ @ @ @ @ @ vocal cues of expression might be necessary for understanding , but it did not seem a sufficient basis on which to identify the meanings expressed . In one pattern or another , the nonverbal characteristics of speech , // tone , timbre , inflection , and so on combine to represent symbolically a specific emotional meaning , and though the exact patterns of cues associated with various meanings can not be defined with great precision , it is obvious that these patterns of interrelated vocal characteristics are complex symbolic stimuli . Therefore , to respond appropriately to these stimuli , to " understand " and identify the meanings expressed by these complex , nonverbal symbols , a listener must presumably have the cognitive ability to deal with abstract symbols , to perceive and meaningfully organize the numerous subtle , nonverbal characteristics that comprise a vocal symbol with emotional meaning . Having perceived and somehow organized the vocal stimulus in his mind ; a listener is required to interpret its emotional meaning . Although there is no explicit , standardized dictionary that defines emotions in terms of their vocal cues , reliable @ @ @ @ @ @ @ @ @ @ , on the listener 's part , of the more or less conventional vocal cues of emotional meaning . Since the subjects of these tests were required to name or label the feeling expressed , and to name it involved some sort of verbal ability , it was reasoned that verbal ability would probably be associated with the ability to identify emotional meanings . The subjects were 61 graduate students , and the following variables were measured for each subject : ( 1 ) ability to make auditory discriminations , ( 2 ) abstract symbolic ability , ( 3 ) knowledge of the vocal characteristics of emotional expression , ( 4 ) verbal intelligence , and ( 5 ) ability to identify vocal expressions of emotional meaning . Under auditory discrimination , the following four dimensions were tested : ( 1 ) pitch , ( 2 ) loudness , ( 3 ) time , and ( 4 ) timbre . The subjects ' ability to identify vocal expressions of emotional meaning was measured by means of a 45-item tape-recording , which contained expressions of 8 different // emotional meanings plus 5 @ @ @ @ @ @ @ @ @ @ speakers expressed each of the following emotional meanings : affection , anger , boredom , cheerfulness , impatience , joy , sadness , and satisfaction ( see Table 5-3 ) . The study of perceptual and cognitive correlates yielded positive results . Each of the four variables ( pitch , loudness , time , and timbre ) was found to be positively related to a measure of ability to identify vocal expressions of emotional meaning , and a multiple correlation of 0.60 was obtained between a combination of all four variables and the measure of emotional sensibility . The results of this study support the view that emotional sensitivity can be conceptualized in terms of complex stimuli , intervening perceptual and symbolic processes , and subsequent verbal responses . In another study , Davitz ( 1964 ) investigated some of the auditory cues associated with vocal expressions of emotional meaning . To explore this problem , two sets of variables were selected : one was concerned with dimensions of emotional meaning , the other with auditory characteristics of speech . The variables involved in emotional meaning were based on the research @ @ @ @ @ @ @ @ @ @ , which yielded three aspects of emotional meaning : valence , strength , and activity . The speech variables used included loudness , pitch , timbre , and speed . The study considered the relation between each of the three variables of emotional meaning and each of the four speech variables . Four female and three male speakers each expressed 14 different feelings in standard-content speech . In terms of content , the same 2 sentences were embedded in 14 different paragraphs , each paragraph designed to express one of the 14 emotions . The speakers read each paragraph designed to express a particular feeling , plus an unemotional paragraph . These readings were tape-recorded and // the two standard sentences embedded in each paragraph were spliced , so as to provide a recording of different emotional expressions with standard content . The 14 feelings expressed were : admiration , affection , amusement , anger , boredom , cheerfulness , despair , disgust , dislike , fear , impatience , joy , satisfaction , and surprise . The recordings of all 7 speakers were judged by 20 persons , who were @ @ @ @ @ @ @ @ @ @ the feeling expressed , using the unemotional reading of each speaker as a base . A final tape , which consisted of the reading of those feelings identified most frequently for male speakers and for female speakers , plus the unemotional reading by each of these speakers , was played to a second set of 20 judges , who were asked to rate each expression on four 7-point scales : ( 1 ) loudness ( loud to soft ) ; ( 2 ) pitch ( high to low ) ; ( 3 ) timbre ( blaring to resonant ) ; ( 4 ) rate of speech ( fast to slow ) . In these ratings , the unemotional recordings of the speakers were also used as a base line . The recordings were rated on 9 scales of the Semantic Differential by a third set of 20 judges . Each of the three dimensions was represented by three scales : valence by ( 1 ) good to bad ; ( 2 ) pleasant to unpleasant ; ( 3 ) beautiful to ugly ; strength by ( 1 ) strong to weak @ @ @ @ @ @ @ @ @ @ ) heavy to light ; and activity by ( 1 ) fast to slow ; ( 2 ) active to passive ; ( 3 ) sharp to dull . The data were analyzed by correlating each of the dimensions of emotional meaning with each of the vocal characteristics of speech . The correlation of activity with each auditory variable was statistically significant . These data , plus those collected in another study by Davitz ( on erroneous judgments of vocal expressions of feeling ) , support the generalization that loudness , pitch , timbre , and rate of speech are a function of the subjective rating of the activity level of the emotion communicated . Valence and strength are presumably communicated by other , perhaps more subtle and complex , auditory cues. // CONCLUDING OBSERVATIONS In the studies we have reviewed , the form and content of emotional expressions have been treated separately . That is , either the studies have involved vocal expressions with standardized content , and hence have controlled the information conveyed by the verbal aspects of the message , or the content has been analyzed only with @ @ @ @ @ @ @ @ @ @ in normal con-versation meanings are communicated both vocally and verbally , an important problem for further research is the interaction of these components of speech in the determi-nation of meaning . 6 Sound Symbolism in Language Wolfgang Kohler ( 1947 ) credits the German poet Morgenstern with the observation that " All seagulls look as though their names were Emma " ( Die Mowen sehen alle aus , als ob sie Emma hiessen ) . The name flows as smoothly as the bird , but we hear the name and see the bird . Evidently we are somehow able to enjoy some part of the same subjective experience through different sensory modalities . The point can be made even more clearly if we ask subjects to match Kohler 's ( 1947 ) nonsense words maluma and takete to the shapes given in Figure 6.1 ( Kohler , 1947 , p. 225 ) . Again , nearly everyone reveals in his match a feeling that the smoothly convoluted figure best fits the sound series that is uninterrupted by stoppages in the flow of breath . In speaking of language , the term @ @ @ @ @ @ @ @ @ @ obtains between a sound sequence or word and its referent . That is , the object that this word describes may be represented by 113 // virtually any sound sequence , so long as the parties in com-munication understand that the connection exists . We say " book , " but the Japanese say lion , the French livre , and so on . The type of symbolism we are discussing now is what Sapir ( 1929 ) called " a more fundamental , a psychologically primary sort of symbolism ; " this he defined as expressive symbolism . This kind of symbolism certainly operates within specific languages , and possibly even universally . Giving an English example of this phenomenon in which the affective component of meaning exceeds the ref-erential component , Markel ( 1961 ) argued that there is a common affective connotation in many /gl-/ words : glad , glance , glass , gleam , glimpse , glitter , globe , glove , and // glow . In the same vein , but somewhat earlier , Bolinger ( 1950 ) analyzed both the initial sounds and the residues @ @ @ @ @ @ @ @ @ @ glare , and flitter , flow , flare . Thus the /gl/ indicates phenomena of light , /fl/ phenomena of movement , /itr/ intermittent , /ow/ steady , and /r/ intense . Similar examples are to be found in German , where initial /gr-/ seems to indicate the connotation " sinister , eerie " : grasslich , grauen , grausig , Greuel , greulich , gruselig . Needless to say , phonetic , or sound , symbolism is not peculiar to Indo-European languages . Samuel Martin ( 1964 ) suggests that Korean may be the champion , since it has more than a thousand lexemes that do not occur simply as isolated items : each is a whole set of words , with systematic variations in shape that correspond to subtle but structured differences in connotation . And Arabic has extensive , complex networks of connotative relationships , connected by means of the sound symbolism implicit in root radicals . To take but a single illustration , many words that contain ghayn ( no close English approximation of this letter is possible ) as the first radical connote " concealment , @ @ @ @ @ @ @ @ @ @ to set , as the sun ) , ghaara ( to seep into the ground ) , ghabasa ( to become dark ) , ghabana ( to hoodwink , gyp ) , ghataa ( to cover , conceal ) , ghatasa ( to immerse , submerge ) , ghamma ( to cloud over ) , ghilaaf ( covering , book jacket ) , and so on , for many more words . The early nineteenth-century French grammarian Antoine Fabre d'Olivet made a similar study of Hebrew , another Semitic language ( Whorf , 1956 ) . The hazards of this line of inquiry are clear : semantic continuity may be governed only by the imagination of the investigator . Benjamin Lee Whorf , for example , saw " dispersal " in a set of words with Maya roots that included " sand , " " white , " " weave cloth , " " much , " and " dislocate . " This was a bit much , even for the generally sympathetic Sapir ( Carroll , 1956 , p. 24 ) . Whorf ( 1956 ) was on intui116 LANGUAGE @ @ @ @ @ @ @ @ @ @ reason we will pronounce hypothetical new words such as " thog , " " thag , " " thig , " and " thuzzle " with the th value found in " thin " and " threw " is that the voiced value of th occurs initially only in the cryptotype of demonstrative particles such as the , this , that , than , those , and so forth . In order to place intuition under a tighter rein and provide systematic guidance to the study of phonetic symbolism , two kinds of empirical study have been made . They were classed according to their methodologies by Taylor ( 1963 ) : one class is analytical , the other is word-matching . The analytical methodologies vary considerably , but the subject is generally asked to judge sounds of nonsense words along one or more dimensions of connotative meaning ( size , roundness , movement , and so on ) . In the wordmatching methodologies the subject is presented with pairs of words ( usually antonymic ) from two languages , at least one of which is unknown to him . He @ @ @ @ @ @ @ @ @ @ pairs in the two languages ; significantly correct guessing is assumed to indicate that some type of phonetic symbolism is in operation . In a variation of the analytic methodology , subjects are asked to pair words in an artificial language with English stimulus words ( for example , see Johnson , Suzuki , and Olds , 1964 ) . As in the case of experiments that use stimulus materials drawn from natural languages , substantial agreement is interpreted as evidence for the presence of sound symbolism . ANALYTIC STUDIES The first published study of empirical phonetic symbolism was that of Edward Sapir ( 1929 ) , who felt that some phonetic symbolism must be universal rather than language-specific . He had noted , for example , that " teeny " is // smaller than " tiny ; " this corresponds to the different sizes of the oral cavity when the vowels of each are pronounced . Sapir 's analytical experiments tested the symbolic magnitude of different consonants and vowels . In his first experiment , he presented the subjects with pairs of **25;549;TOOLONG ( CVC ) nonsense syllables that differed @ @ @ @ @ @ @ @ @ @ the syllables on a scale of relative magnitude . For example , subjects were told that " mal " and " mil " both meant " table , " and were asked which word designated the larger table . More than 755 of the subjects consistently selected " mal " as larger than " mil , " which again parallels the difference in the size of the oral cavity . In a second experiment , Sapir ( 1929 ) presented 500 subjects with 100 word pairs , each representing a different phonetic contrast . Again he found that " symbolic discriminations run encouragingly parallel to the objective ones based upon phonetic considerations p. 233 . " In his final experiment , he presented the subjects with a nonsense word that had an arbitrary meaning , which was used as a starting point . The word was then systematically varied by a single feature at a time , and the subject was asked to describe the change in meaning that accompanied the change in form . The procedure was too open-ended to yield quantitative results , but sample responses suggested that many @ @ @ @ @ @ @ @ @ @ . Basing his work on Sapir 's data , Newman ( 1933 ) found that grammatical category had no effect on the scaling of eight vowels , and that younger subjects ( aged 9 ? 13 ) showed essentially the same subjective patterns as older subjects ( aged 16 and up ) , but that they discriminated less well and less consistently . He found that the symbolic magnitude judgments were due to three mechanical factors : ( 1 ) the kinesthetic factor of the articulatory position of the tongue ( front-back ) , ( 2 ) the acoustic factor of the character118 LANGUAGE IN BEHAVIOR istic frequency ( high-low ) , and ( 3 ) the kinesthetic factor of the oral cavity size ( small-large ) . In a second , similar experiment , Newman found similarities between a large-small and a dark-bright scale , but whereas the large-small scale was patterned on the three factors used in the first experiment plus vowel quantity , the brightness scale was patterned exclusively on the basis of articulation and frequency . More recently , Davis ( 1961 ) has made a cross-cultural @ @ @ @ @ @ @ @ @ @ the nonsense words uloomu and takete , all modified from Kohler ( 1947 ; cf. Figure 6.1 ) . Both African children who spoke only a Bantu language ( Kitongwe ) and monolingual English-speaking children matched takete to the angular drawing and uloomu to the curved drawing with significantly more than chance frequency . Davis therefore concluded that universal phonetic symbolism provided the proper cues for " correct " matching in both groups . Not all investigators have reached the same conclusions . Bentley and Varon ( 1933 ) , for example , conducted a highly complex set of experiments to test the findings of Sapir and Newman further , and they did not feel that their results supported the notion of phonetic symbolism . More formidable , perhaps , was a series of cross-cultural experiments by Taylor and Taylor ( 1962 ) , the results of which supported the theory of phonetic symbolism within a single language , but cast a considerable shadow over the theory of universal phonetic symbolism . The experimenters first formed CVC nonsense syllables of six consonants and three vowels , to test the effects of @ @ @ @ @ @ @ @ @ @ No significant effects were found . In the second experiment four consonants and vowels were used to form CVC patterns , to test the effects of syllable length , the number of syllables , and the stress position in two-syllable strings . The longer strings were perceived as larger , but stress posiSOUND // tion was not found to have any significant effect on phonetic symbolism . In their final experiment , Taylor and Taylor presented nearly monolingual subjects , each speaking one of four different languages ( English , Korean , Japanese , and Tamil ) , with the same CVC combinations as were used in the second experiment , and asked the subjects to rate the strings on five-point scales along four dimensions ( size , movement , warmth , and pleasantness ) . The experimenters found that phonetic symbolism had significant effects in all languages , but the symbolism was not the same for the different languages . For example , initial t and p were regarded as very small in English but very big in Korean , and initial d was regarded as very big in Japanese @ @ @ @ @ @ @ @ @ @ that the phenomenon of phonetic symbolism does exist in natural languages , but specific examples are not universally understood in the same way . Interpreting these data in a later article , Taylor ( 1963 ) hypothesized that a major variable of phonetic symbolism must be the language habits of the speakers of a given language . These habits force them to associate a specific sound or sound sequence with a generalized meaning . For example , English speakers habitually associate an initial g with bigness , simply because many words that connote bigness in English begin with g . For the same reason , Taylor argued , an initial d is associated with bigness in Japanese ( from debu " fat , " dekkai " huge , " daikibo " on a grand scale , " and so forth ) . Taylor claimed that this hypothesis explained not only why speakers associate certain sounds with certain meanings , but also why the associations differ for speakers of different languages . In a vigorous attack on Taylor 's arguments , Weiss ( 1964a ) maintained that Taylor 's criticisms of earlier @ @ @ @ @ @ @ @ @ @ selective reporting . Further , he stated that the languagehabits theory begs the question of why certain unrelated // words that share a connotation in a given language also share structural components , and it fails to explain why only initial consonants are associated with meanings . As for the Taylors ' application of the theory , he claimed that only those words that supported the theory were given , while those that failed to support it were selectively ignored . Weiss therefore suggested that a theory of phonetic symbolism ought perhaps to rely on sound and semantic hierarchies , rather than using isomorphic relations between single sounds and single meanings . Such a theory , of course , happens to have been proposed by Weiss ( 1963 , 1964a , 1964b , 1966 ) . Weiss developed the theory in part from his investigation of the effects of meaningful versus nonmeaningful referent categories on the phonetic symbolism response . Using a variation of the picture-matching methodology of Davis ( 1961 ) , Weiss ( 1964b ) worked with the dimensions of magnitude , brightness , and angularity by asking groups @ @ @ @ @ @ @ @ @ @ the match of meaningless nonsense-word pairs to nonsense-picture pairs that represented the three dimensions ; ( 2 ) the match of the same nonsense-word pairs with meaningful referent objects , presented verbally ; ( 3 ) the match of nonsenseword pairs of " high meaningfulness " ( established by pretesting ) with the picture pairs ; and ( 4 ) the match of nonsense words of " high meaningfulness " with the referent objects . All of the nonsense words were in the canonical form CVCV ; thus the same phonetic contrasts were employed in each experimental condition . All four groups matched words to pictures or objects at significantly higher than chance frequencies . Moreover , the use of referent objects raised the scores of both high- and low-meaningfulness nonsense words , but it affected the three dimensions differentially . Weiss concluded that the results generally supported his hypothesis that referent meaningfulness aids the matching response . That is , intersubject agreement is // higher when meaningful referents are provided , because they reduce the possible number of bases for judgment . Finally , Vetter and Tennant ( 1967 ) @ @ @ @ @ @ @ @ @ @ response . In a sense they came full circle with the analytical methodology . They subvocally presented 60 subjects with the stimulus words " oho " and " it i , " and asked the subjects to identify the larger referent . The subjects guessed in the expected direction at better than chance frequency . In a second experiment , 40 subjects were presented with pairs of nonsense syllables such as the ones used by Sapir ( 1929 ) . Two experimental conditions , vocal and nonvocal , were used . Again , under both conditions the subjects correctly ranked the /a/ and /i/ elements at highly significant levels . Vetter and Tennant interpreted these results as suggesting that cues derived from the perception of mouth articulations produce responses similar to those produced by cues of phonetic symbolism . Future experiments in phonetic symbolism must therefore impose stricter controls upon the stimuli used , in order to eliminate extraneous variables . WORD-MATCHING STUDIES The word-matching methodology was given its classic form for phonetic symbolism experiments by Tsuru and Fries ( 1933 ) , who presented 36 pairs of Japanese words to 57 @ @ @ @ @ @ @ @ @ @ those of equivalent English pairs . No levels of significance were ascribed to correct guessing , but 69% of the guesses were reported to be correct . In another study in which the wordmatching methodology was used , Brown , Black , and Horowitz ( 1955 ) presented 21 pairs of antonyms of sensory continua to 86 subjects . The pairs were presented au jiovisually in three languages ( Hindi , Czech , and Chinese ) , and the subjects were asked to match an English meaning // to each stimulus word . The experimenters found significantly better than chance guessing for all three languages , but reported that guessing of words was no better for the Indo-European languages than for Chinese . In order to explain this correct guessing , the experimenters accepted the theory of a " physiognomic language , " composed of universal , unlearned intersensory connections ? a sort of universal synesthesia . They postulated that the origin of speech could have been in the arbitrary association of sounds and meanings , but that it then progressed toward phonetic symbolism , so that a given speech form @ @ @ @ @ @ @ @ @ @ et at . ( 1955 ) concluded , perhaps whimsically , that in the evolution of languages , " speech forms have been selected for symbolism and that we are moving toward a golden millennium of physiognomic speech p. 393 . " Using a methodology similar to that of Brown and his associates , Maltzmann , Morisett , and Brooks ( 1956 ) found that English Japanese and English-Croatian pairs were matched well above chance levels , but that Japanese-Croatian pairs were not . For phonetic symbolism to take effect , apparently English words had to be involved , so Maltzmann et at . felt that the ability to match foreign words must be based on a complex sort of learning process , which probably involved mediated generalization . Brackbill and Little ( 1957 ) tried to define the problem more carefully by conducting similar experiments that involved three methods of presentation ( auditory only , visual only , and both auditory and visual ) and two forms of presentation ( one English word in each pair , and both words foreign ) . They found significantly higher than chance matching @ @ @ @ @ @ @ @ @ @ pairs were matched well below chance levels , however . Visual presentation improved guesses for the English-foreign pairs , but not for the foreign-foreign pairs . Obviously universal phonetic symbol'SOUND // ism can not apply to all words of all languages , but the positive findings suggest that there may be interesting possibilities for further research in connection with language typologies . Maltzmann et at . ( 1956 ) , on the basis of a post-hoc inspection of their data , suggested that various stimulus characteristics of the word pairs ( length , spacing , place of articulation , and so forth ) might have influenced intersubject agreement , and two tests yielded a " potency ranking " of the characteristics , in this order : connotation , vowels , length , spacing , and consonants . Brown and Nuttall ( 1959 ) reviewed the procedural differences in the preceding experiments ( by Brown et at. , 1955 , Maltzmann et at. , 1956 , and Brackbill and Little , 1957 ) and tried to evaluate the effects of the differences in procedure by varying the audiovisual presentation of word pairs @ @ @ @ @ @ @ @ @ @ conditions , the number of correct guesses was significantly above the chance level , but the Englishforeign language matches were best . Brown and Nuttall concluded that universal phonetic symbolism is sensitive to the form of presentation , because only the English-foreign condition allows subjects to determine the appropriate semantic contrast . Brown and Nuttall ( 1959 ) then reformulated Brown 's original phonetic symbolism theory into one that requires a referent continuum : Antonyms naming opposite ends of sensible referent continua ( in languages with which the subject is unfamiliar ) contrast with one another on appropriate phonetic dimensions often enough to make possible better than chance matches with the equivalent terms in the subject 's native language . This condition , if it exists , need not be explained by a myth about the origin of speech in physiognomic representation . It is possible that in the history of languages , antonyms evolve toward phonetic contrasts appropriate to this semantic contrast and that pairs so contrasting sound " right " to native speakers and so have a superior prospect for survival . p. 445 // In a direct test @ @ @ @ @ @ @ @ @ @ whether only antonym pairs would work in the English-foreign condition , or whether nonantonym pairs would also work . He presented 394 subjects with English-Hindi and English-Chinese word pairs , some of which were antonyms and some of which were on different semantic dimensions . Weiss reported highly significant levels of correct quessing for all pairs , but found no differences between the experimental conditions ; thus the use of antonym pairs did not increase correct guessing . Moreover , the subjects reported that they had approximately the same degree of difficulty in guessing under both conditions , whereas Brown and Nuttall ( 1959 ) had predicted that the subjects should have more difficulty in guessing nonantonymic pairs ( pairs without marked relation of meaning ) . On the basis of these data , Weiss concluded that the meaning dimension described by Brown and Nuttall ( 1959 ) is unnecessary for accurate guessing , but that a meaningful context ( represented by the English words ) provides a necessary orientation for the subject , directing his attention to the appropriate phonetic elements . That is , the presence of an English @ @ @ @ @ @ @ @ @ @ which the subject must use to find the appropriate meaning of a sound sequence . Weiss concluded that " to the extent that sound-sense relations congruent with the subject 's experiences have found their way into all natural languages , correct guessing is likely to occur p. 1061 . " Weiss ( 1966 ) elaborated upon this statement , on the basis of another experiment in which 318 subjects matched the Japanese equivalent of one of a pair of English stimulus words in 28 word sets . Again , the words were nonantonymic but sensation-related . From his results , which showed significantly correct guessing , Weiss concluded that his previous theory had been supported . He therefore postulated that the following sequence of events is an appropriate process of phonetic symbolism : ( 1 ) experiences // are assimilated as categories , some of which are bipolar ( " large-small " ) and others of which are not ( " hoarse , vibrating " ) ; ( 2 ) many experiences are accompanied by more or less characteristic sets of sounds ; ( 3 ) consistent pairings of the sounds @ @ @ @ @ @ @ @ @ @ above categories ; ( 4 ) conversely , the experiences and categories are hierarchically associated with the sounds ; ( 5 ) when the subject is presented with an unmeaningful sound sequence , he attributes these learned associations to it ; ( 6 ) the sounds associated with categories of meaning are incorporated into words that denote those categories ; ( 7 ) some categories of meaning are shared by different language groups ; and ( 8 ) some sounds associated with those categories are associated universally . Step 6 explains the phenomenon of phonetic symbolism , while steps 7 and 8 explain universal phonetic symbolism . CONCLUSION It is evident that the varied , often conflicting results obtained in studies of sound symbolism are attributable at least in part to differences in experimental design and procedure . Barik ( 1969 ) has pointed out that one major source of the differences in the findings of word-matching studies is the mode of stimulus presentation ( auditory or visual ) . He questions the validity of the assumption that the spelling of a foreign word with which the subject is unfamiliar constitutes @ @ @ @ @ @ @ @ @ @ the word , as in the case of Croatian words such as crn and tvrd ( Maltzmann et al. , 1956 ) . If stimuli are to be presented visually , some method such as the projecting of items on a screen , trial by trial , should be employed . This would prevent the subject from making cross-item comparisons , which is a consistent risk in studies where materials are presented in list or booklet form . // The phenomenon of universal phonetic symbolism has been seriously challenged by the cross-cultural study of Taylor and Taylor ( 1962 ) , although other such studies are needed to substantiate this claim . The existence of lan-guage-specific phonetic symbolisms , however , has received wide empirical support . In view of these conclusions , the next step in the study of phonetic symbolism is the system-atic examination of the patterns of connotative meaning of the sounds in a large sample of natural languages . 7 Biological Bases of Language The locus of all behavior is the organism . It follows , therefore , that an understanding of language behavior presupposes some basic @ @ @ @ @ @ @ @ @ @ organism , which does the behaving . As Lenneberg ( 1967 ) has noted , the study of language entails not only a description of language , not only a sociopsychological or experimental analysis of verbal learning , but an analysis of man as an organic system of interdependent variables . A full investigation of language , according to Lenneberg , " must not only study the organism that speaks but must also study the behavior itself ? language ? much the same way the zoologist who studies the badger must study its physique together with its habits in order to give a complete picture of that animal p. 3 . " Linguistic functioning is a series of complex actions , which involve the integration of the central nervous system with the operation of auditory and vocal articulatory struc-izs // tures . Anatomical and physiological studies of these structures have contributed to our understanding of their functioning ; especially important are such pioneering studies as those of Penfield and his associates ( Penfield , 1965 ; Penfield and jasper , 1954 ; Penfield and Perot , 1963 ; Penfield and Rasmussen @ @ @ @ @ @ @ @ @ @ the localization of speech centers in the brain . Additional evidence of a valuable kind has been gained from clinical studies of organic brain damage that results in aphasia , or of functional speech disorders such as stuttering . Still further contributions are made by physical anthropologists , whose efforts are directed toward the ways in which our biological heritage has shaped the species-specific characteristics of human language . LANGUAGE AND EVOLUTION In Chapters 2 and 3 we touched on the problem of when and how language may have developed . We saw that apes have a rudimentary ability in language which can be brought out under patient human tutelage . Modern apes may be brighter than their precursors some ten million years ago , when the human line seems to have diverged from that of the apes ( Campbell , 1974 ) , but it is still reasonable to seek the origins of language rather early in our evolution , when we were more apelike than we are today . The distinctively human type of adaptation that depends on culture seems to have been launched some five million years ago @ @ @ @ @ @ @ @ @ @ tool-making man-ape with the generic name of Australopithecus . There is a dispute over whether some of the early fossil material actually represents the genus Homo but for our purposes we may follow Campbell ( 1974 ) , Washburn ( Washburn and Moore , 1974 ) and others in considering all of the relevant materials to represent the aus130 LANGUAGE IN BEHAVIOR tralopithecines . That is , the general considerations relative to language are essentially the same no matter how the taxonomic issues are resolved . Brain size , for example , is an important consideration . There is considerable overlapping in the range of the brain sizes of the great apes and Australopithecus , and if we look only at the approximate average brain size it is apparent that the advantage of the ancient man-ape was rather limited . Chimpanzees have a mean brain size of a little less than 400 cc. , orangutans slightly more than 400 cc. , gorillas barely more than 500 cc. , and Australopithecus averages just under 600 cc . ( Campbell , 1974 ) . By comparison , Homo sapiens , or modern man @ @ @ @ @ @ @ @ @ @ form Homo erectus , sported a respectable 950 cc . ( Campbell , 1974 ) . We can not assume a direct correlation between absolute brain size and mental ability ? let alone specifically linguistic ability ? because several animals have larger brains than we do . There is one kind of whale , for example , with a brain of more than 10,000 cc . While we can not usefully gauge the mental ability of such a creature , we have no reason to think it is within the human range , let alone six times as great . And as Washburn and Moore ( 1974 ) note : For all its great bulk , it constitutes only one gram of brain substance for each 8,500 grams of body , while modern man has one gram of brain for each 44 grams of body weight . But neither is the latter measurement an absolute . The capuchin monkey has one gram of brain for each 17.5 grams of body . The noted anthropologist Franz Weidenreich maintained ... that a brain may be judged only by the use made of it @ @ @ @ @ @ @ @ @ @ such use . pp. 173 ? 174 Though neither absolute brain size nor the size of the brain relative to total body weight is a certain index of mental ability , there remains a general correlation . Up to a point , at least , cultural complexity has increased in proBIOLOGICAL // portion to increased brain size . The most obvious limit to the relationship is the fact that our brain size has been about the same for the last 300,000 years or so , while cultural complexity has been increasing at a fantastic rate in historical times , and particularly in the last few generations . More important than brain size as such is the question of brain structure , though the two considerations are related because a great deal of our increased brain size is the result of new structures that have developed ? structures that are critical for the distinctive cultural adaptation of humankind , including our ability in language . But some of the differences between our brains and those of infrahuman species , including those related to language and speech motor functions , involve not only @ @ @ @ @ @ @ @ @ @ Thus the capacity for language can not be assigned to any specific neurological structure . Lenneberg ( 1967 ) suggests that insight into the language function of the brain could be gained more readily through the study of developmental processes and growth than through a study of mass . In Lenneberg 's view language would have a biologically concrete structural basis in the sense that organization within the brain is itself a developmental process that has structural correlates on a molecular level . But even in the more general sense , if we can not say that the presence of certain gross features of the brain is proof positive of language ability , we can still approach the problem negatively . Thus Washburn and Moore ( 1974 ) see no evidence that the australopithecine brain had structures that would permit speech . We may assume that these manapes had vocal , gestural , and postural signals , since the great apes have them ; and we may assume that they were a little brighter , partly because of their very slight advantage in brain size and more importantly because they did @ @ @ @ @ @ @ @ @ @ speculation'on the language capability of our fossil ances132 LANGUAGE IN BEHAVIOR tors depends to a considerable extent on how far we think cultural forms could develop in the absence of language . Washburn and Moore ( 1974 ) are cautious in attributing language ability to the australopithecines , yet they do indicate that certain cultural forms may well have been present . The hunting bands of the australopithecines , they suggest , were too small to survive without intermating with other groups . " After some intermingling , it would be easy for a mother to suggest to her son that he might find a mate in the group from which she herself had come . Ties of custom and kinship would spring up p. 151 . " Of course , in the absence of language , it would not be easy for a mother to suggest anything . But given some intermingling of two small bands of the sort envisioned by Washburn and Moore ( 1974 ) , it is not too difficult to imagine that malefemale bonding could become customary between the two groups . It is doubtful that @ @ @ @ @ @ @ @ @ @ without the tool of language , but the basis for some of the social relationships which would later be verbally labelled could , and probably did , predate language . This is not a niggling qualification on our part , because speculation on the origin of language must be conservative in order to be sound . That is , if a custom , social relationship , technology , or conceptual system could reasonably have developed without language , it is prudent to assume that it did so . The subsequent verbal labelling of items , relationships , and events is easy enough to understand once the labelling concept became established . Bernard Campbell ( 1974 ) suggests that by the early Pleistocene ? toward the end of the australopithecine phase , that is ? we " would expect Australopithecus to have a stable and well-adapted social system p. 384 . " We might suppose that cooperative hunting , for which there seems to be evidence , would imply the use of language . But while language would no doubt be a help , it is by no means // required . @ @ @ @ @ @ @ @ @ @ Campbell 1974 ) , hunt cooperatively , and many animal species can be described as having stable and well-adapted social systems even though they lack language . Direct evidence for the early use of language is not to be found in the archaeological record because the spoken word is ephemeral , while archaeological evidence necessarily is durable . The hard cultural evidence from the remote past does , however , provide a basis for judging complexity of social organization and cultural advance . It might be possible to discover a criterion for stating that a particular level of development could not have been attained in the absence of language . Organizational accomplishments on the order of those achieved by the social insects would no doubt meet such a criterion , given our general understanding of the different evolutionary course of the vertebrates and the particularly cognitive tendency of the hominids . Unfortunately this understanding does not help us pinpoint the origin of language . Our own only began to approach the complexity of social-insect organization in historical or near historical times , when language was already highly developed . The examination @ @ @ @ @ @ @ @ @ @ an archaeologically verifiable aspect of culture for which there is a linguistic sine qua non . In the meantime , we have not exhausted the fossil evidence . We should expect an intellectual advance as significant as the development of language to have discoverable anatomical correlates . If this is so , there are several general periods in the past which may eventually prove particularly important . First is the period some millions of years ago when the australopithecines first appeared . But while they were clever enough to launch our cultural beginnings , these primordial tellows are not generally credited with anything that can properly be called language . A somewhat // better bet , perhaps , would be the transition between Australopithecus and Homo erectus , since this was accompanied by an enormous expansion of the brain that peaked between one-half million to one million years ago ( Campbell , 1974 ) . By 300,000 years ago , if Campbell ( 1974 ) is correct , the people living in Eurasia and Africa were physically indistinguishable from modern human populations except for their relatively long skulls and heavily built @ @ @ @ @ @ @ @ @ @ ours . It may be that these Neanderthals were the first to develop language . Or the great step may have come with the reduction of the massive jaw and the slight reshaping of the skull that took place between 50,000 and 30,000 years ago , as Neanderthals disappeared and modern man ( Homo sapiens sapiens ) monopolized the human stage . The last big change is of special interest because of the recent argument put forth by Lieberman ( 1973 ) , who says that Neanderthal lacked the supralaryngeal vocal tract necessary for fully encoded human speech . The apes and Australopithecus show a similar lack . On the other hand , the female cranium found at Steinheim , which is thought to be 150,000 to 250,000 years old ( Campbell , 1974 ) , seems to have been suitably equipped with the necessary supralaryngeal vocal tract . Lieberman does not deny that Neanderthal may have communicated by means of language , but he does feel that by modern standards it would be greatly restricted , slow , perhaps supplemented by ? a gestural system , and best considered to @ @ @ @ @ @ @ @ @ @ , and Klatt , 1972 ) . Lieberman 's conclusions have been challenged on methodological grounds by Carlisle and Siegel ( 1974 ) , and while Lieberman and Crelin ( 1974 ) have offered a rebuttal , even on linguistic grounds their argument is somewhat questionable . That is , a great deal of their attention focuses on the specific quality of a very few sounds , and there is no // obvious reason why any language should have to depend on a specific sound or limited set of sounds . Further , people who have had various of the " speech organs " surgically removed are often able to compensate for the loss sufficiently to speak more or less intelligibly . Still , Lieberman 's approach is interesting as an example of the kind of ingenuity that can be turned loose on the problem of the origin of language . CHARACTERISTICS OF SPEECH According to a Pavlovian formula , vocal sounds make up another and more powerful " signaling system . " In other words , they become coded . If words are used specifically and conventionally for external events @ @ @ @ @ @ @ @ @ @ or other kinds of stimuli from these sources . Words , like gestures , can then be used to - direct the sense organs of the hearer toward parts of the environment that he would not otherwise perceive , and to induce him to perceive at second-hand sectors of the larger environment that the speaker has perceived but the hearer has not . As man 's use of speech developed , the vocalizations that were uttered came to possess expressive as well as symbolic qualities . The qualities of vocal sounds that we call " expressive " specify types and subtypes of human emotions , moods , and feelings . The crying of a baby and the laughter of a young person are sounds that are unmistakable . There are moans of pain and sighs of relief , growls of anger and grunts of effort , shouts of triumph and murmurs of love . We must assume that these types of vocalization existed long before speech . It was probably from this repertory of spontaneous , unlearned utterances in our hominid ancestors that conventional speech sounds developed . It remains the function @ @ @ @ @ @ @ @ @ @ , feeling , intentions , and temperament of the speaker . Vocal speech also contains the symbols that express things in the common environment of all individuals . These symbols , according to Gibson ( 1966 ) , enable men " to think of the same things , to have concepts in common , and to verify their concepts jointly p. 88 . " Symbolic meaning is on a different level from perceptual meaning . The cry " wolf ' has an entirely different function from both the cry of alarm when one actually sees a wolf and the baying of the wolf itself . The relation of a perceptual stimulus to its causal source in the milieu is of one genre , while the relation of a symbol to its referent is of another . The former depends on the laws of physics and biology , that is , on the " ecology of stimulation . " The latter depends on a " linguistic community , " which is a unique invention of the human species . The relation of perceptual stimuli to their source is an innate one ; @ @ @ @ @ @ @ @ @ @ of symbols to their referents is an arbitrary one , governed by social agreement . The conventions of symbolic speech must be learned , but the child can learn one language just as easily as another . The connections between stimuli and their sources may well have to be learned in part , but they do not make a language . The language code is cultural , traditional , and arbitrary ; the connection between stimuli and their sources is not . PHYSIOLOGICAL ASPECTS OF SPEECH The source of acoustical speech sounds is the human vocal apparatus , backed up by the human nervous system . This apparatus is one of the most complex sound-makers in the world . The sounds arise from a series of exhalations and inhalations produced by the breathing muscles of the // chest and diaphragm . These may or may not be accompanied by movements of the mouth , jaw , lips , tongue , and velum ( Gray and Wise , 1959 ) . The series of concurrent movements produces what is called the " segmentation of speech " ? that is , the segments @ @ @ @ @ @ @ @ @ @ or unvoiced , is modified in spectral composition to make vowels . It is also cut by pauses , stops , and transitions , to make consonants . The vowels and consonants are the units of articulation . The muscular movements that create phonemes tend to be stereotyped . If these phonemes are thought of as both the responses of a speaker and the stimuli for a listener , it can be predicted that each speaker of a community will be compelled to make the same phonemes as others , in order to be intelligible ( Gibson , 1966 ) . This phenomenon is generally viewed as part of what children do when they " learn to speak " : they learn to pronounce in accordance with their language or their dialect , under social pressure from playmates , parents , and school . In other words , the process of speech development could be conceptualized thus : at first the child possesses a large repertoire of speech sounds ( many of which are not included in his native language ) . Gradually , through processes that seem to involve both @ @ @ @ @ @ @ @ @ @ the sounds that are needed in his language ; sounds that are not reinforced by the speech of his verbal environment are eliminated , and the child is left with a repertoire that contains his approximation of the sounds he hears . As the neuromusculature and the sound-discrimination processes mature , the child refines and polishes his repertoire into the sounds of his native tongue , gaining voluntary control over their production ( Osborn , 1961 ) . The sounds , having been stereotyped by the community , can be said to have a valid objective reality ; according to Gibson ( 1966 ) , they are " anchored in the habitual resonances , stops , frictions , and explosives of // conventional articulation and specified by certain invariant properties of the wave trains of vibrating fields in the air p. 94 . " One physiological process that plays a part in the way the infant learns to speak is referred to by Simon ( 1957 ) as " kinesthetic and auditory feedback . " Buhler ( in Brain , 1961 ) , noting that the child hears the sounds that @ @ @ @ @ @ @ @ @ @ is the formation of strong associations between the auditory impression and the movements which produce it , for this is the essential basis of the later imitation of the sounds the child hears , in which it has to translate what it has heard into vocal movements of its own . p. 154 This approach represents an old theory , according to which the human infant , in the babbling stage of speech development , learns associations between the sounds of speech and the acts of speech , or conditioned reflexes that connect a certain auditory stimulus to a certain vocal response . This is taken to be the basis of vocal imitation , and to explain why deaf children do not learn to speak . It is assumed by association theorists , therefore , that children must learn that hearing and speaking correspond . It is perfectly true that any single , elementary muscle contraction does not correspond to any single , elementary sensory datum . But the pattern of of nervous input at the cochlea ( Gibson , 1966 ) . There is no need for these to be @ @ @ @ @ @ @ @ @ @ during the babbling stage is that the child learns to differentiate pattern and change in muscular output , and makes a parallel differentiation of pattern and change in the cochlear input . As the child learns to articulate the invariants of sound , he learns to discriminate them . The practisBIOLOGICAL // ing of vocal-auditory activity permits learning , but it is not associative learning . The function of auditory self-stimulation is , therefore , probably best understood if it is conceived not as a kind of audition , but as a kind of proprioception . It monitors the flow of speech in the same way as other modes of proprioception keep track of the flow of other types of behavior . It thus enables articulation to be controlled . The next syllable depends on the previous one ; feedback yields a concurrent record of how far the speech has progressed . NEUROPHYSIOLOGICAL ASPECTS OF SPEECH From a neurophysiological standpoint , the expressive and symbolic qualities of language are merely manifestations of what Head ( 1926 ) considered to be the basic processes of symbolic formulation and expression . Brock and @ @ @ @ @ @ @ @ @ @ complete form , this symbolic thinking and expression becomes a function of the entire cerebral cortex . It is largely through the work of Penfield , however , that the true complexity of the speech mechanism has been revealed . Penfield and Roberts ( 1959 ) have demonstrated that no two human cerebral hemispheres are ever the same in form and in the pattern of convolutions and fissures . At the time of birth , the motor and sensory areas of the brain are beginning to take on their function as transmitting stations . At that time the speech areas are " blank slates on which nothing has been written p. 198 . " Generally three cortical speech areas , shown below in Figure 7.1 , will be developed in the left hemisphere . The right hemisphere may become dominant with respect to localization of the speech centers , but this is quite rare . In addition , a small lesion in infancy may produce some displacement of the expected location // of the areas within the left hemisphere . A large lesion in the posterior speech area may cause the @ @ @ @ @ @ @ @ @ @ , where the cortical areas will take up homologous positions . In the cerebral cortex of the human adult certain areas are devoted to the control of speech musculature , and cerBIOLOGICAL // tain other areas are devoted to the ideational processes of speech . Each of these areas will be discussed separately . Information about the motor mechanism of speech has been obtained by Penfield and others through the electrical stimulation of the cortex of conscious subjects . Vocalization ( Penfield and Jasper , 1954 ) has been found to be the response of a small area between those governing the upper face movement and the lip movement on the precentral Rolandic gyrus ( Figure 7.2 ) . It was subsequently shown that vocalization could be produced in the supplementary motor area of either cerebral hemisphere ( Penfield and Rasmussen , 1950 ) . A gentle electric current in one of these specific cortical areas causes a patient who is lying fully conscious on the operating table to utter a long-drawn-out vowel sound , which he is completely unable to stop until he runs out of breath . Then , @ @ @ @ @ @ @ @ @ @ helplessly as before . One of the major differences between the cortical motor responses of man and animals is manifested in human voice control . The cortical area that governs control of the voice , including articulatory movements and vocalization , is located between the two principal areas that control ideational speech , one posterior and the other anterior ( see Figure 7.1 ) . It would appear that the Rolandic area of voice control on either side can serve the purposes of speech alone , since excision of one of the vocalization areas does not permanently interfere with speaking . The areas of the cortex that are utilized in the ideational elaboration of speech have been determined by applying a gentle electric current to the relevant areas of the cortex of the dominant hemisphere in conscious human beings . The interfering current causes the patient to become aphasic until the electrode is withdrawn . Three areas have been outlined ( see Figure 7.1 ) : 1 . A large area in the posterior temporal and posterior inferior parietal regions ( Wernicke 's area ) // 2 . A small area @ @ @ @ @ @ @ @ @ @ anterior to the motor voice-control area ( Broca 's area ) . Three areas are devoted to the ideational elaboration of speech ; two areas devoted to vocalization . The principal area devoted to motor con-trol of articulation , or voice control , is located in lower precentral gyrus . Evidence for these localizations is summarized from the analysis of corti-cal stimulation and cortical excision . ( Reprinted by permission of Prince-ton University Press and the authors . Source : W. Penfield and L. Roberts , Speech and Brain Mechanisms , Princeton : Princeton University Press , 1959. ) // 3 . A part of the supplementary motor area within the midsagittal fissure and just anterior to the Rolandic motor foot area ( the supplementary speech area ) . All three of these cortical areas , which are organized to function in one hemisphere only , play roles in the ideational speech mechanism under normal conditions . The primary function of these areas of the cortex is the " memory " of words . In addition , part of the temporal cortex ( chiefly on the superior and lateral surfaces of @ @ @ @ @ @ @ @ @ @ the parietal lobe ) and parts of the hippocampal gyrus assume the function of interpreting experiences ; hence they are known as the interpretive cortex . Referring to these areas , Penfield and Perot ( 1963 ) concluded the following : There is within the adult human brain a remarkable record of the stream of each individual 's awareness . It is as though the electrode cuts in , at random , on the record of that stream . The patient sees and hears what he saw and heard in some earlier strip of time and he feels the same accompanying emotions . The stream of consciousness flows for him again , exactly as before , stopping instantly on removal of the electrode . He is aware of those things to which he paid attention in this earlier period , even twenty years ago . He is not aware of the things that were ignored . The experience evidently moves forward at the original pace . This was demonstrated by the fact that when , for example , the music of an orchestra , or song or piano , is heard @ @ @ @ @ @ @ @ @ @ the tempo of his humming is what one would expect . He is still aware of being in the operating room but he can describe this other run of consciousness at the same time . The patient recognizes the experience as having been his own , although usually he could not have recalled it if he had tried . The complete record of his auditory and visual experience is not subject to conscious recall , but it is evidently used in the subconscious brain-transaction that results in // perception . By means of it , a man in normal life compares each succeeding experience with his own past experience . He knows at once whether it is familiar or not . If it is familiar , he interprets the present stream of consciousness in the light of the past . There is , apparently , no overlap of the boundaries that separate the speech cortex , which endows one with memory of words , and the interpretive cortex , which gives one access to the memory of past similar experiences and thus enables one to understand the present ( Penfield , @ @ @ @ @ @ @ @ @ @ only real evidence for the biological basis of language is the language universals : a common age of onset , the universality of the ontogenetic process of language , and the universality of syntactic structure ( concatenation of morphemes in a nonrandom manner ) . The contention that language is biologically based seems well-supported , theoretically and experimentally , but this is only preliminary to the more basic question of what specific biological mechanisms are involved . That speech habits emerge as a function of maturational changes within the growing child seems to be the best biological explanation of language , since a great variety of environmental conditions leave the age of onset unaffected . Furthermore , there is much evidence that language development is interlocked with other maturationally-based behavior such as stance , gait , and motor coordination , although it is independent of these other processes ( that is , it is neither caused by , nor a cause of , these processes ) . Also , there is no evidence that training procedures can advance the rate of language learning . A critical period of language acquisition is @ @ @ @ @ @ @ @ @ @ termination is related to a loss of adaptability and of the capacity to reorganize in the brain ; this is a function of the cerebral lateralization of function . As the specific neurophysiological correlates of language are still unknown , the emergence of the critical period of readiness for language can not be attributed directly to any one maturational process . The prerequisite for the eventual discovery of these specific neural phenomena is a knowledge of the exact brain states before , during , and after this critical language period . Some factual evidence is available on which we can postulate that there is a correlation between full maturation of the brain and the end of the critical period , but a causal relationship can not be inferred . Aside from the correlational aspects of the process , just how does language develop ? Lenneberg ( 1967 ) presents an argument that is more convincing on how it does not develop than on how it does . To say that language is a discriminatory learning process , or that it is a function of secondary reinforcement , or that it is @ @ @ @ @ @ @ @ @ @ constructs and are contrary to the observed facts . There is some evidence that linguistic development is a process closely related to other biologically based principles of the organization of behavior . Sensory data are first of all grouped into undifferentiated global classes , and these are subsequently differentiated into more specific patterns . Both perceived patterns and self-produced patterns become organized in this way . CONCLUDING OBSERVATIONS The outline of the neurophysiological basis of speech seems to be well-established . The three speech areas have been clearly mapped , and their function in word-recall has // been described . Although the location may be different from person to person , their presence is certain . Penfield has demonstrated the existence of an interpretive cortex , which complements the function of the speech centers . It has the function of presenting a background of experience against which the individual can compare and interpret his present situation . Connecting pathways integrate these speech mechanisms , linking them to each other , to other areas of the cortex , and to the thalamus . It is the thalamus ( plus the hypothalamus and @ @ @ @ @ @ @ @ @ @ all bodily functions . The neurophysiological aspects of speech are still far from completely understood . As van der Berg ( 1961 ) has stated : The present data show a certain degree of specialization in the tremendous number of neurons and associated inter-connecting structures . A large number of centers ' seems to be imbedded in a vast network of multi-purpose neurons . The topography becomes gradually better known and with it a rough outline of the channels interconnecting the ' cen-ters , ' but we are yet far away from the point where it would be possible to build an electrical analog. p. 66 Until further research is conducted and more facts are discovered , our understanding of the neurophysiological and psychological aspects of the production of speech will remain incomplete . A greater insight into the controlling mechanism of the subcortical structures and into the corre-lation of patterns of neural excitation with words and con-cepts is sorely needed . 8 The Theory of a Language While most of us are startled to realize that ghoti can be pronounced " fish " ( if we use the phonetic values @ @ @ @ @ @ @ @ @ @ all acknowledge that our system of orthography is extremely cumbersome . We have at least a vague understanding that the problem lies in the fact that the same letters can stand for different sounds ( I , machine , mitt ) , while given sounds may also be repre-sented by different letters , as in the ghoti example . So even the linguistically naive individual soon reaches the conclu-sion that an alphabetic script should represent rather closely the sounds of the language it depicts . A script that attempts to reflect pronunciation in detail is phonetic , and we might suppose that this is an ideal kind of writing sys-tem . In fact , a strictly phonetic script is neither feasible nor desirable for most purposes . A number of attempts have been made to devise pho-netic alphabets ; the one most widely employed throughout 149 // the world is the International Phonetic Alphabet ( IPA ) of the International Phonetic Association . The IPA was developed before the phonemic principle was well understood ( Bloomfield , 1933 ; pp. 86-88 ) , and great pains were taken to make fine @ @ @ @ @ @ @ @ @ @ represent the infinitely fine acoustical variations that mark speech , not only from one language to another , but even within the speech of a single individual . This will become clear shortly , when we consider some of the variations that occur in our own speech . THE PHONEMIC PRINCIPLE For most purposes , it is not the exact acoustical quality of a speech sound that must be graphically represented , but rather certain ranges of sound that are significant for a specific language or speech variety . This is the essence of the phonemic principle . A phoneme is an abstraction . We do not speak or hear a phoneme as such ; rather we speak and hear specific representations of phonemes , which are known as allophones . We can illustrate this by considering the variations in the four words " cool , " " school , " " kill , " " skill . " There are two vowel phonemes , /uw , i/ , and three consonant phonemes , /s , k , 1/ . But a closer look at the kand sk- sequences shows that @ @ @ @ @ @ @ @ @ @ . In " cool " and " kill " a puff of air accompanies the k ; this is missing in the other set , " school " and " skill . " We can note the same contrast in the p of " pin " and " spin " and in the t of " tall " and " stall . " We do not even notice this difference when speaking English , but it is a critical difference in some languages ? as critical as the difference between b and p in English , for example . Thus Chao ( 1968 ) states that " the English word pie sounds like the word for to dispatch ' in Chinese , while the py part of spy sounds like the Chinese word for to bow ' p. 3. " // Aspiration Thus we simply say that the aspirated and unaspirated varieties of the k are allophones of a single /k/ phoneme , and we can further indicate that the aspirated form appears in the initial position and the unaspirated form occurs after a fricative , s , z , f @ @ @ @ @ @ @ @ @ @ impeded by sufficient closure to yield audible friction , but is not stopped completely , as it is for stops such as p , t , and k . Positioning But we have not exhausted the allophones of /k/ . If we compare " kill " and " cool , " we can tell that with the k-before the i , the tongue presses the roof of the mouth further forward than in the case of the k- before the oo . One can feel this by forming the two k ' s in the mouth , without actually saying the words " kill " and " cool : " the tongue is shifted back and forth . Again , we can predict that the front k will occur before front vowels ( as in " kill , " " keel , " " care , " " Kate , " and " cat " ) , while the back k will anticipate the articulation of back vowels ( as in " coops , " " coat , " and " couch " ) . It is obvious , then , @ @ @ @ @ @ @ @ @ @ , which will contrast with other allophones . This is why we say that we do not actually hear or say a phoneme : the phoneme is an abstrac-tion of all the allophones , and only one of the allophones can be uttered at a single time . We may also note that the quality of the -1 differs after the front vowels in " kill " and " skill " and after the back vowels in " cool " and " school " ; because the approach to the place where the /1/ is ar-ticulated is different in the two cases , and the lips remain rounded after the back vowel and unrounded after the front vowel . If we were to look in detail at all of the environ-ments of /k/ ( or of any other phoneme ) , we would find an // enormous number of allophones . Fortunately , this is not necessary for most purposes . What is necessary is that we should identify the phonemes and then assign a single symbol to each one , rather than attempting to use a separate symbol for each @ @ @ @ @ @ @ @ @ @ to distinguish meanings . That is , when we find two strings of sound that are identical except for a single feature , we will say that the strings are identical if the feature in question is phonemic , and will not if it is not . Thus " nip " will be regarded as the same , whether or not the final -p is released with a puff of air . Voicing Thus aspiration is not critical , and we can say that we are dealing with allophones rather than with separate phonemes . But what of the difference between nip and nib ? It happens that " nip " will characteristically end with a puff of air , while " nib " will not , but we have ruled out the aspiration as critical ; and yet we know that the two sequences of sound have different meanings for us . If we attend carefully to what is happening , we will find that it is possible to prolong the sound of the -b but not the -p . What we hear when we prolong the -b is the @ @ @ @ @ @ @ @ @ @ vibration can be felt if we place the hand around the throat and sound the sequence of a very long s-z-s-z-s . That is , if we alternate between a hiss and a buzz , the absence of vibration when we are hissing is quite clear . So voicing is critical for certain consonant pairs ( p-b , t-d , k-g , s-z , f-v , and so on ) . Vowel Length In some languages , such as Hawaiian and Japanese , vowel length is a critical , or distinctive , feature . In the latter language , for example , to lengthen the first vowel of kofun // " burial mound " transforms the morbid meaning of the sequence into the much livelier koofun " ( sexual ) excitement . " We are not used to the idea that vowel length is distinctive , and yet we regularly employ long vowels before voiced final consonants ( as in " buzz , " " pig , " " bode " ) but short vowels before their unvoiced counterparts ( " bus , " " pick , " " boat " @ @ @ @ @ @ @ @ @ @ vowels , we do not effect a change in the meaning . Free Variation Just as have to work a little even to hear the nondistinctive features that distinguish our allophones ( such as the lack of aspiration in some phonetic environments or routine differences in vowel length ) , people who are learning English as a second language have the same sort of difficulty in distinguishing what are , for us , obviously distinctive sounds . How could anyone , for instance , confuse " loom " and " room " ? Yet in some languages the l and r are in free variation . The Japanese r is usually described as a " flap " r , more like the Spanish sound than ours , but with many speakers the sound in question sounds like an l to us . In Japanese , it simply does not matter which way the articulation ends , because there is no linguistically significant difference between the two . And since the Japanese have grown up " tuning out " the differences within that particular range of phonological variation , when they find @ @ @ @ @ @ @ @ @ @ difficulty in learning to hear the distinction . PHONEMES , MORPHEMES , AND SYNTAX The development of the concept of the phoneme was something of a breakthrough in linguistic analysis , but in some ways it was too successful . The differences between phonemes could be demonstrated fairly neatly , and the // same methodological approach could be applied to the smallest meaningful segments , morphemes , while longer stretches could be built up from morphemes . The striking success attained with phonemes focused attention on them almost to the exclusion of other features of language . This limitation was enhanced by the very useful work of missionaries who were primarily concerned to translate the Christian Bible into languages that had hitherto been without a script . Since the targets of this enterprise already knew their languages , the main job of the missionary/linguist was to identify and label phonemes . For various reasons , then , phonemes were the first order of business , and all too often the researcher ran out of gas , as it were , before he tackled the syntax . As Bolinger ( 1968 ) @ @ @ @ @ @ @ @ @ @ practical necessity and historical accident was thus elevated to a theoretical precept : " Do not attempt to deal with syntax before morphology , nor with morphology before phonology ; to do so is to rnx levels . " Since the units of each lower level were the components of the units at the next higher one , it was impossible to move up until the proper foundation had been laid . pp. 193 ? 194 We have probably implied that the identification of phonemes and morphemes is much simpler than it really is , but once the actual complexity of the task is appreciated , it is also easier to appreciate why so few attempts were made to deal seriously with syntax . The investigator of a tongue that is alien to him will hear a great number of exotic sounds , but some of these will be significant ( phonemic ) and some will not , while some of the acoustical distinctions he has been making all his life may not be relevant to the speakers of the alien language ; thus we can imagine that even the description @ @ @ @ @ @ @ @ @ @ Yuen Ren Chao ( 1968 ) relates a surprise he received once : ... I was watching some bargaining on a street market in Yunnan ( where the dialect is a variety of Mandarin ) . I // could n't be sure whether they were quarrelling or coughing . Listening more closely to what they were saying , I began to realize that the cough was simply the dialectal cognate of standard Mandarin aspirated k , the unaspirated k , as I knew , being a glottal stop in that dialect . p. 24 We should not be deceived into underestimating the task by anecdotes such as that offered by Chao ( 1968 ) about Edward Sapir , " who on our first meeting learned in little more than an hour not only the main phonemics of my native dialect Changchow , Kiangsu , but also what to say and when , and what expressive intonation to use p. vi . " Very likely Sapir knew exactly what questions to ask , and Chao was able to respond immediately and knowledgeably ; this is a rather different situation from that of @ @ @ @ @ @ @ @ @ @ , who is dealing with individuals who would not understand economical questions . SUPRASEGMENTAL PHONEMES We have mentioned some English phonemes ; a more or less complete listing of phonemes for one speaker is given in Table 8.1 . The segmental phonemes , including consonants , vowels , and semivowels , are probably clear enough ? ( at least in principle ) , thanks to our experience in writing and reading . That is , while our spelling seems highly imperfect , what we write consists of consonants , vowels , semivowels , and punctuation . Our punctuation marks only hint at another kind of phoneme , the suprasegmental phoneme . Stress In order to establish suprasegmentals ( for example stress ) as phonemes , it is necessary again to establish them as somehow critical . For many of us , the following constitute minimal pairs : Table 156 // Table In all these cases , the shifting of the primary stress from the first syllable to the second shifts the meaning from that of a noun to that of a verb . This is enough to establish stress as phonemic @ @ @ @ @ @ @ @ @ @ will demonstrate that there are more than two degrees of phonemic stress in English . Nucleus and Intonation We have what we can think of as normal stress patterns in English . Paul Roberts ( 1967 ) says that in English , a ker158 LANGUAGE IN BEHAVIOR nel sentence is made up of a nucleus and an intonation . The nucleus is represented by a word or several words , while the intonation is a combination of stress ( loudness ) and pitch ( the high or low quality that depends on the speed of vibrations with which sounds are uttered ) . Any kernel sentence has a syllable that carries the main stress . More often than not , this stress falls on or within the last word in the sentence : I bought a new book . This carries no special implications : it is simply a casual sentence , which does not suggest a particular context . But if we shift the stress pattern , we change the meaning : we are answering different questions . " I bought a new book " tells who bought it ; @ @ @ @ @ @ @ @ @ @ means whereby I acquired the book is in question ; a answers the question of number ; new rules out secondhand ; and if we give an overstress to book we emphasize what it was that we bought . Joe Pierce ( 1966 ) thinks that overstress is not phonemic , serving only to call attention to that segment of the utterance ; the fact that overstress alters the meaning ( in that the utterance thereby answers different questions ) would seem to indicate that it is , indeed , phonemic . Pierce also suggests that because stress and pitch are so closely related , there are two " intensity " phonemes , rather than stress or pitch . The first is a phonemic stresspitch and the second is a sentence stress-pitch . We need not choose sides here , but the argument depends in part on the claim that stress does not show up on the sound spectrograph even if it is " heard . " Whatever the final decision may be so far as English phonemes are concerned , it is difficult to accept the idea that stress is @ @ @ @ @ @ @ @ @ @ have to learn to avoid applying stress in Japanese , which relies on pitch accent . Americans must learn to make the right syllables higher in pitch , without at the same time making those syllables louder . // We have already shown that stress is phonemic in English , but so too is intonation . If , for example , we ask " Where ? " with a rising intonation , we are asking to have the statement repeated , as if we did not hear it clearly or can not believe the destination . But if " Where ? " has a falling intonation , it means we want more detailed information . Suppose A says " I 'm going shopping " and B asks " Where ? " with a falling intonation : the name of a specific store would be an appropriate answer . If the " Where ? " were asked with a rising intonation , a repeat of the statement would be the appropriate answer . Thus intonation contours are phonemic in English , but our use of them is relatively limited . In Mandarin @ @ @ @ @ @ @ @ @ @ ( though in practice it works a little like our nuclei ? a polymorphemic string will usually have a single syllable that predominates ) the problem is more complex . As Robins ( 1964 ) describes the phenomenon , " The pitch levels or the rising and falling pitches are properties of the words as lexical items ; the substitution of a different word in a sentence may change the pitch sequence , if the two words concerned are different in tonal composition p. 112 . " As an example , the sequence /ta/ in Mandarin may represent four different words , depending on its tone : " to raise " ( level tone ) , " to penetrate " ( rising tone ) , " to hit " ( rising-falling tone ) , or " great " ( falling tone ) . The local dialect of Hong Kong is more complicated ; it has three tones in each of two registers ( high and low ) . Juncture A moment ago we mentioned that not only stress and pitch , but also the intonation contour are phonemic in Erb glish @ @ @ @ @ @ @ @ @ @ of pitch and juncture , and at least one kind of juncture is phonemic and is not confounded by the question of pitch . This // is the kind of pause that distinguishes " night rate " from " nitrate . " The junctures are transitions that have a great deal to do with the rhythm of the language and its overall sound . Many speakers of Cantonese , for example , have a distinctly choppy sound when they tackle English , partly because they introduce too many open ( or internal ) transitions of the sort that separates the " night " and " rate " above . Some Spanish speakers , on the other hand , ignore certain open transitions in English , or else shift them : instead of saying an + ashtray , they may produce a + nashtray . We tend to think generally that the open transitions separate the words of an utterance ( Sawyer and Silver , 1960 ) , but this does not work out quite so neatly . In the sentence " Here it is , " for example , the open @ @ @ @ @ @ @ @ @ @ " it . " We distinguish three other kinds of juncture in English . There is a rising juncture , represented by a double bar /11/ , which usually comes at the end of a yes-no question ( " Is he coming ? " ) . One of the characteristics of many English speakers in Hawaii is that they use a falling juncture in this type of question . The falling , or terminal juncture , represented by a double cross /#/ , marks the end of most of our sentences . Finally , there is a level juncture , marked by a single bar /1/ , which is characteristically indicated by a comma when we write . Morphemes If we examine a corpus , or body , of material ( a novel , for example ) , we will notice that it contains recurring partial similarities . The smallest units that occur this way are of course letters and punctuation marks , but having established that these are simply derived from phonemes , we may consider larger segments . We may see , for example , strings such as " @ @ @ @ @ @ @ @ @ @ " " wood , " " woods , " " woody , " and so forth . These six strings have four components : " word " and " wood , " which may appear // as independent units , and -s and -y , which appear only at the end of a string . We would have to modify the latter statement somewhat as we accumulated additional evidence ( there are variations , as in " the park has a woodsy feeling about it , even though it is located in the heart of town . " ) But as a matter of convention we make the most complete , general statement that we can on the basis of our corpus . At any rate , we can in this way identify the minimal meaningful strings that we call morphemes . Strings such as " word " and " wood " we call free morphemes , and strings such as -s ( indicating " plural " ) and -y ( indicating " like " or " characterized by " ) we call bound morphemes , since they can not appear @ @ @ @ @ @ @ @ @ @ various allophones , many morphemes have allomorphic variants . In the case of the plural , for example , we may note that typically there is an s sound after unvoiced consonants , except after some fricatives . Thus we get s after the t in " cat , " or after the fricative f in " cliff , " but after the fricative s of " bus , " or the fricative s of " bush " we get az or iz . The same midvowel + -z sound follows not only some fricatives , where the flow of air is forced through a constricted channel but is not quite stopped , but also some affricates . Affricates consist of a stop + fricative , as in " church , " which begins and ends with a t + s , or " vex , " which ends with a k + s . Elsewhere the plural is just the -z sound , without the preceding vowel . But this only accounts for the majority of noun plurals in English . There is also a zero allomorph of the plural @ @ @ @ @ @ @ @ @ @ " and there is another form that depends upon an internal vowel change , as in " man-men , " " louse-lice , " and so forth . There are also a few nouns that form the plural with - en , as in " oxen , " or -a , as in " datum-data , " or -i , as in " cactus-cacti. " // When we consider all the problems with nouns ( singu-lar versus plural , morphemes that make nouns into other forms such as adjectivals ? bookish ? or adverbials ? mo-mentarily , and so forth ) and the other so-called parts of speech , the study of morphemes becomes a little formida-ble . Some morphemic problems may not even come into focus until syntactic problems are tackled . In English we have a considerable number of two-part verbs , for example , but these are not very clear until we see how we can juggle the parts . We can turn off the road , and indeed we may have to turn off it if we come to a detour . But while we can turn off @ @ @ @ @ @ @ @ @ @ turn off it , no matter hard had we try . Thus we can use the pronoun " it " after the preposition " off " when " turn " is a one-part verb , but we can not use " it " after the particle " off " when it is the second component of the two-part verb " turn off . " We can not say * turn it off for " the road , " or * turn the road off , but " turn the audience off ' is good English , if poor policy . Immediate Constituent Analysis Until 1957 the building-block approach to linguistic analysis held the field . One tackled phonemes , then mor-phemes , and then , as time permitted , so to speak , one tackled larger sequences such as syntax . One way or an-other , the interrelationships of the various elements in an utterance must be determined and described . ' To take an example from Gleason ( 1961 : p. 129ff. ) , given the sentence " The old man who lives there has gone to his son 's @ @ @ @ @ @ @ @ @ @ English to deter-mine that " old " and " man " belong together in a way that " man " and " who " do not ; similarly , " has " and " gone " seem close . Our intuitions may differ on whether " his " and // " son 's " go together better than " son 's " and " house , " however , and to the extent that we must depend on such intuitions ( which , Gleason notes , are beyond the reach of the foreign linguist , since he lacks the native 's " feel " for the language ) , the approach is weak . In the present case , however , it is possible to go beyond our intuitions by using the phenomenon of substitutability . That is , for elements that " go together , " effectively constituting a single unit , we can find a single-unit replacement that will still yield a grammatical sentence . Thus " oldster " can substitute for " old man " and " that " will substitute for " his son 's . " @ @ @ @ @ @ @ @ @ @ and substitute for them : thus one can substitute " Boston " for " that house . " This seems to verify our feeling that " his " and " son 's " are closer than " son 's " and " house " in this particular sentence . Gleason ( 1961 , p. 130 ) carries the process to the point at which " He " ultimately represents " The old man who lives there , " and " went " represents " has gone to his son 's house . " If we reverse the process , and ask what the basic division is in the sentence ? what the primary constituents are ? we will again distinguish " The old man who lives there " from " has gone to his son 's house . " And if we take each of these sections and treat it as a construction , seeking its immediate constituents , we will probably arrive at " The old man " and " who lives there " in the first case , and " has gone " and " to his son 's @ @ @ @ @ @ @ @ @ @ show the relative degrees of closeness of the several elements in the sentence . But it is not always possible to get agreement on even such a simple example as this , and there are two kinds of sentence that immediate constituent analysis seems flatly incapable of dealing with : ambiguous sentences and passive constructions . Langacker ( 1968 , p. 99 ) offers the example of " Steve or Sam or Bob will come . " If Bob is // coming for sure , then Steve and Sam constitute a unit , but we may only know that either Steve will come or both Sam and Bob will come ; here the immediate constituents are different for the two cases . A sentence that is famous by now ( thanks to Chomsky ) is " Visiting relatives can be a nuisance ; " here we do not know whether we are irritated by our guests or by our need to visit relatives . The case of the passives is more technical , and we shall return to it later . In either case the traditional approach reflects a kind of @ @ @ @ @ @ @ @ @ @ up an utterance and get at the basic elements . The implication of the traditional approach seems to be that language is a linear production . Surface Structure and Deep Structure But we do not begin an utterance by first thinking of a word with which to head the string , and then simply concatenating components until we need to draw a fresh breath . Complex rules govern the arrangement of the sounds of an utterance , and some segments that are destined to appear late have to be set up in advance by the inclusion of particular segments early in the utterance . To illustrate the point , we can contrast rules for typical yes-no questions in Japanese and in American English . In Japanese , one can convert most statements into questions by tacking the syllable ka onto the end of the utterance . But consider all the parts that have to be moved when we want to convert " he went " into a question . We have to begin with the auxiliary verb " do , " which by beginning the utterance tells us that the utterance @ @ @ @ @ @ @ @ @ @ And the " do " carries the tense marker , which means that the tense marker is substracted from the main verb : " Did he go ? " All these arrangements are set up before we actually produce the utterance ; the utterance is a reflection of the arrangements of linguistic units that constitute its surface structure . // Morphophonemic Rules This surface structure is not exactly the same as the utterance we hear , since it takes morphophonemic rules to convert strings of morphemes into strings of phonemes . ( Chomsky , 1965 , handles this differently , but the details need not concern us here . ) Thus the plural morpheme will be in the surface structure , but the morphophonemic rules yield an /s/ sound in some cases , a /z/ sound in other cases , no sound at all in words such as " sheep , " and so forth . If we had to concern ourselves only with the surface structure , however , we would essentially be making an immediate constituent analysis . And we would still be hardpressed to deal with ambiguities . @ @ @ @ @ @ @ @ @ @ chickens " can refer either to a kind of chicken being examined or to an activity that some people are engaged in , and since the speaker has one meaning or the other in mind before he speaks , the two meanings of the string must be separate somewhere in the system . Where they are separate is in the deep structure of the utterances . In the deep structure there are two quite different sentences . When we are talking about the kind of chicken , the main verb is the copula " are , " and " barbc ? uing " is an adjectival expression that describes the chickens . When we are talking about what some people are doing , " are " is an auxiliary and the main verb is " barbecue . " TRANSFORMATIONAL GRAMMAR To get from the deep structure down to the surface structure , we depend on phrase structure rules , which are ( to state the matter a little too simply ) expansions of ideas such as " main verb " or " noun phrase . " And then , to achieve @ @ @ @ @ @ @ @ @ @ transformation rules . Thus it is a transformation rule that tells // us that to make " he went " into a question , we must put the auxiliary " do " at the beginning of the utterance . But just as the surface structure is not the actual end product of an utterance , the utterances do not actually begin with the deep structure . A myriad decisions have to be made before the deep structure can be set up . The first decision is whether to speak at all : individuals who incur sudden pain at a solemn moment are usually able to repress any " spontaneous " cry of pain , for example . If there is no psychological set to repress all sounds , so that the speaker has no inhibition against vocalizing , he must then select a code . If he is bilingual , he must draw on one language or the other . Once that decision is made , he must decide on a suitable level of politeness . If alone , he may curse ; if in " polite " company , he @ @ @ @ @ @ @ @ @ @ intense pain may elicit a truly involuntary response , anything less will be subject to the kinds of decision just described . The considerations that lead directly to the formation of the deep structure are whether to make an utterance interrogative , negative , passive , and so forth . Indeed , Charles Fillmore ( 1968 ) has gone so far as to propose a " case grammar , " which depends on meaning-relations . As Crystal ( 1971 , pp. 236ff. ) puts it , Fillmore is referring to a set of concepts that have to do with the kinds of judgments that humans are capable of making about the events that occur around them : who did something , who it happened to , where it happened , and so forth . There are various possible descriptions for any given event . If John opened the door with the key , " for instance , the subject position is occupied by the actor or agent ( John ) ; if " the key opened the door , " the subject slot is filled by the instrument by which the @ @ @ @ @ @ @ @ @ @ " the door opened , " the subject slot is filled by the goal of the action ( the door ) . Thus , Crystal states , " the function of the underlying meanings in relation to the verb does not change from // sentence to sentence , despite the surface differences ; and it is this fundamental , semantic identity which is the important thing to recognize about these sentences , and the central fact which a system of grammatical analysis should explain p. 237 . " At any rate , the new grammar promoted by Chomsky is known as transformational or generative ( or **26;576;TOOLONG ) grammar . Such grammars do not depend on a fixed corpus ; rather they aim to design rules that will generate all of the grammatical utterances of a language , while generating no nongrammatical utterances . Linguistic Competence and Linguistic Performance Viewing the matter in this way , we may readily understand why Chomsky , with one turn of phrase or another ( 1965 , for example ) , has presented the idea that grammar is a theory of language , and a @ @ @ @ @ @ @ @ @ @ works . This suggests that there are principles for the general case of language , which have applications to specific languages . In speaking of " language " here , we have in mind that Chomsky calls " linguistic competence , " as against " performance . " The competence is what one has to know ( the rules ) in order to produce and understand utterances . Performance is frequently marred by false starts , slips of the tongue , groping for the right word , and so forth . The distinction between competence and performance corresponds in part to the distinction between langue ( language ) and parole ( speech ) , which was first made by the Swiss linguist de Saussure early in this century . But there is another aspect of parole , or speech , in which performance is governed by social considerations , as we shall see later . For the present we are concerned only with linguistic competence , the knowledge that we all rely on to engage in verbal communication . // As indicated above , the generative grammarians depend on two kinds @ @ @ @ @ @ @ @ @ @ The former are essentially instructions for expansions that will get us from deep to surface structure , while the latter deal with the arrangements of elements in the surface structure . Here we can do little more than hint at the complexity of the problem , and can provide only the roughest of conceptions of how the approach works . Typically the transformationalist begins with the very abstract concept of the sentence , which is represented by an S. Then the S is expanded , to show that it consists of an optional sentence modifier and a nucleus . In order to gain some economy of presentation , a number of conventions are adopted . Optional elements are enclosed in parentheses , for example , and an arrow is used to indicate the appropriate expansion or category from which a selection is to be made . Thus S -4 ( SM ) + Nuc means that S is to be rewritten or read as ( Sentence Modifier ) + Nucleus . The sentence modifier comes into play in the event that a sentence must be made negative or interrogative , for @ @ @ @ @ @ @ @ @ @ phrase plus verb phrase ( Nuc -3 NP + VP ) . The noun phrase , in turn , can be written ( Det ) N (   ) , which indicates that it must consist of a noun at the very least , but it may be preceded by a determiner ( " a , " " the , " " those , " for example ) , and it may be plural . The verb phrase consists of an auxiliary and a main verb , and may have various adverbials , as of manner , place , time , and reason : VP ? Aux + MV ( manner ) ( place ) ( time ) ( reason ) . Liles ( 1971 ) , on whom this section draws heavily , offers the example of " The man will drive carefully in town today because of the ice , " where the NP is " The man , " the Aux is " will , " the MV is " drive , " and manner is " carefully , " place is " in town , " time @ @ @ @ @ @ @ @ @ @ of the ice . " We can see that if we begin at the end of the sentence and eliminate the optional elements // one at a time , the essential integrity of the sentence is maintained . In fact , we can eliminate almost all of the op-tional elements without changing the essential meaning of the sentence ; but there is one exception . If only " carefully " is omitted , there is a subtle shift in the meaning of the sentence , but a perfectly good sentence remains . At first glance it might seem a little strange to say that the VP invariably contains an auxiliary as well as a main verb , ' tit cause we think immediately of sentences such as " He ran , " or " She is sad , " but the rules of this approach specify that every auxiliary contains tense , and sometimes it consists only of tense . Thus the representation of the sur-face structure of " He ran " is He past run . If this seems a little cumbersome , consider an ambiguous example of the type @ @ @ @ @ @ @ @ @ @ habitual action or to a specific event in the past ; this shows us that one meaning or the other was present in the deep structure , and thus must be carried down to the surface structure . The expansion of the main verb becomes a little com-plicated . It may consist of a verb and an optional noun phrase , V ( NP ) , as in " I present understand ( her ) , " or it can consist of " be " followed by a number of options : NP ( is aman ) , Place ( was athome ) , Adjective Phrase ( is very pretty ) . In the last case the " very " is an optional intensifier . The potential expansions of the main verb may thus be very economically represented by this formula : The rules that have been applied to this point are simply phrase structure rules which show the elementary struc-tures that underlie the sentence . If we must rearrange , delete , or add structures , we will have to utilize transforma-tional rules . In the present case we have @ @ @ @ @ @ @ @ @ @ the surface structure of the sentence . In particular , we have to have such a rule to show us how to put the SM " not " in the right place ; the right place turns out to be the position following the first auxiliary after tense . Thus the deep structure of " he is n't going " is not he present be ing go . The application of the negative transforma-tion yields he present be not ing go , and all one must then do to arrive at the surface structure is to apply the affix trans-formation . That is , one must finally separate the ing from the auxiliary ( be ) and affix it to the MV ( go ) : he present be not go ing . Morphophonemic rules yield the " is , " and the join-ing of " is " and " not " yields is n't . As a matter of conve-nience , discussions of the surface structure are frequently handled as if the morphophonemic rules had already been applied . That is , the form we are accustomed to hearing or @ @ @ @ @ @ @ @ @ @ . // The " be " and the " - ing " go together , no matter what the main verb may be , so it is very economical to keep them together until the last step in the generation of the surface structure is reached . Similarly the past participle ( en ) goes with the auxiliary " have " " thave + en ) , and it is again ecnomical to keep them together as long as possible . Thus , before the affix transformation is applied , " He had been going " ' has the arrangement he past have en be ing go , and the affix transformation shifts the participles to the next unit in the sequence : en + be becomes " been , " ing + go becomes " going . " ( A morphophonemic rule tells us that the past of " have " is " had " ) Ambiguous sentences provide one difficulty in immediate constituent analysis , and the passive construction provides the other serious difficulty . In a sense , the two problems are similar but opposite . That is , @ @ @ @ @ @ @ @ @ @ deep structures , but for every passive construction there is an equivalent active construction , and either surface structure can be generated from a single deep structure . The passive transformation is characterized by the inclusion of be + en and by . That is , since the equivalence of the active and passive varieties is intuitively obvious and demonstrable , it is as important to find some way of relating the two structures as it is to clarify " They are barbecuing chickens . " For a number of reasons ( Chomsky , 1957 ) it is much more economical to derive the passive form from the active form of the utterance . Thus the man past eat the food becomes the food past be en eat by the man ; there is a morphophonemic rule to ensure that past be is realized as " was , " and the affix transformation shifts en to eat , " eaten . " Again , the en is just the notation we use for the past participle , and the final form of the participle is subject to a morphophonemic rule that @ @ @ @ @ @ @ @ @ @ finally attached . The en takes the form ed in " The barn was painted by the farmer , " for example . // GENERATIVE SEMANTICS AND BEYOND One of the most significant features of the whole **30;604;TOOLONG movement has been the increasing concern with the role of meaning . Most recently , in fact , the concern with meaning has for some scholars supplanted the concern with syntax , somewhat analogously to the way the classic generative concern with syntax supplanted concern with such lower-order events as phonemic analysis and description . Earlier , for example , we briefly remarked on the case grammar of Charles Fillmore ( 1968 ) ; another provocative statement from the same period was that of James McCawley ( 1968 ) , who queried whether , in the quest to join semantic and phonological interpretations , there was really a need to posit deep structure as a separate level . Indeed , at the other end of the model , there seems to be no need for the phoneme , if phonological analysis can be conducted without the concept ( a view shared with McCawley @ @ @ @ @ @ @ @ @ @ to a recent personal communication ) . In general the problem that has led to the development of " generative semantics " is that , in the words of Wardhaugh ( 1972 , p. 149 ) , " Feature notation leaves many problems unsolved , " including " that of specifying how the meanings of individual features and words somehow add up to produce the meanings of the total sentences . " One approach to this problem is to develop " semantic-projection " rules that would " provide semantic interpretations for syntactic structures into which meaning units had been inserted at some point or points " ( Wardhaugh , 1972 , p. 149 ) . The syntax would thus remain the central generative component of the grammar , while the semantic component would synthesize the meaning in much the same way that the phonological component can be said to provide the sound . The generative-semantic approach , on the other hand , // makes the semantic component the generative component and the syntactic component interpret , . Consequently , the deep structure of a sentence is a semantic structure rather than @ @ @ @ @ @ @ @ @ @ completely determined by the semantic structure . Wardhaugh , 1972 , pp. 149 ? 150 The generative-semantic approach , according to Wardhaugh ( 1972 ) , is intuitively attractive because , in addition to its various technical advantages , it takes into account the fact that what we put into sentence form are the meanings we wish to express , rather than the other way around . Chomsky ( 1972 , for example ) admits that his " standard theory " ( essentially represented by Chomsky , 1965 ) is inadequate and needs modification . But the necessary modifications , he feels , are included in his " extended standard theory . " Many of the differences that seem to exist between the extended standard theory and generative semantics are more apparent than real , as when the differences are basically terminological . Perhaps the " only fairly clear issue with empirical import that distinguishes these theories , " Chomsky ( 1972 ) suggests , " has to do with the ordering of lexical and nonlexical transformations " ( p. 136 ) . In essence , Chomsky is defending deep structure @ @ @ @ @ @ @ @ @ @ or bypassed . We can not here lay out the arguments in detail , but it is not likely that the classical generative grammar is going to be abandoned altogether . It is still useful even to the most avantgarde of the theoreticians , and even if it is an imperfect system , it is , at any rate , a complete one . Lakoff 's repeated challenges on the other hand do not comprise a complete system and Lakoff admits that many other kinds of rules must yet be formulated , prompting Chomsky ( 1972 ) to remark that " to say this is not to provide an alternative theory " ( p. 142 ) . // Finally , generative semantics seem now to be becoming engrossed with what Lakoff ( 1973 , for example ) calls " fuzzy grammar . " Philosophically , the concern is with the fact that things are rarely tidy . We define categories and describe their membership . But just as some blues are bluer than others , some men more masculine and some women more feminine than others , so , too , @ @ @ @ @ @ @ @ @ @ some sentences are more incontestably grammatical than others ( see Lakoff , 1972 ) . One of the lead scouts through the morass of fuzzy grammar is John Robert Ross , who has armed himself with a conceptual weapon that he calls a " squish " ( Ross , 1972 ) . In place of fixed , discrete syntactic categories , Ross posits quasi-continua ( squishes ) that include within a category space variable categories ( verb adjective noun ) that may even be quantifiable . That is , it may be possible to develop a measure of nounness or verbness , and so forth . To illustrate variability at the level of the sentence , we may take an example from Lakoff ( 1973 ) . In the eleven sentences that follow , all but the last would be grammatical if the adverb for time appeared at the end of the sentence . But if the adverb is preposed , Lakoff asserts , only a few of the sentences are clearly grammatical ( the first four , which lack an asterisk ) . The next sentence , which is marked @ @ @ @ @ @ @ @ @ @ but is fully aware of its fuzziness ; the one after that is marked by an asterisk , indicating that it is not grammatical , yet there is a residual uncertainty in his mind , so he has added a question mark . The remainder , all marked by asterisks , he finds clearly ungrammatical. a . Tomorrow John will leave . b . Tomorrow I think John will leave . c . Tomorrow Bill says he 'll be able to do your tax return . d . Tomorrow I know Bill will be in his office . c . ? Tomorrow I realize that Bill will be in his office . // ? *Tomorrow I found out that tax returns are due . *Tomorrow I 'm surprised that Bill will be in his office . *Tomorrow I believe the claim that Bill will be in his office . *Tomorrow John married Mary and will leave on his honeymoon . *Tomorrow I knew the girl who John will marry . *Tomorrow John will see Bill and the day after . The sentences are listed approximately in accordance with their degree of @ @ @ @ @ @ @ @ @ @ The last differs from the others in that the adverb can not come at the end either , but must be immediately in front of " and the day after " in order to be clearly grammati-cal . The discovery and formulation of rules to account for such variability seems likely to occupy the neogrammarians for some time to come , and their findings could enor-mously enhance our understanding of the relation between language and mind , even if they never generate a thor-oughly new theory of language . 9 Derived Systems Linguists consider language to be primarily a system of vocal communication , but it can be transposed into nonvocal forms in various ways . The transpositions may correspond rather closely to the spoken forms ; in our writing system , for example , we may say in a very general way that each graph ( letter ) corresponds to a sound , and the sequencing of the graphs corresponds to the sequencing of the sounds in the spoken form of the message . On the other hand , the transposition may be very global ; a signal may correspond @ @ @ @ @ @ @ @ @ @ to Paul Revere that one signal light would indicate that the British were approaching by land , while two lights would indicate that they were approaching by sea . One could argue against describing this sort of case as a transposition of language , but we shall keep the example as marking one extreme ( the other being , perhaps , a very precise phonetic transcription of a spoken message ) . Among the types of derived system to be discussed here are scripts , the manual communication system of the deaf , various kinds of secret language , " Pig Latins , " drum and 177 // whistle languages , and glossolalia , which is a kind of pseudolanguage . SCRIPTS The first attempts at graphic communication may have been of the global variety , rather than being isomorphic with spoken language . The magnificent cave paintings from the Upper Paleolithic period in Europe , which date from about ten to fifteen thousands years ago ( Clark , 1967 ) , imply very strongly that mimetic magic was used . The famous masked dancer known as The Sorcerer , for @ @ @ @ @ @ @ @ @ @ a deerhead mask , seems to be prancing in a ritual dance , which Hoebel ( 1972 , p. 187 ) compares with the Deer Dance that is performed today by Pueblo Indians . In the same vein , Clark ( 1967 ) looks to the Australian aborigines to show that primitive hunters seek an edge in survival and reproduction , and that art is used as a magical device to get that edge . Of course Upper Paleolithic art does not reflect language , but in the Near East , within a few thousand years , pictures had become pictograms , and had formed the basis for a true system of writing : what Trager ( 1972 ) describes as " any conventional system of marks or drawings or analogous artifacts which represents the utterances of a language as such p. 180 . " The oldest such system , so far as we know , was the cuneiform writing of the Sumerians , developed some five to six thousand years ago ( Trager , 1972 , p. 193 ) . The cuneiform messages consisted of wedge-shaped components that were formed @ @ @ @ @ @ @ @ @ @ 9.1 shows how pictograms ( at the top of each sequence ) developed into the cuneiform characters . The slightly more recent and perhaps independently invented Egyptian hieroglyphs ( Trager 1972 , p. 19 ) remained more obviously pictorial ( Figure 9.2 ) , and were painted onto surfaces , including paper ( papyrus ) , with a brush and ink . By four thousand years ago the Chinese were inscribing pictographic characters on bones for purposes of divination , and by the beginning of the Christian Era the Maya were inscribing and painting characters that were basically pictographic , but in                     