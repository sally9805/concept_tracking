@@432270

 | H ello , everyone , " comes a clear , somewhat laconic voice from a white box on the desk before me . " Let me introduce myself to you . I 'm DECtalk , a system for converting ordinary English text into understandable speech . My name is Paul . " I 'm sitting in an open , brightly lit room in Costa Mesa , Calif. , a regional office of Digital Equipment Corp. , makers of DECtalk . Kathy Sanden , a sales representative , then introduces the synthesized voices of Paul 's friends : Beautiful Betty , Huge Harry , Rough Rita , Kit the Kid , and several others . " Would you like to hear some of Paul 's songs ? " Sanden asks . She pushes a button , and a list of selections appears on a TV screen . After I pick " New York , New York , " Paul 's spirited but reedy rendering emerges from the box . Paul , I conclude , is no threat to Frank Sinatra . A few days later , I 'm @ @ @ @ @ @ @ @ @ @ , in Cambridge , Mass. , with the creator of DECtalk , Dennis Klatt . Klatt is a slim , gentle-looking man in his late 40s with a highpitched whispery voice . Ironically , having given computers the power of speech , he is slowly losing his own . " It 's like a trade with the devil , " he says . Klatt points to a rack of electronic speech-analysis equipment and a keyboard nearby . " This terminal allows me to type text directly into DECtalk , " he explains . I ask Klatt to demonstrate his improved version of Paul 's synthetic speech by having it recite " The Gettysburg Address . " As Klatt types , a voice from a loudspeaker be- gins , " Fourscore and seven years ago ... " The speech has the easy drawl of a New Englander ? a Yankee from Vermont , perhaps . But the words are a trifle more precise than speech you usually hear . It 's as though the synthesized speaker had attended prep school . The speech lacks the sense of life and feeling you hear @ @ @ @ @ @ @ @ @ @ computer had taken the typed text , broken it down into syllables , applied a number of pronunciation rules , and synthesized within its microchips a voice that might pass for human speech . DECtalk and the work of Dennis Klatt are part of a revolution in the way messages are received from computers . Instead of traditional video displays and paper printouts , realisticsounding speech-synthesis systems are being put to use . The new systems are based on built-in dictionaries and programs that reduce the deficiencies of older speech-synthesis techniques , which produced artificial , reedysounding voices . Human-sounding synthesis methods may also replace " canned " speech ? digitized recordings of human words . Emotional speech Text-to-speech technology like the $4,000 DECtalk ? actually a micro computer itself ? now lets computers read data and electronic messages over the telephone . ( Less-expensive text-tospeech devices perform this feat , too , but with less realism and more mispronunciations . ) And in the works are systems that will talk to you with the voice of a close friend or loved one , or simulate emotion in speech . Canned @ @ @ @ @ @ @ @ @ @ involve the most elementary parts of synthetic speech . Such messages involve digital speech recording and data compression . In a cassette recorder , audio is stored as a continuous analog signal . The wavy vibrations of speech are represented as wavy magnetic patterns on tape . Jr . digital recording , the amplitude of this wavy pattern is measured several thousand times per second . Each measured amplitude is then stored as a digit or number . These digits represent the original wave form , which when recreated can drive a speaker to produce the original sound with the fidelity of a fine stereo system . It is then easy to record the names of numbers , which can be strung together to compose a phone number or to store the text of a simple message Still , this calls for a lot of memory . To say " I love to eat pancakes in the morning " might require 150 kilobits o : data : This is because good-quality digital recording requires a great man , samples , or measurements , of the rapidly varying wave form . Thus @ @ @ @ @ @ @ @ @ @ finding the sounds of syllables within it . The key to finding those sounds is that while the wave form varies extremely rapidly , the syllables we speak vary far more slowly By determining the sound of the syllables , a computer can store and regenerate natural-sounding speech using 100 times less data . The computer has a chip that " listens " to the wave form , knowing that the sound it hears at any instant will remain unchanged @#  | ports on ski and weather conditions . And there is SPORTtalk , which gives up-to-the-minute scores from the professional leagues . The Shawmut Bank in Boston has recently made it easy for holders of corporate accounts to check their balances . With an appropriate user number and password , customers can dial a number and listen as the computer reads the status of their accounts . While Shawmut is pioneering this service , other banks may soon make it as common as automated tellers . Credit-card companies will probably be quick to follow . Yet another area for utilizing synthetic speech is electronic mail . Electronic mail sends written @ @ @ @ @ @ @ @ @ @ network , but there is a sort of Murphy 's Law here : Important messages inevitably arrive when you are not there to receive them . With synthesized speech added to such a system , however , users can tap into their messages from home , from an airport terminal , or from a pay phone on the road . The computer simply reads them over the telephone . Applications like these will likely make synthetic speech increasingly commonplace within the next few years as data bases proliferate , each as close as a phone . Stockbrokers will appreciate quick access to stock and commodities prices . Farmers will use systems like Grass Roots , offered by an Ontario firm , which gives current information on crops and fertilizers . Salespeople on the road will call the home office to check inventories and delivery dates . Customers waiting for an order to arrive will call in to check its status . Amid all these applications , a number of firms already are vying for the opportunity to develop advanced textto-speech systems based on Dennis Klatt 's work . The competition in @ @ @ @ @ @ @ @ @ @ . Indeed , there are already applications for which nothing but the best will do . " You would n't want to present DECtalk as a model for foreignlanguage learning , " says Glenn Akers of Kurzweil Applied Intelligence . " People would learn French with a DEC accent . " There are also voice-store-and-forward systems . These resemble electronic mail but deal with spoken and recorded messages rather than with text . Such systems can overcome " telephone tag , " in which one person phones another and the other is out ; when the second party returns the call , the first party is out . Instead , both parties can leave recorded messages in an electronic file that each can access with push-button codes from a phone , and thus can reach each other . But such systems require more than DECtalk or Calltext can offer . " Our customers demand a particularly high quality of voice , " says Judy Prokop of Voicemail Intl. , in Santa Clara , Calif. , which offers this service . " They want to feel that when they send a message @ @ @ @ @ @ @ @ @ @ across the line and not some synthesized voice . " Accordingly , Voicemail systems rely entirely on digitized recorded speech , which gives the highest possible quality . It calls for huge amounts of memory and data rates of 32,000 bits per second . Yet until better forms of speech compression come along that improve on LPC and formant synthesis , Voicemail will continue to rely on computer memory . Several paths lead in the direction of increasingly lifelike speech , with what Richard Jacks , inventor of Smoothtalker , calls " next-door-neighbor quality . " At Bell Laboratories , in Murray Hill , N.J. , Bishnu Atal , who directs the acoustic-research group , has high hopes for an improved speechmodeling procedure called multipulse LPC . " We get highly natural-sounding speech , " he says , " to the extent that most of the time you will not know the difference . " The multipulse-LPC technique emphasizes the rapidly changing features of such sounds as " b " and " p " ? features that are not readily captured with current methods . In Atal 's office I heard @ @ @ @ @ @ @ @ @ @ speech had been compressed using multipulse LPC , then reconstituted . The messages sounded like radio broadcasts : Their quality seemed excellent . Then , in a nearby office , speech researcher Joseph Olive showed me an experimental text-tospeech system featuring multipulse LPC . Again I typed in " The Gettysburg Address . " It took several minutes for his computer to digest the data , but the result , while throaty and low in pitch , carried more feeling than DECtalk 's Paul . While Paul sounded like a slightly bored professor , the experimental Bell system sounded like Edward R. Murrow 's wartime broadcasts by transatlantic shortwave radio . Though crackly and faint , an emotion showed through . Emotion in synthetic speech can result when a computer understands what it is saying . But true understanding is far away . " That research is in its infancy , " says Bell Lab 's Atal . " We do n't know the meaning of meaning . " Klatt agrees : " I ca n't find the most important word in a sentence . " Still , it has been @ @ @ @ @ @ @ @ @ @ Parsing a sentence means breaking it up into clauses , identifying nouns , verbs , and other parts of speech . Some of us remember this as the most boring part of high-school English , but it is a key element in the science of computer speech . While at Kurzweil Applied Intelligence , near Boston , I visited Richard Goldhor , a young linguist and one of the leaders in computer parsing . " Give me a sentence , " he urged . I responded with , " I saw the city while flying to Chicago . " Soon his computer screen blossomed with a diagram showing that sentence 's linguistic construction . " There 's more , " he warned . Indeed , beside that construction were six other parsings , based on using " while " as a verb or a noun , or " flying " as a gerund , as in " kite flying . " But the computer seemed aware that the commonsense parsing was the most likely one . With this sort of information , a computer can give modulation and intonation to a @ @ @ @ @ @ @ @ @ @ an exclamation point , or a rising inflection when there is a question mark . And it can pause briefly at the major clauses , its voice rising and falling in a natural way . All of this , of course , is a far cry from real feeling or emotion , but it is a definite step up from a robot 's flat monotone . " Parsing is absolutely necessary , " says Klatt . His DECtalk uses a version of such a system . Still another route to next-doorneighbor quality is for speech researchers to continue to plug away at the hard , nitty-gritty work that has carried them this far . As Klatt puts it . " Why does n't DECtalk sound more like my original voice , after years of my trying to make it do so ? According to the spectral comparisons , I 'm getting pretty close . But there 's something left that 's elusive , that I have n't been able to capture . It has been possible to introduce these details and to resynthesize a very good quality of voice . But @ @ @ @ @ @ @ @ @ @ can do it for any sentence ' ? that 's the step that 's failed miserably every time . " But he has hope : " It 's simply a question of finding the right model . "                     