@@773975

txt // subjects to reason about situations that might be considered theoretically impoverished . The other asks subjects to reason about situations that are theoretically rich but stipulates , operationally , that correct performance consists of ignoring ( or at least overriding ) theoretical considerations . This section focuses on those situations that are theoretically impoverished . Studies of formal-operational reasoning and many studies of causal reasoning are obviously relevant to the question of scientific thinking . At least when research is at a fairly advanced stage and the phenomena studied are sufficiently simple , scientists certainly rely on the strategy of varying one thing at a time while holding everything else constant ? the same strategy that guarantees success on a formal-operational task . And the motivation for following this strategy is to identify the causes of a phenomenon . However , the paradigm used in formal-operational studies and in most , though not all , studies of causal reasoning is based on a Humean model of causation and focuses almost exclusively on the use of covariation and on hypothesis testing of a fairly circumscribed sort . @ @ @ @ @ @ @ @ @ @ a formal-operational task , consider the " chemicals " task in which the subject has to discover which combination(s) of five odorless , colorless chemicals ( one of which acts as a bleach ) will produce a yellow liquid . Inhelder and Piaget ( 1958 ) explicitly intended that the formal-operational paradigm would model the hypotheticodeductive account of scientific inquiry ? an empiricist rational reconstruction in which scientific inquiry is described in terms of the Humean principles of causation . In keeping with Inhelder and Piaget 's aim , the formaloperational task is structured so that the causal chemicals are those that covary with the effect . As another example of a causal-reasoning task , consider Shultz and Mendelson 's ( 1974 ) study in which a child had to decide whether it was pulling one or another lever that caused a light to come on . Again , the task was structured so that the cause was the event that covaried with the effect . That is , in both approaches , causation was operationalized in Humean terms , as being equivalent to covariation . Because of the emphasis on @ @ @ @ @ @ @ @ @ @ the other types of information relevant to making causal judgments do not play a role . The most salient example of this is that questions of mechanism do not arise . Since the chemicals are all both odorless and colorless , it is not possible to identify them . And even if it were , it would make little difference , as children typically have very little knowledge of mechanisms by which most chemicals operate . Nor do most children at this age have knowledge of mechanisms that might mediate between pulling a lever and having a light come on . // The role of alternative hypotheses is ignored Furthermore , in both situations , the role of alternative hypotheses is also not explored in any depth . The sense in which alternative accounts or causes are considered is that if one of the factors ( one set of chemicals , one of the levers ) does not covary with the desired effect , then correct performance consists of checking an alternative factor . There is no attempt to examine whether the subject considers alternatives that are plausible and this relates @ @ @ @ @ @ @ @ @ @ included in the set The tasks are contrived so that the actual cause is definitely included in the set of factors presented to the subject . There is thus no way of using this sort of situation to examine how subjects decide , in the first place , whether a particular factor ought to be included in the set of potential causes . When a cancer researcher tries to identify possible cures , for example , there is no one waiting in the wings who tells her that the actual cure can definitely be found in a particular set of possibilities . Potential causes in the set are stipulated to be equally plausible Related to the preceding point is the fact that the tasks are structured so that the possible causal factors included in the set of possible causes are all , at the outset , equally likely . Therefore , there is no way of using this paradigm to study how causal judgments are affected by whether the possible causes are plausible or implausible , standard or nonstandard instances . That such considerations do ( and should ) matter when @ @ @ @ @ @ @ @ @ @ about medical diagnosis . Not all possible causes of persistent headaches are ( or should be treated as ) either standard or plausible . For example , it is usual to investigate brain tumors as a cause of headache only after sinus infections , a need for eyeglasses , stress , etc. , have all first been eliminated as possible causes . In short , many studies of formal-operational and causal reasoning simply bypass questions of mechanism , alternative hypotheses , and the differential plausibility of possible causal factors . This is not to say that the research just discussed tells us nothing about causal reasoning . It is very relevant , for example , to situations in which the mechanisms that are operating are unknown ? as happens when one is , for example , trying to figure out the dash knobs of an unfamiliar foreign car or trying to discover which settings of which knobs will improve the picture on a TV screen when any guess is as good as any other guess and even though one does not understand the mechanism by which turning a particular knob will @ @ @ @ @ @ @ @ @ @ doing so in a systematic , combinatorial way is a good way of keeping track of which // tests have been carried out ; it makes for good bookkeeping . Similarly , if all the plausible hypotheses to explain a phenomenon have been ruled out and one is left with no other theoretical considerations to guide further research , then an investigation of whatever factors ( however implausible ) happen to covary with the phenomenon is often the only option left . ( This happens , for example , when the Center for Disease Control has ruled out all plausible known causes of a set of symptoms and must investigate factors that covary with the symptoms in order to discover a disease that has not yet been identified . ) However , the limitation of this research is that it does not inform us about causal reasoning in situations in which a subject does have beliefs ? even incomplete beliefs ? about underlying mechanisms or the differential plausibility of possible causal factors . A formal-operational subject , for example , who correctly systematically tests all combinations in the chemicals task might @ @ @ @ @ @ @ @ @ @ task in which there are mechanisms known to be operating for some of the relevant factors but not for others . More on this below . The tasks emphasize hypothesis rejection rather than modification Finally , one way of conceptualizing these tasks is as involving a series of hypotheses that the subject tests regarding which of the possible causal factors ( or , in the case of the chemicals task , which subset of factors ) is the actual causal factor . However , two features of these tasks result in an emphasis on hypotheses testing to the exclusion of hypothesis modification or articulation . One is that , given the way the tasks are designed , the hypotheses can be limited to a fairly small set , and each hypothesis can be formulated in a way that is very precise and thus very circumscribed . Specifically , each hypothesis is that a particular set of chemicals will produce the desired effect . This is in contrast to many noncontrived situations in which it is a fairly imprecise or working hypothesis that one starts out with ( for example , that @ @ @ @ @ @ @ @ @ @ precise dosage required or the particular types of infections and populations for which it is effective ) . The second feature of these tasks , in terms of hypothesis testing , is that they are contrived so that there is one factor ( for example , a set of chemicals ) among a fairly small set of factors with which the data are perfectly congruent . Thus , in formal-operational and causal reasoning tasks , when a hypothesis ( for example , that chemicals 1 , 2 , and 3 produce a yellow liquid ) is met with noncongruent or disconfirming data , there is no incentive to treat the data as mere anomalies that warrant modifying the hypothesis in order to accommodate them . Rather , because there is one hypothesis with which all of the data are perfectly congruent , correct performance consists of treating noncongruent data as though they were disconfirming rather than merely anomalous and of continuing to search for that // hypothesis ( for example , chemicals 1 , 2 , and 4 ) with which the data are perfectly in accord . That is , @ @ @ @ @ @ @ @ @ @ tasks are contrived so that correct performance does not require the problem solver to engage in hypothesis modification . Again , by way of contrast , in many noncontrived situations , when a working hypothesis meets with noncongruent data , one can often treat the data as merely anomalous and modify the hypothesis ( rather than altogether reject it ) to take account of that data . For example , if drug x does not cure colds in the elderly , the working hypothesis that x is effective can be modified to state that drug x is effective but not in the elderly . Anomalies , modification , and working hypotheses will be discussed in more detail in chapter 3 . Briefly , though , I would like to reiterate my earlier point that there certainly are causal situations for which the research paradigm just discussed provides an accurate model of reasoning . In the TV case , for example , there is one set of knob positions that provides the best picture , and the appropriate response to a fuzzy picture is certainly to reject an unsatisfactory set of knob @ @ @ @ @ @ @ @ @ @ in many cases of hypothesis testing , especially when the hypothesis is a working hypothesis , anomalous data call for modification , rather than outright rejection of the hypothesis . And the decision about whether to modify or reject is often influenced by beliefs about what mechanisms are bringing about the anomalies . Therefore , a subject who rejects a hypothesis in the face of anomalous data in the experiments just described might ( appropriately ) do something quite different in a situation in which there is a mechanism that can explain how the anomalies came to be . Thus , studying causal reasoning in the former situation might provide a distorted picture of what causal reasoning would ( and should ) look like in the latter situation . More on this in chapter 3 . There is a sense in which hypothesis modification is examined in this research : in some studies of causal reasoning , the factor stipulated to be the causal factor covaries only imperfectly with the effect ( for example , Siegler 1975 ) . Therefore , there are some instances that , in a sense , @ @ @ @ @ @ @ @ @ @ , in these instances , although the causal factor is present , the effect is not . However , the strategy stipulated to be the correct way of dealing with these instances is to conclude that the target factor is necessary but not sufficient , without any concern for identifying what the anomalous instances have in common or what the mechanisms are that make the factor bring about the event in some situations but not in others . There is certainly a step in scientific problem solving when a judgment that a cause is necessary but not sufficient is the only appropriate response to the data available . When , for example , a new virus is discovered and little is known about it , a probabilistic estimate that it is fatal // in a certain percentage of cases might be the best ( and only ) conclusion possible . However , even in such cases the next response is typically to try to understand why the virus is fatal in some cases but not in others . ( At the very least , the next response is to try to @ @ @ @ @ @ @ @ @ @ fatal from those in which it is not in the hope that doing so will provide a clue to what the underlying mechanism might be that makes it deadly in some cases and not in others . ) That is , how probabilistic hypotheses are evaluated ? whether they are treated as reflections of random " noise " or as helping to refine our understanding of when the target cause does or does not operate ? often depends on information about mechanism . Therefore , studies of how subjects evaluate probabilistic covariation when mechanism information is absent might provide a misleading model of how subjects evaluate anomalies when information about mechanism is available . This point will be addressed in more detail in chapter 3 and in experiment 11 . In short , in many formal-operational and causal reasoning tasks , causation is stipulated to be equivalent to covariation with little attention paid to the roles of mechanism , anomalies , and alternative theories or hypotheses . Indeed , the tasks are designed to present situations that are theoretically impoverished so that questions of theory or mechanism can not arise . @ @ @ @ @ @ @ @ @ @ are designed to be either conclusively confirmed or disconfirmed because anomalous data are designed to be disconfirming ; the tasks are not designed so that anomalous data call for working hypotheses to be modified rather than rejected . The result is that there is a focus on hypothesis testing to the exclusion of hypothesis modification or articulation . These tasks undoubtedly provide us with information about causal reasoning in situations in which plausible hypotheses to explain a phenomenon either do not exist or have been ruled out . However , they might well provide misleading expectations of how people reason in situations in which information about mechanism is available . Hypothesis Testing or Rule Discovery The literature on hypothesis testing or rule discovery is also relevant to the issue of scientific thinking because the tasks used in such research typically involve identifying the properties of a set of stimuli or discovering what the effects are that covary with a particular cause . However , neither type of task is aimed at examining subjects ' beliefs about mechanism . For example , Wason 's ( 1960 ) task asks subjects to identify @ @ @ @ @ @ @ @ @ @ 6 . Questions of mechanism do not arise in this sort of task . Tasks used by Klahr and his associates ( e.g. , Klahr and Dunbar 1988 ; Klahr , Dunbar , and Fay 1990 ) require the subject to disThe // cover what the function is of a particular key or command on a computer device . Again , since the subjects are expected to know not how the key brings about a particular outcome but merely what the outcome is , these tasks also do not examine the role of mechanism . ( However , some of Klahr 's tasks do examine the role of alternative hypotheses , and this aspect of his tasks will be discussed below . In addition , rule-discovery tasks do , in some sense , deal with the issue of subjects ' alternative hypotheses . This feature of the tasks will be discussed in chapter 3 . ) Existing Research on Information about Causal Mechanism and Alternative Accounts As mentioned earlier , there have been some exceptions in the causalreasoning literature that did examine young children 's beliefs about causal mechanism . Recent @ @ @ @ @ @ @ @ @ @ 1972 ) work with young children . Using as data children 's verbal explanations for various natural phenomena ( such as the phases of the moon ) and mechanical events ( such as the working of bicycles and steam engines ) , Piaget concluded that young children were either indifferent to causal mechanism or actually held the false belief that intervening mechanisms were not necessary , that is , that action at a distance is possible . Using less complicated tasks than the ones Piaget had used , several researchers ( Bullock et al . 1982 ; Koslowski , Spilton , and Snipper 1981 ; Shultz 1982 ) have found that , contrary to what Piaget had concluded , even four- and five-year-olds spontaneously invoke possible causal mechanisms when explaining how an apparatus works . That is , in at least some situations , children are neither indifferent to considerations of mechanism nor do they hold a false belief in action at a distance . For obvious reasons , the tasks used to study the causal reasoning of children have been fairly simple and concrete . In contrast , the research @ @ @ @ @ @ @ @ @ @ situations involving more abstract , verbal problems . Furthermore , in much recent research , because the emphasis was on considerations of whether mechanism information played any role at all in the causal reasoning of children , there was little attention to how mechanism information was evaluated when it was combined with ( or pitted against ) other causal information ( in contrast to the present experiments ) . However , there are two studies relevant to this question . One , by Mendelson and Shultz ( 1976 ) , found that when a visible connection was absent between a putative causal agent and its effect , children were likely to rely on temporal contiguity rather than on regularity of cooccurrence . However , when a visible connection was present , regularity // played a greater role . The authors suggested that a visible connection provides a rationale for ( or , in terms of the present discussion , a mechanism that can explain ) a fairly long temporal delay so that when the connection is present , children are more likely to take regularity into account . The other study @ @ @ @ @ @ @ @ @ @ mechanism information conflicts with information about covariation , even children as young as three years of age accord more importance to the former than to the latter . Studies of causal reasoning among adults have used more abstract , verbal problems and have also found that considerations based on mechanism often override or interfere with the conclusions suggested by a strict reliance on covariation . For example , in their classic study of illusory correlations , Chapman and Chapman showed undergraduates a series of " drawings , each drawing being arbitrarily paired with contrived statements about the symptoms of the alleged patient who drew it " ( 1967 , 194 ) . The subjects ' task was to discover which kinds of drawings were made by patients with each symptom . Even when there was no correlation , subjects reported having observed one , and their " observations " of " illusory correlations " corresponded to ( independently assessed ) prior beliefs ( or , in terms of the present discussion , rudimentary theories ) , such as that a man worried about how manly he is would draw a picture @ @ @ @ @ @ @ @ @ @ and Medin ( 1985 ) make an analogous argument when they discuss the role of covariation in concepts . They point out that the world is rife with correlations , many of which are artifactual or based on an arbitrary cutting up of the world . To account for why we look only for some correlations and take them seriously when we find them , an account of concepts and categories must acknowledge the role that theories play . We search for and take seriously only some correlations precisely because it is these correlations that we have theoretical ( or causal mechanistic ) reasons for believing to be important . Finally , Tversky and Kahneman ( 1974 ) , as well as Nisbett and Ross ( 1980 ) , demonstrate that our ability to apply various statistical principles can be overridden by prior beliefs in the form of causal theories . For example , if told that Steve is shy and withdrawn , invariably helpful , but with little interest in people or the world , and that he has a need for order and structure and a passion for detail @ @ @ @ @ @ @ @ @ @ a librarian than a salesman , even if given the base-rate information that the group he is in consists of 30 librarians and 70 salesmen . Presumably , we override the base-rate information because we believe that certain personality variables are one of the causal mechanisms by which various career choices are made . Worth noting at this point is that in some of the work just discussed ( for example , Chapman and Chapman 1967 and Kahneman and Tversky // 1974 ) , the reliance on explanation or theory is treated as a flaw in the reasoning process . In contrast , one of the arguments being made here is that a reliance on explanation or theory is legitimate . By way of illustration , consider a variant of the Kahneman and Tversky example . Imagine learning that 1 percent of the U.S. population is infected with the AIDS virus . Imagine now being told that John has , for some time , been a casual user of intravenous drugs and frequently shares needles , lives in the Hell 's Kitchen section of New York , and often works as @ @ @ @ @ @ @ @ @ @ us would ignore national baserate information in this case as well and infer that John is more likely than members of the general U.S. population to be infected precisely because we have some beliefs about the mechanism by which AIDS is transmitted . And I would also argue that in this case , overriding base-rate information with background beliefs is scientifically legitimate . A public health officer who inferred , on the basis of the base-rate information , that there was a 1 percent chance that John had AIDS would be medically irresponsible . The background beliefs make a causal suggestion that John was drawn from a different population than the one for which the baserate data are appropriate . Similarly , in Kahneman and Tversky 's example concerning whether John is a librarian or a salesman , I would argue that the problem is not that subjects were ignoring or overriding base-rate information because of their causal theories . The problem may have been that the subjects were not sufficiently skeptical about the causal theories they held , but this is a separate issue . And in any case , @ @ @ @ @ @ @ @ @ @ actually call their theories into question . The question of whether reliance on theory is legitimate or mistaken is not trivial , because it is relevant to how one can teach people to be more rigorous in their thinking . If the problem is that people are ignoring the principles of statistical inference in favor of causal theories , then the solution should be to teach them more statistics . However , if , as I have argued , the problem is not that people are relying on causal theories but rather that people are not being sufficiently skeptical of or informed about whether their theories are correct , then the solution is to teach them more about their theories , such as its limitations , alternatives to it , etc . The possible advantages of skepticism aside , the point I am making is that the practice of ignoring causal theories in favor of base-rate information about a general population is not always a reasonable approach ; tasks that stipulate that such an approach should be used may provide us with an inaccurate picture of how people reason in situations @ @ @ @ @ @ @ @ @ @ ( Of course , the illusory correlations observed by Chapman and Chapman 's subjects are , indeed , a reflection of flawed thinking . More on this in chapter 3. ) // Scientific Reasoning Scientific Reasoning as Conceptual Change In terms of recent research , there have been two major approaches to the study of scientific reasoning . One has looked at the sort of conceptual reorganization that takes place ( historically as well as ontogenetically ) as people acquire more knowledge about a scientific construct such as aliveness ( Carey 1985 ) , heat and temperature ( Wiser 1987 ) , dinosaurs ( Chi and Koeske 1983 ) , physics ( Chi 1992 ; Chi , Feltovich , and Glaser 1981 ; McCloskey 1983a , 1983b ; etc . ) . In this approach , one of the issues is whether or not the kind of reorganization that takes place involves the sort of radical restructuring analogous to what T. S. Kuhn has called a " paradigm shift . " A second issue is the related one of the extent to which people 's naive conceptions parallel the conceptions that @ @ @ @ @ @ @ @ @ @ , the issues addressed in the conceptual-change literature complement the questions addressed here . However , they intersect with my questions in several ways . First , they emphasize the importance of theoretical frameworks in organizing data , and this is continuous with my interest in the importance of causal mechanism in scientific reasoning . Second , in drawing attention to the role of knowledge in scientific reasoning , the research on conceptual change makes the same point made in experiments 3 , 4 , and 5 , namely that one 's knowledge about a domain may affect the methodological import of the principles one uses to reason about it . For example , consider the principle that x becomes less likely to have caused y if one can find no evidence for any of the mechanisms by which x might ( plausibly ) have brought y about . This principle might be difficult to rely on if one does not have the knowledge base to identify what the plausible mechanisms are likely to include . Finally , just as one can ask about conceptual change whether it involves radical restructuring @ @ @ @ @ @ @ @ @ @ that people employ undergoes an analogous shift with age . That is , one can ask whether people of different ages employ qualitatively distinct strategies for generating , testing , and refining hypotheses . Scientific Reasoning as the Application of Principles for Assessing Evidence The second major approach to the study of scientific reasoning has examined the principles or strategies that people use in generating and testing hypotheses . The formal-operational approach of Inhelder and Piaget ( 1958 ) , explicitly intended to model the hypotheticodeductive account of // scientific inquiry , is based on the role of Humean indices and has already been discussed . Recall that this research examined scientific reasoning by relying on task situations that might be described as theoretically impoverished . In this section my focus will be on tasks that are theoretically rich but in which correct performance has been stipulated to consist of ignoring or overriding considerations of theory or mechanism . The work of D. Kuhn et al . In recent work , one of the most significant contributions to research on scientific thinking has been made by Kuhn , Amsel , and @ @ @ @ @ @ @ @ @ @ two respects : It is a systematic body of research that addresses in a clear and precise way the important question of how a subject 's existing theories are reconciled with new evidence . Furthermore , like all thoughtful research , Kuhn et al . ' s work raises at least as many questions as it answers and is therefore significant in this respect as well . Research and conclusions Kuhn and her colleagues used several tasks to study subjects ' ability to coordinate theory and evidence . In one of the tasks , Kuhn et al . began with hypotheses that they had asked subjects to generate about , for example , whether eating one type of food rather than another would make children more or less likely to catch cold . Kuhn et al . ' s emphasis was on the way in which subjects would deal with subsequent information that either confirmed or disconfirmed one of their hypotheses . ( In describing their research , I will use the terms " confirmed " and " disconfirmed " because these are the terms the researchers themselves used in describing @ @ @ @ @ @ @ @ @ @ I will later argue that in many cases subjects were behaving in a scientifically legitimate way when they treated the " disconfirming " evidence as merely anomalous data that called for modification , not rejection , of the hypotheses they were evaluating . ) For each subject , the experimenters identified two causal variables , for example , type of potato ( fried versus baked ) and type of cereal ( granola versus Special K ) that the subject believed would have an effect on colds and two noncausal variables that the subject believed would not affect childrens ' likelihood of catching cold . Then the subject 's beliefs about one causal variable ( for example , type of potato ) and one noncausal variable ( for example , type of juice ) were confirmed , while her beliefs about the other causal and the other noncausal variable were disconfirmed . In all cases , confirmation and disconfirmation consisted of presenting the subject with evidence that , in a particular school population , the target variable either did or did not covary with the effect . ( For example , in @ @ @ @ @ @ @ @ @ @ eating chocolate cake rather than carrot cake caused more colds would be shown evidence that children who ate carrot cake were just as likely to get colds as children who ate chocolate cake . ) In short , the only type of information presented to the subject was information that a variable did or did not covary with an effect . In another task , subjects were asked to identify what it was that made some sports balls bounceable and others not . Subjects were presented with four variables ( size , color , texture , and presence or absence of ridges ) . The focus of the study was on two variables : the one the subject had identified as making the most difference and the one the subject had identified as making the least ( or no ) difference . ( For future reference , it is worth noting that color was explicitly included to make it likely that one of the variables would be seen as noncausal , and in fact " most " subjects selected color as the variable least likely to make a difference . ) @ @ @ @ @ @ @ @ @ @ to generate evidence that would support their own theory and also to generate evidence that would support someone else 's conflicting theory . Subjects did this by arranging the sports balls in two baskets ( labeled " good serve " and " bad serve " ) . That is , they demonstrated how the factors would covary with type of serve if each of the two theories were true . Subjects were also asked to justify the arrangements they proposed . In another part of the task , half the subjects were presented with evidence that the two variables ( the one chosen as most likely , and the one chosen as least likely , to be causal ) did covary with the effect , and half were shown evidence that the two variables and the effect did not covary . Again they were asked to evaluate the evidence . In yet another task , subjects were asked to articulate their causal theories about , for example , why children fail in school or why prisoners return to crime upon being released from prison . Subjects were then asked various questions @ @ @ @ @ @ @ @ @ @ your view is right , what evidence would you give to try to show this ? " ) designed to tap their beliefs about what would constitute evidence for their theories . Because many of Kuhn et al . ' s tasks dealt with disconfirming information ( or , on my view , anomalous information ) , their research will also be discussed , again in chapter 3 . Yet it is relevant to this chapter for several reasons : One is that it illustrates my claim that in most studies of scientific thinking ( as in most studies of causal reasoning ) , causation is operationalized as equivalent to covariation and correct performance consists of ignoring , or at least overriding , considerations of theory or mechanism . Another reason it is relevant to this chapter is that it provides an example supporting the argument , made earlier , that an empiricist emphasis that operationally reduces causation to covariation ( often to the exclusion of other information ) can lead to a distorted picture of subjects ' reasoning in // situations in which mechanism information is available . A third @ @ @ @ @ @ @ @ @ @ conclusions about people 's ability to engage in scientific thinking , and these conclusions have provoked studies designed to examine the extent to which the conclusions can be generalized . The most basic conclusion is that at all ages , but especially among younger subjects , there is a fairly robust inability to coordinate theory and evidence . Furthermore , this inability is intertwined with a metacognitive inability to think about theories rather than with them . According to Kuhn et al. , the general inability to distinguish theory and evidence is reflected in several ways in the tasks just described . For example , after subjects generated evidence to support either their own or a conflicting theory , they frequently provided a theory-based response , rather than a response based on covariation evidence , to explain why the evidence supported the theory . Indeed , this was true even when subjects were justifying an arrangement generated to support a theory that conflicted with theirs . For example , when a ninth-grader was asked to generate evidence to show that her theory ( that texture affects bounceability ) was correct , @ @ @ @ @ @ @ @ @ @ good serve " basket and rough balls in the " bad serve " basket . When asked to explain how this evidence supported the theory , she responded , " The rough texture will make the ball heavier , so it wo n't go so far when hit " ( Kuhn et al . 1988 , 170 ) . In explaining why this subject mentioned only theory and not evidence in her justification , Kuhn et al . note , " We can assume that it is her lack of a firm differentiation between theory and evidence that prevented her from acknowledging explicitly the meaning of covariation evidence , though she obviously had some appreciation of its meaning " ( 1988 , 270 ) . In the " foods " task also , subjects ' justifications often made no reference to evidence , by which D. Kuhn et al . meant information about covariation . For example , many of the theory-based responses , instead of citing evidence of covariation ( or noncovariation ) cited evidence based on , among other things , " some mechanism connecting cause and effect " @ @ @ @ @ @ @ @ @ @ based on mechanism was provided by a subject who explained that type of cake makes a difference : " Carrot cake has ... is made with carrots , and chocolate cake is made with a lot of sugar . But this carrot cake is made with some sugar too , but it 's made with less sugar .... Less sugar means you do n't ... your blood pressure does n't go up . It makes a difference " ( Kuhn et al . 1988 , 78-79 ) . An example of intuition occurred when a subject explained that the kind of breakfast roll does not make a difference " because the breakfast rolls are pretty much the same thing . The only thing , they taste differently , but they are made the same way , they have the same thing ? dough ; they // have to mix " ( Kuhn et al . 1988 , 73 ) . ( If this example is representative , I would argue that some examples of intuition might also have been based on considerations of mechanism : One could interpret this example as @ @ @ @ @ @ @ @ @ @ same ingredients , there is no mechanism by which the different rolls could have produced different outcomes . ) In short , according to Kuhn et al. , in many cases , subjects ' justifications were based on theory , not evidence , because subjects could not distinguish theory and evidence . In contrast , consider some of the examples that Kuhn et al . cite of valid reasoning : " No , because the tomato soup is with healthy children here and sick children here . " " Some children with colds had tap water , and some had bottled water , so it makes no difference " ( Kuhn et al . 1988 , 58 ) . Kuhn et al . argue that in examples of valid reasoning , theory and evidence were treated as independent , and evidence was used to evaluate theory . As can be seen from the examples , this meant that in examples of valid reasoning , subjects cited covariation evidence to support their theories or to call them into question . Furthermore , in Kuhn et al . ' s tasks , in @ @ @ @ @ @ @ @ @ @ is , justifications that mentioned covariation ) , and there were theory-based responses , even when the instructions explicitly called for the former . For example , in one of the studies , subjects were explicitly told " to consider only the information that the scientists collected , " " to answer the question not from what you know about foods , but based only on the scientists ' findings " ( Kuhn et al . 1988 , 51 ) . And although such instructions made the sixth-graders produce more evidence-based responses , the difference was not statistically significant . According to Kuhn ( 1989 ) , another example of people 's inability to distinguish theory from evidence is that , when asked explicitly to provide evidence for a belief , even adults often merely elaborated the belief , providing a causal script of " how it happens . " For example , asked to answer the question of what causes prisoners to return to a life of crime , one subject cited a combination of leniency in the judicial system and overcrowding : " I think some of our laws @ @ @ @ @ @ @ @ @ @ face it , today some of them even commit murder , and they are out on the street the next day . Plus , they 've got the overcrowding in the prisons , and I do n't think ? well , in some places , they are letting them out before their time " ( Kuhn 1989 , 683 ) . When asked to provide evidence , this subject merely elaborated his script : " The judges and a lot of them , I do n't think they give them the full amount in sentencing " ( Kuhn 1989 , 683 ) . After further probing , the subject suggested that a survey of prisons could be taken to show that they were indeed overcrowded . Even here , the proposed-survey evidence was directed toward supporting the script // of how it happens , rather than toward providing evidence that certain factors such as overcrowding covary with returning to a life of crime . According to D. Kuhn et al. , people 's inability to distinguish theory from evidence is also reflected in the fact that people are not troubled by @ @ @ @ @ @ @ @ @ @ , one subject who had antecedently identified texture as likely to affect a ball 's bounce and color as likely to be irrelevant was then shown a situation in which texture and color were confounded so that both covaried with bounceability . When this happened , the subject was quite content to identify texture as the cause and to ignore color . According to D. Kuhn et al. , the subject did not realize that , given that texture and color both covaried , the actual cause was indeterminate . In a word , according to Kuhn et al. , subjects failed to consider ( and rule out ) alternative hypotheses . Furthermore , according to Kuhn et al. , the lack of attention to issues of confounding and control was also apparent when subjects generated evidence on their own . They write , for example , " The major source of error in the generation of covariation evidence , however , was the failure to recognize the potential effects of other variables and the need to control them in order to produce a valid demonstration " ( 1988 , 181 @ @ @ @ @ @ @ @ @ @ meant , according to Kuhn et al. , that " subjects had less difficulty generating covariation evidence to demonstrate the correctness of a causal theory than they did generating noncovariation evidence to demonstrate the incorrectness of a causal theory " ( 1988 , 180-181 ) . Kuhn et al . also note two additional ways in which the inability to distinguish theory and evidence makes it difficult for subjects to deal with disconfirming or anomalous data . One is that , even when subjects did refer to evidence , to preserve theory they often adjusted the evidence to fit the theory , pointing out the number of times that , for example , mustard did co-occur with colds but ignoring the instances in which mustard co-occurred with no colds . Conversely , subjects also often adjusted their theory to fit the data , claiming that the theory in question " was right with respect to those instances that conformed to the covariation pattern but was wrong with respect to those instances that did not " ( Kuhn et al. , 1988 , 126 ) . According to Kuhn et al. , @ @ @ @ @ @ @ @ @ @ and evidence affects the evaluation of disconfirming data is that , in the face of disconfirming evidence , subjects have more difficulty relinquishing a causal than a noncausal belief . Presumably , when the disconfirming evidence is directed toward a causal belief , the subject can not distinguish the disconfirming evidence ( which shows that the causal relation is absent ) from the theoretical belief that the causal relation ought to he present . // In short , according to D. Kuhn et al. , flawed scientific reasoning is present at all ages ( although it is more pronounced in younger subjects and is also affected by educational level ) and is realized in a number of situations . An alternative interpretation In light of the conclusions just described , consider three of the points raised earlier . First , it is clear that Kuhn et al . ' s work exemplifies an approach in which causation is operationally defined in terms of covariation . This is not to say that causation is explicitly stated to be equivalent to covariation ( or not equivalent , for that matter ) ; it @ @ @ @ @ @ @ @ @ @ to use when assessing causation consist of assessing covariation . The tasks are structured so that what it means for type of cake to cause colds is that type of cake covaries with colds . The second point is that when subjects cite mechanism or theory rather than covariation as evidence , their answer is treated as flawed , as a way in which " theoretical belief compromises both generation and evaluation of evidence " ( Kuhn et al . 1988 , 183 ) , and this relates to the third point . The third point I will defend is that reducing causation to covariation provides a misleading description of the situations in which subjects ' judgments deviate from good scientific practice . In the present section , I will discuss some of the specific findings in Kuhn et al . ' s work by way of arguing that very often the subjects ' behavior was scientifically reasonable , because relying on mechanism or theory is reasonable . I will then consider a possible rejoinder , namely that the subjects ' reliance on their beliefs about mechanism was not reasonable , @ @ @ @ @ @ @ @ @ @ about theory or mechanism and , in particular , did not use covariation information to test those beliefs , even when told explicitly " to answer the question ... based only on the scientists ' findings . " Next I will suggest some flaws that were present in the subjects ' thinking but that did not involve relying on theory in a way that interfered with the coordination of theory and evidence . I will then argue that , although it is reasonable to take some correlations more seriously than others , it does not always make sense to ignore correlations that are implausible . Briefly , my argument is this : Subjects ' behavior in many of Kuhn et al . ' s tasks was reasonable because theory or mechanism can be evidential ; the presence of a plausible mechanism that could have mediated between a factor and a correlated event actually functions as some evidence that the correlation might be causal . ( It counts as some evidence that Jones died from being treated with penicillin that she had an allergy to molds , because the allergy demonstrates that @ @ @ @ @ @ @ @ @ @ have been fatal . ) In addition , in the face of anomalous data , it is sometimes reasonable to treat a theory as a working hypothesis to be revised rather than rejected , and it is reasonable precisely because of considerations of theory or mechanism . In the Kuhn et al . ' s tasks , subjects treated theory and data as mutually interdependent ; they brought their theories to the experimental situation and relied on them in assessing covariation evidence . And Kuhn et al . point this out . However , there are two differences between their approach and the approach defended here . One is that Kuhn et al . treat theory or mechanism information as being quite distinct from , and inferior to , evidence that consists of covariation . The other is that Kuhn et al . treat subjects ' reliance on theory to evaluate data as an example of flawed reasoning ; it is citing covariation information that is treated as good thinking . In contrast , my approach is that treating background theory or mechanism information as evidentially relevant is scientifically legitimate ( @ @ @ @ @ @ @ @ @ @ ) . On my view , the subjects ' reasoning may well have been flawed , but the flaw was not that subjects relied on theory or mechanism as well as on covariation . Indeed , rational scientific standards for taking covariation information into account require that one consider mechanism or theory when possible . The contrast between the approaches provides an alternative interpretation of some of Kuhn et al . ' s results . Consider first cases in which the subject was asked to arrange covariation evidence and then to justify the arrangement . For example , consider the ninth-grader who responded to the request for evidence that texture affects bouncability by explicitly putting all the smooth balls in the " good serve " basket and all the rough ones in the " bad serve " basket and who then justified her arrangement with the theory-based explanation that the rough texture makes the balls heavier . Admittedly , the subject did not explicitly describe the covariation evidence , but rather than showing a lack of metacognitive awareness , the subject 's justification may instead have reflected the view that since @ @ @ @ @ @ @ @ @ @ the balls in the appropriate baskets ) , she would now provide additional evidence by describing the mechanism by which the covariation might be causal . ( Note also that on this view there is a sense in which the subjects in the sports-balls study had a remarkably robust understanding of how to evaluate causal relations : not only were they able to generate the appropriate covariation to support a theory that conflicted with their own , but they were also able to provide theorybased explanations for theories that conflicted with theirs . Again , this will be discussed , in the following chapter on disconfirmation . ) Conversely , when a subject points out that two types of " breakfast rolls are pretty much the same thing , " she could easily be construed as voicing the belief that there is no mechanism that could account for how bread // could make a difference . ( Indeed , in experiment 13 below , several of our subjects gave the explanation that " milk is just milk " and therefore could n't affect sleep . However , they frequently elaborated this @ @ @ @ @ @ @ @ @ @ types of milk except for fat , and fat does n't make it hard to sleep , " that is , does not constitute a causal mechanism . ) In a word , subjects were relying on beliefs about mechanism , which they had acquired before entering the experimental situation , just as scientists ( appropriately ) continue to rely on their accumulated knowledge when they enter their own laboratories . In evaluating Kuhn et al . ' s work , it is important to note that they claim not that subjects do not cite evidence but rather that subjects do not cite covariation evidence . However , what is also clear is that the tendency not to cite covariation evidence is treated as flawed reasoning . What I am arguing is that , at least in this regard , the subjects ' reasoning is not flawed , because what subjects are doing is relying on information about mechanism to explain why they are taking some covariations seriously while dismissing others and this is a scientifically legitimate thing to do . ( It is worth noting that graduate students were less @ @ @ @ @ @ @ @ @ @ suggest that this is because they were more test-wise in realizing that the rules of the experimental situation called for them to suspend their beliefs about mechanism , which they certainly would have relied on in a noncontrived situation . ) A skeptical rebuttal and a rejoinder Turn now to the question of subjects ' skepticism . The obvious rebuttal to the argument that subjects were reasonable in treating mechanism information as evidential is that , had the subjects been engaging in good scientific thinking , they would have been more skeptical about their own theory-based beliefs . On this view , they either would have relied on covariation information to assess whether their beliefs were supported or , at the very least , would have cited both covariation and mechanism information as evidence . Consider this rebuttal with respect to four sets of results . ( The question of skepticism with respect to anomalous evidence will be dealt with again in chapter 3 . ) Arranging evidence for rival theories Consider first the sports-balls study in which subjects were asked to arrange high-bounce and low-bounce balls in the appropriate baskets @ @ @ @ @ @ @ @ @ @ which variables caused bounceability . It is important to note that subjects were able to arrange the appropriate covariation evidence and were able to provide theory-based explanations not only for their own theories but also for theories that conflicted with theirs . That is , if // subjects did lack skepticism , it did not prevent them from being able to describe what both types of support for a rival theory would look like . Not citing covariation as evidence Consider next subjects like the one who proposed that it is judicial leniency and overcrowding in the prisons that causes prisoners to return to a life of crime . When asked to provide evidence for his belief , the subject merely elaborated his causal script by suggesting that judges give criminals less than the full sentence and by proposing a survey of prisons to document that overcrowding is indeed a problem . That is , the subject did not propose gathering covariation evidence to determine whether leniency and overcrowding did in fact covary with returning to a life of crime . However , when asked , " What evidence would you @ @ @ @ @ @ @ @ @ @ " such a subject might have understood the question to mean , " What is your justification for saying that now ? " rather than as meaning , " What sort of evidence could you gather in the future to support your argument ? " And , in terms of providing a justification for saying now that leniency might be a source of recidivism , it is reasonable to say , roughly , " The reason I 'm suggesting leniency as a cause is because of my perception that many judges do n't give maximum sentences , " or , " I 've suggested early release as a cause of overcrowding and I would justify having said that by taking a survey to show that prisons are indeed overcrowded . " ( In experiment 16 , below , when it was made clear to subjects that they were being asked to gather evidence that did not now exist , all subjects at all ages did propose a treatment/control contrast to see whether the target factor would covary with the effect . ) ( In chapters 3 and 13 , I discuss @ @ @ @ @ @ @ @ @ @ covariation evidence , they may lack the technical knowledge to be able to do so . This does not mean that they do not see covariation evidence as important , but rather it simply means that they do not know how to arrange a controlled design , especially when the data are naturally occurring or correlational . ) Evaluating confounded data The objection that subjects should have been more skeptical of their theory-based beliefs could also be leveled against their behavior when evaluating confounded data . But here too acknowledging the importance of mechanism information suggests an alternative interpretation . Recall that , in the task that involved the bounciness of sports balls , one of the possible causal factors was color . Color was included specifically to make it likely that one of the variables would be seen as noncausal , and in fact it was color " which most subjects selected as the variable they believed least likely to make a difference . " In this task , even when it was clear that color ( or whatever variable a subject had chosen as noncausal ) and the variable @ @ @ @ @ @ @ @ @ @ the effect , subjects frequently ignored the confounding data and maintained their view that only the latter factor was causal . For Kuhn et al. , this reflected an inability to take account of covariation evidence . However , on an alternative view , it reflected the fact that subjects were being thorough in that they were taking account of all of the evidence available to them ? including evidence about mechanism ? and were using mechanism evidence to decide that one of the covariates was likely to be irrelevant noise . Before entering the experimental situation , subjects had already learned that , with respect to bouncability , color has very few causal properties . As a causal factor , it is simply not plausible . ( Color may be used as an index of something causal , but this is a separate issue . ) Subjects bring this information to the experimental situation and , in consequence , ignore the covariation of color with bouncability precisely because , in taking account of all available evidence , they can think of no mechanism that could render the covariation causal rather @ @ @ @ @ @ @ @ @ @ thinking , consider the following thought experiment : Imagine learning of a study done on two wards of a single hospital in which infants who were frequently held developed better than infants who were not . Imagine also learning that the infants who were frequently held were from the ward that happened to be blue and those not held were from the ward that happened to be yellow . I suspect that few people would be tempted to conclude that since developmental outcomes covaried with ward color as well as with the amount of holding , it would not be possible to decide which of the two variables was the causal one . In experiment 6 , chapter 6 , I describe a study in which the factor that covaried with an effect was sometimes confounded with another factor that is causally relevant in the real world . When both confounded factors were causally relevant , even sixth-graders concluded that confounded data were more likely than controlled data to be indeterminate . ( These results are also congruent with the findings of Bullock 1991 , described below . ) Responding to @ @ @ @ @ @ @ @ @ @ that subjects should have been more skeptical of their theorybased beliefs might be found in the colds study . Here as well one could argue that a more skeptical approach would have been to reject the theory when the covariation evidence was not congruent with it , especially when subjects were explicitly told " to answer the question not from what you know about foods , but based only on the scientists ' findings . " However , rejecting the theory was something subjects seemed reluctant to do , as evidenced by the following two results : subjects often tried to preserve the theory by adjusting it to fit the anomalous data or by adjusting the // anomalous data to fit the theory , and anomalous data had a smaller effect on causal than on noncausal theories . Both results will be discussed in chapter 3 because they are relevant to the literature on disconfirming evidence . However , it is worth briefly mentioning them briefly now in order to note that an analogous point applies : an emphasis on covariation underestimates the extent to which subjects deal with disconfirming evidence @ @ @ @ @ @ @ @ @ @ , my rejoinder to this skeptical rebuttal is to note that it is misleading to study scientific reasoning by studying whether subjects can follow instructions to ignore information that they have already acquired . As Keating notes in his discussion of causal reasoning , including scientific reasoning , " There is little point in trying to explain reasoning independent of a knowledge of content " ( 1990 , 66 ) . In evaluating evidence , scientists do not , nor should they , ignore what they know ( including the theories they know ) . A cancer researcher , for example , who somehow managed to do this would not be very productive . As Boyd ( personal communication ) has pointed out , to study scientific reasoning by asking subjects to evaluate covariation evidence while ignoring what they already know about theory or mechanism is analogous to studying verbal memory by studying memory for meaningless nonsense syllables in order to control for the effects of meaning : there is no reason to think that one would learn about verbal memory , since verbal memory almost certainly relies on meaning-dependent strategies @ @ @ @ @ @ @ @ @ @ know about theory or mechanism might tell us something about the subject 's ability to follow experimental instructions but not about scientific reasoning . Nevertheless , what a critical skeptic could argue is that in the colds study , even if the subjects did not ignore ( and possibly should not have ignored ) what they already knew , they nevertheless been skeptical enough about their own theories that they rejected rather than modified them in the face of the anomalous evidence . To this I offer a three-part rejoinder : First , the anomalous evidence was incomplete . In the colds task , subjects ' beliefs about which foods caused colds were based on considerations of mechanism ( however rudimentary or incorrect ) as well as on covariation . However , what Kuhn , et al . called " disconfirming " evidence called into question only subjects ' beliefs about covariation , leaving their beliefs about mechanism intact . Therefore , when subjects were explicitly told " to answer the question not from what you know about foods , but based only on the scientists ' findings , " the @ @ @ @ @ @ @ @ @ @ ( Experiment 13 , chapter 10 , presents some evidence suggesting that disconfirming or anomalous evidence that deals with the mechanism component , as well as the covariation component , of // a belief is more compelling than disconfirming or anomalous evidence that deals with covariation alone . ) Second , even when disconfirming or anomalous evidence is compelling , it is often scientifically legitimate to modify one 's belief by restricting its scope . For example , if one discovered a strep infection for which penicillin was not effective , it would make sense not to abandon the general belief in the efficacy of penicillin against strep but rather to treat it as a working hypothesis that can be modified and to conclude that the theory that penicillin cures strep infections was right with respect to only some strep infections . That is , we would be tempted to conclude ( though perhaps in a more articulate way ) exactly what Kuhn et al . ' s subjects had concluded , namely , that it " was right with respect to those instances that conformed to the covariation pattern but @ @ @ @ @ @ @ @ @ @ " ( Kuhn et al . 1988 , 126 ) . Yet this conclusion was treated as reflecting flawed thinking . In short , one of the effects of ignoring the legitimate role of mechanism in scientific reasoning is that reasonable hypothesis modification or articulation is treated as reflecting flawed thinking . Similarly , it is also sometimes scientifically legitimate to question data that do not accord with a theory especially if the theory includes a mechanism that explains why the problematic data should not have obtained and why the data anticipated by the theory should have obtained . For example , suppose that scientists are testing the hypothesis that a broadspectrum antibiotic of well established efficacy will actually be effective at doses much lower than those currently employed ( which would be important for economic reasons as well as to minimize side effects ) . Suppose further that scientists treat a number of patients suffering from diseases for which the drug has been effective in the past , giving them doses ranging from the currently standard dosage down ( by increments ) to I percent of the standard dose . @ @ @ @ @ @ @ @ @ @ rational to begin by questioning the data , that is , by tentatively adopting an explanation of the data that did not require any change in their attitude towards the test hypothesis at all , since it would be rational to suppose that the drug samples were defective . As already noted , these issues will be discussed in more detail in chapter 3 . ( Note that this is not to argue that subjects ' beliefs about what causes colds were correct ; clearly , many of them were quite erroneous . It is simply to point out that the disconfirming covariation evidence dealt with only one component of their beliefs and that in the face of disconfirming evidence , hypothesis modification rather than rejection , is often scientifically legitimate and not an example of flawed thinking . ) Third , Kuhn et al . ( 1988 ) , as well as Schauble ( 1990 ) , found that as disconfirming or anomalous evidence accumulated , subjects did become // increasingly likely to reject their theories . ( These findings will be relevant , again , in chapter 3 . @ @ @ @ @ @ @ @ @ @ theories at the first sign of anomalous evidence , but they also did not ignore anomalous data when repeated occurrence made it clear that the data were not accidental . In short , maintaining a certain skepticism about one 's own beliefs is often an admirable thing to do . However , skepticism that is unconstrained by , among other things , considerations of theory or mechanism can be counterproductive ; without some way of deciding which correlations or beliefs should be taken seriously ( at least at the outset ) , one would be overwhelmed . In the same vein , to reject theories at the first sign of anomalous evidence might be to reject them when modification would instead be appropriate . Note also the point about terminology made in the beginning of this chapter . If we understand a hypothesis tested by Kuhn et al . ' s subjects to have been " Variable x always causes colds , " then changing the hypothesis to be " Variable x causes colds only in certain instances but not in the ones we were presented with here " would , @ @ @ @ @ @ @ @ @ @ the initial hypothesis . Thus a subject who made this modification would not have failed to understand ( and apply ) the logic of confirmation and disconfirmation . Of course , the question could still be raised of whether the modification in question was well motivated , as opposed to ad hoc . But if the subject 's initial hypothesis is instead treated as an imprecise working hypothesis , then its refinement would be a case of what I have been calling elaboration rather than one of modification . Here too there would be the question of whether the elaboration in question was well motivated or ad hoc , but there would be no question of whether the subject appreciated the necessity for making some revision in the light of the data . It is not clear from the reported data which interpretation of the subjects ' hypotheses is appropriate or ( more important ) whether or not their revisions to them were well motivated . In experiment 11 there is some evidence that subjects do prefer theoretically motivated to ad hoc hypotheses . The flaws there were Returning to the @ @ @ @ @ @ @ @ @ @ engaged in flawed thinking , I suggest that in some cases they certainly did but the flaws had to do with information-processing limitations rather than with an inability to coordinate theory and evidence . One example of flawed thinking was that subjects were better able to generate covariation evidence to support a causal theory than they were to generate noncovariation evidence to demonstrate the incorrectness of a causal theory . However , as Kuhn et al . themselves point out , " Noncovariation evidence could be of three types : ( 1 ) a selection of balls of a // single variable level distributed across two outcomes , ( 2 ) a selection of balls of both levels of the variable yielding the same outcome , and ( 3 ) a combination of the two preceding types , that is , a selection of balls of both levels of the variable distributed across both outcomes " ( 1988. 175-176 ) . I suggest that the three types might have been conflated in the subjects ' thinking so that , although the subjects understood conceptually what it meant that a variable made @ @ @ @ @ @ @ @ @ @ through and disambiguate the three ways of demonstrating operationally that the variable made no difference , and the reason they might have been unable to disambiguate is that either they lacked the information-processing capacity to be able to do so or else they lacked a strategy that would have enabled them to do this kind of sorting with the information-processing capacity that they did have . Another flaw that may have reflected information-processing limitations is that the major source of error in generating covariation evidence was the failure to recognize the potential confounding effects of other variables and the need to control for them . As already noted , one reason for the subjects ' lack of attention to control may have been that they , like many practicing scientists , did not feel the need to control for a variable that they believed to be causally irrelevant . ( This may , of course , have reflected a mistaken belief about which variables were irrelevant , but it did not necessarily reflect the belief that a control is not important . ) However , information-processing limitations might also have played @ @ @ @ @ @ @ @ @ @ were size , then one strategy for testing its effect would be to put a large ball in one basket and a small in the other while holding all other variables constant . However , another would be to put large balls in one basket and small ones in the other and to have each pair of balls matched on the other three variables . In terms of information processing , and for the subject who had no prior training in experimental-design strategies , it might be difficult to disentangle the two approaches , and in cases in which more than two balls were used , it might be difficult to keep track of the other three variables . ( Some evidence that information processing might be have been playing a role can be found in Bullock 's 1991 study , discussed below . ) In short , then , one possibility is that information-processing limitations ( rather than subjects ' reluctance to reject their theory-based beliefs ) made the generation of noncovariation evidence more difficult than the generation of covariation evidence and , when covariation evidence was generated , made @ @ @ @ @ @ @ @ @ @ to control for ) confounding variables . A caveat about theories I have been arguing that relying on theory or mechanism considerations is scientifically legitimate and , in particular , that it is reasonable to do so in deciding which correlated factors are likely to // be causal rather than artifactual . However , in making this argument , I am not suggesting that variables that seem to be causally irrelevant should never be taken into account . Sometimes factors that are in fact causal seem nevertheless to be causally irrelevant simply because the operative underlying mechanism has not yet been discovered . In terms of the earlier example regarding the color of hospital wards and developmental outcomes , if the two wards differed only in color and not also in terms of amount of holding the infants received , and especially if other hospitals also found a systematic correlation of developmental outcome with ward color , then color would be worth a second look because it might indicate as yet undiscovered effects of color on , for example , the infants ' moods , irritability , etc . However , @ @ @ @ @ @ @ @ @ @ look , the second look is typically motivated by information other than covariation : typically , in such cases , the usual causes of the phenomenon have all been ruled out and the covariation is observed more than once . What I am suggesting is that without this other information , and given the large number of correlations in the world , it is reasonable that some instances of covariation should be dismissed as artifactual in order to avoid being overwhelmed by irrelevant noise . In this regard , recall that when the subjects of Kuhn et al . ( 1988 ) and Schauble ( 1990 ) were repeatedly exposed to disconfirming covariation evidence ( that is , in terms of the present suggestion , when they were shown that the anomalous covariation was systematic ) , they did indeed become increasingly likely to reject theory-based beliefs . ( This point is developed in experiments 9 and 10 , below . ) In short , the guideline that implausible alternative hypotheses ought to be ignored and the qualifier that implausible alternative hypotheses should sometimes be taken seriously both ought to be @ @ @ @ @ @ @ @ @ @ It is resonable to slight seemingly irrelevant correlations and implausible alternative hypotheses in the early steps of data collection . If , as evidence accumulates , a seemingly irrelevant correlation continues to obtain , then the implausible correlation ought to be pursued , especially if more plausible possibilities have been ruled out . In a word , skepticism about seemingly irrelevant causes needs to be constrained . ( These issues are examined in experiments 7 through 10 , below . ) The notion of constrained skepticism is also related to the suggestion , mentioned in chapter 1 and to be elaborated in subsequent chapters , that scientific reasoning can be described as a bootstrapping operation . Briefly , the argument is as follows : Principles of scientific inquiry ( such as , identify the cause of an event by identifying its correlates ) function as rules of thumb rather than algorithms because they do not guarantee success . The success of the principles depends on the accuracy of the background information ( such as information about mechanism ) that the principles // are used in conjunction with . However , principles @ @ @ @ @ @ @ @ @ @ background information not now known . That is , we are more likely to identify a genuinely causal correlation if we are already approximately correct about what the mechanism is that distinguishes it from specious correlations , but pursuing apparently specious but systematic correlations might enable us to discover an underlying mechanism not now known . Related work Turn now to the third point regarding Kuhn et al . ' s ( 1988 ) work , namely , that it has provoked studies designed to examine the extent to which its conclusions can be generalized . Consider two conclusions in particular . In Kuhn et al . 1988 one of the ways in which people are said to have difficulty distinguishing theory from evidence is that they have trouble testing hypotheses . The other is that they are said to have difficulty dealing with confounded variables . Recent work by other researchers has examined both of these claims . Sodian , Zaitchik , and Carey designed their experiments to test the claim that , when asked to determine the causes of a phenomenon , young children " act as if their @ @ @ @ @ @ @ @ @ @ rather than to discover its causes " ( 1991 , 753 ) . They presented their firstand second-grade subjects with a problem in which two brothers were trying to find out whether the mouse living in their house was large or small . Two boxes were described : one with a large opening and one with a small opening . The subjects were then asked which box the brothers should put out if they wanted to tell , according to whether the food was gone in the morning , what size the mouse was . If a subject wanted to test the hypothesis about size , she would suggest the box with the small opening should be used , since only the small mouse could fit through it . However , a subject could fail on this test because she interpreted the task of testing the hypothesis about the size of the mouse as the task of feeding the mouse ( that is , of producing a desirable effect ) . To assess whether children could distinguish these two goals , Sodian et al . also gave children a second task @ @ @ @ @ @ @ @ @ @ out to make sure that the mouse got some food no matter what its size . Subjects were also asked questions about conclusive and inconclusive tests : they were asked what conclusions would follow if the food were removed from the box with the large opening or from the box with the small opening . Most of the first-graders and all of the second-graders gave evidence that they were distinguishing the goal of testing a hypothesis from the goal of producing an effect . The most frequent pattern ( observed in 55 percent of the first-graders and 86 percent of the second-graders ) consisted of correctly choosing the box with the large opening to feed the mouse and the box // with the small opening to find out the size of the mouse , correctly justifying both choices , and correctly answering questions about conclusive and inconclusive tests . In the second study , the same children were told that two brothers wanted to find out if aardvarks have a good or a poor sense of smell . First the subjects were simply asked what they could do to find this @ @ @ @ @ @ @ @ @ @ propose . Then they were asked whether , to distinguish between the two hypotheses , they should put out a strong-smelling or weak-smelling piece of food , in order to see whether subjects could choose the conclusive test . While few children in either age group were able spontaneously to propose a conclusive test , the majority of children , when presented with the two possible options , did suggest using the conclusive weak-smelling food rather than the inconclusive strong-smelling food . Sodian et al . are careful to point out the many differences between their task and tasks in which subjects have engaged in less sophisticated behaviors . Nevertheless , what their work demonstrates is that , at least in some situations , very young children are able to distinguish testing a hypothesis from merely producing an effect . The results of their study are also relevant to the claim that children have difficulty understanding that some data are inconclusive . In Sodian et al . ' s study , subjects were able to choose a conclusive test by drawing inferences about what additional things would be true ( about @ @ @ @ @ @ @ @ @ @ true . Although this does not mean that subjects can recognize inconclusive data ( or design conclusive tests ) in all situations , it does suggest that subjects ' understanding of an inconclusive test is more complex than it might appear to be and that analyzing their understanding in more detail might be necessary to paint a more fine-grained picture of how it develops . Some recent work by Bullock ( 1991 ) also concerned inconclusive tests , but her task was one more directly comparable to the sports-balls task . Like Kuhn et al . ( 1988 ) , Bullock presented her subjects ( second through fourth graders ) with a problem that involved identifying a causal factor . Specifically , subjects were told that a young boy wanted to make some lanterns that would not go out in the wind . The lanterns could be made with many small holes or a few large ones , with short wide candles or tall thin ones , and with or without a roof . Subjects were then told that the boy wanted to find out whether having a roof makes a @ @ @ @ @ @ @ @ @ @ . There were two measures : One was what the subjects spontaneously proposed . The other was what choices they made when presented with a set of eight cards , with each card depicting one of the eight possible types of lanterns ( for example , a lantern with a few large holes , a short wide candle , and no roof ) . // The large majority of third and fourth graders ( 74 percent and 84 per-cent ) spontaneously proposed a contrastive test ( one lantern with a roof and another without ) . Only a small percentage also added that one would have to hold one or both of the other variables constant . However , when subjects were choosing which of the eight cards would provide a good test of whether a roof makes a difference , a third of the third-graders and most of the fourth-graders chose cards that held everything constant and varied only whether or not a roof was present . In a word , in Bullock 's task , subjects were able to choose the sorts of tests that avoided confounding , whereas @ @ @ @ @ @ @ @ @ @ sub jects were not able to recognize indeterminacy when presented with a confounded design . I suggest that the difference can be understood in terms of the argument offered earlier in this chapter : In Kuhn et al . ' s task , one of the confounded variables had already been identified by the sub ject as being causally irrelevant ( and when the variable was color , which it was for " most " subjects , then it actually was causally irrelevant ) . Thus there was a rationale for ignoring it . In contast , in Bullock 's task , the vari ous factors that could be confounded all made causal sense . One could imagine a mechanism by which the factor could affect whether the lan terns blew out in the wind . ( Large holes , for example , could admit large gusts of wind . ) And because subjects could see the relevance , they con-trolled for confounding . Related results are reported in experiments 6 and 16 , below . In addition , the fact that subjects found it difficult to propose tests that controlled @ @ @ @ @ @ @ @ @ @ arrangement of cards that enabled nontarget variables to be controlled for supports my earlier suggestion that information-processing limitations also play a role in how subjects deal with confounding : choosing an arrangement of cards may have been less cognitively demanding than designing a test from scratch . General Summary In summary , I have argued that the research on formal-operational rea soning and on causal reasoning has , for the most part , examined scientific reasoning by asking subjects to reason about a theoretically impover ished environment and by stipulating that correct performance consists of equating causation with covariation . Although these sorts of situations approximate the kind of predicament that exists when plausible hypoth eses either do not exist or have been ruled out , such tasks provide a pic ture of causal reasoning that is , at best , incomplete . In most circumstances , people do not ( nor should they nor can they ) treat all covariations as equally indicative of plausible causes . And distinguishing correlations that // are genuinely causal from those that are merely artif actual is done , in part , by relying @ @ @ @ @ @ @ @ @ @ subjects to reason about theoretically impoverished situations describes subjects ' scientific reasoning in a way that omits many of its most important aspects . But this is not simply an argument that a lack of attention to the role of theory or mechanism is an omission that produces an incomplete picture of scientific reasoning and nothing more . When experimental tasks consist of having subjects reason about situations that are theoretically rich but in which correct responses are stipulated to consist of ignoring considerations of theory or mechanism , then the resulting picture of scientific reasoning is not merely incomplete but is actually distorted . When laboratory tasks are contrived so that correct performance consists of ignoring mechanism and treating covariations as roughly equivalent to one another , then subjects who ignore certain covariations while taking others seriously or who treat mechanism as evidential will be treated as engaging in flawed reasoning when they are , in fact , reasoning in a way that is scientifically legitimate . This chapter has focused on hypothesis testing . The following chapter will deal with the kind of hypothesis articulation or modification that takes @ @ @ @ @ @ @ @ @ @ Although there is a distinction between these two activities , the distinction is not at all a sharp one . It is often very difficult to tell when hypothesis testing ends and hypothesis modification begins . ) I will argue that here too an undue emphasis on covariation underestimates people 's ability to think scientifically . Chapter 3 Disconfirming and Anomalous Evidence The previous chapter focused on the way in which people identify causes or formulate at least preliminary causal explanations for various events . But one of the hallmarks of scientific inquiry is that explanations in general , and especially preliminary ones , are not always perfect . The result is that subsequent data may be anomalous to the explanation . Conclusions about Disconfirming Evidence In the social-psychological literature , the question of how people evaluate explanations in light of disconfirming data has been examined in studies of attitude change . Although there are certainly exceptions , Gleitman 's summary of the findings is representative : " The overall picture is one of attitude stability rather than of attitude change . Attitudes can be altered , but it takes some @ @ @ @ @ @ @ @ @ @ a tendency to hold on to the attitudes one already has " ( 1983 , 343 ) . In many of these studies , the attitudes in question concerned beliefs about politics , abortion , capital punishment , race , personal efficacy or worth , etc . The typical conclusion about the stability of such attitudes makes intuitive sense . It is easy to imagine that they would be quite resistant to change for two reasons . One is that such attitudes are often emotion-laden , and it would hardly be surprising if the emotional component of the beliefs served to filter out or somehow distort disconfirming evidence . Another reason is that these sorts of beliefs , far from being circumscribed , are typically interwoven with much broader beliefs ( including beliefs about what can count as evidence ) that define a kind of worldview . Thus arguments that run counter to the circumscribed belief may do little to change it , because they may have little to do with the broader web of beliefs within which the target belief is imbedded and by which it is buttressed . ( @ @ @ @ @ @ @ @ @ @ . Clearly they sometimes are , but usually over a period of time longer than the typical experiment . ) In short , the claim that the beliefs just discussed are tenacious seems to have a certain face validity . However , what seems less intuitively obvious // are analogous results from the cognitive literature on how people deal with disconfirming evidence . Here too the conclusions drawn from the research have been quite uniform and consist of two main points . The first is that , by and large , people do not seek disconfirming evidence and only sometimes take it into account when it is presented to them . That is , people are said to exhibit a confirmation bias ( e.g. , Bruner , Goodnow , and Austin 1956 ; Wason 1960 ) . The second is that when people fail to take account of disconfirming evidence , their behavior is parallel to the behavior of scientists , as described by T. S. Kuhn ( 1970 ) , who cling to their theories in the face of disconfirming data that call for the theories to be rejected ( @ @ @ @ @ @ @ @ @ @ Amsel , and O'Loughlin 1988 ; Wason 1977 ) . There are two reasons for questioning these conclusions . One is that there are other results , also in the cognitive literature , that suggest the exact opposite . The other is that it is initially implausible that nonscientists ' behavior in the cognitive experiments would resemble the scientists ' behavior as described by T. S. Kuhn . Questioning the Conclusions Cognitive Research on Hypothesis Testing Consider first empirical work from a related cognitive area not directly aimed at studying how people deal with disconfirming evidence : the body of research on hypothesis testing in which relinquishing hypotheses is precisely what people ( children as well as adults ) do ( Stevenson 1972 ) . In the bulk of these tasks , subjects generate and test a series of specific hypotheses , and each time a hypothesis proves not to be correct ( that is , each time a hypothesis is disconfirmed ) , the subject moves on to generate and test a different hypothesis . Indeed , people frequently adopt a winstay/lose-shift strategy for relinquishing a disconfirmed hypothesis with maximum @ @ @ @ @ @ @ @ @ @ consists of doing precisely what subjects are often said , in studies of disconfirming evidence , to be reluctant to do . Normal versus Crisis Science Consider next whether it is initially plausible that nonscientists ' behavior in the experiments in question resembles the scientists ' behavior as described by T. S. Kuhn . When T. S. Kuhn drew attention to scientists unwilling to relinquish their theories in the face of disconfirming evidence , he was describing situations that occur during what he termed periods of " crisis " as opposed to " normal " science . Crisis situations involve paradigm shifts that affect not only the content of the beliefs in a discipline // but also the very methodology that the discipline is based on . For many of the scientists practicing during a crisis period , the paradigm shift calls into question the work of a lifetime . In this context , a tendency to cling to their old paradigms in the face of disconfirming evidence has strong emotional as well as cognitive roots . In a very real sense , the scientists ' careers are at stake . @ @ @ @ @ @ @ @ @ @ are said to be clinging to their theories . These tasks involve hypotheses such as whether one rather than another geometric figure repels a moving dot on a computer display ( Mynatt et al . 1977 ) , whether drinking apple juice versus orange juice causes more colds ( D. Kuhn et al . 1988 ) , whether the rule that defines a number sequence is " any increasing series " ( Wason 1960 ) , etc . These tasks do not involve beliefs that define whole careers or even worldviews about a particular area . They are of little consequence , and therefore of little emotional import . True , some of the beliefs are ones that the subjects themselves have generated , and thus they undoubtedly reflect a certain amount of ego involvement but presumably only a pale copy of the kind of ego involvement that occurs when a career 's worth of work is at risk . Nevertheless , the conclusions are parallel : the subjects are said to have a confirmation ( or verification ) bias ; they avoid searching for and taking account of disconfirming evidence @ @ @ @ @ @ @ @ @ @ to conclusions that seem , on the face of things , to be implausible ? Of course , one explanation is that even when beliefs are inconsequential , people nevertheless hold on to them and ignore disconfirming evidence . However , there are other explanations , as well . An Alternative Account of the Data One reason the conclusions may have been unwarranted is that in some cases they were based on measures that were either confounded or ambiguous . Another reason is that the many different readings of " confirmation bias " are not always adequately distinguished , the result being that behavior that would be genuine confirmation bias on one reading would not be on another . A third reason is that many studies of confirmation bias are based on misleading descriptions of scientific inquiry that ignore the importance of considerations based on theory or mechanism . Inconclusive Measures Clinging to an initial theory versus being unable ? if only temporarily ? to generate an alternative Clinging to one 's initial theory need not reflect a preference for the familiar over the new . Instead , it may reflect @ @ @ @ @ @ @ @ @ @ therefore a preference for some explanation ( however defective ) over no explanation at all . That is , there are two senses in which measures of confirmation bias have been flawed . One is that , although the term " confirmation bias " connotes a fairly long-term disposition , the measures have assessed what may be merely temporary states . The other is that the measures have confounded clinging to the old explanation with being unable to generate an alternative to replace it . As a case in point , consider the series of studies carried out by KarmiloffSmith ( 1984 ) . Karmiloff-Smith has identified three phases that children go through in solving a problem . The first , a procedural data-driven phase , is one in which each behavioral unit is successful in the sense that it achieves its goal but in which the individual units are not linked to one another in a consistent whole . For example , in her classic block-balancing task ( Karmiloff-Smith and Inhelder 1974/1975 ) , in which the task is to balance ordinary blocks as well as blocks that contain either @ @ @ @ @ @ @ @ @ @ each block successfully by relying on proprioceptive feedback , but they treat each block as an isolated problem . Therefore , once a child has succeeded in balancing a conspicuously weighted block , she does not then try another block of that type in order to make use of her newly acquired knowledge . Blocks are simply taken up in the order in which they lie on the table . Phase 2 behavior is described as being top-down or theory-driven . The child generates a metaprocedural rule , that is , a simplified procedure that allows the child to link the previously isolated problems into a single problem . For example , in the block task , the child generates the rule that blocks balance at their geometric center . The cost of this top-down procedure is fewer successes than in phase 1 , because the weighted blocks in fact do not balance at their geometric center . Furthermore , what is striking is that in phase 2 the children actually ignore noncongruent data by , for example , dismissing the weighted blocks as being " impossible to balance . " @ @ @ @ @ @ @ @ @ @ procedure with the top-down strategy , trying first a geometric-center theory but rapidly adjusting the position of the weighted blocks in accord with proprioceptive feedback . The data from phase 2 clearly demonstrate that frequent counterexamples alone do not induce a change in the child 's theory . In fact , in phase 2 the counterexamples are typically dismissed as being " impossible . " This has lead at least one researcher to conclude , " Children hold on to their initial theory for as long as they can " ( Wason 1977 ) . However , it would be mistaken to conclude from these findings that ignoring disconfirming data is a general feature of the child 's cognitive life . It would be equally mistaken to conclude that in holding on to their theories , the children were choosing between competing theories and // were basing their choice on comfortable familiarity rather than explanatory value . As Karmiloff-Smith ( 1984 ) points out , one of the salient features of the children 's behavior was that ignoring " impossible " data was only a temporary strategy . It was adopted @ @ @ @ @ @ @ @ @ @ the initial theory to be consolidated . Once consolidation took place , then the children did begin to deal with the " impossible " instances , first by trying to generate a separate theory independent of the initial one and then by aiming at a single unifying theory that could account for both types of blocks . That is , ignoring disconfirming data was a temporary strategy rather than a general dispositional state . In addition , dismissing noncongruent data need not mean that the children viewed the data as unproblematic for the explanation . It could mean instead that they were simply unable to generate an alternative explanation to take account of the data . Being dissatisfied with an explanation and having the wherewithal to generate a replacement for it are two separate processes that ought to be treated as independent . Yet when Wason ( 1977 ) was inferring that children cling to their theories , his conclusion was based on their not having generated an alternative . One can easily be dissatisfied with an existing explanation without necessarily having the resources to generate a replacement for it . @ @ @ @ @ @ @ @ @ @ simplify the data they are dealing with by temporarilly ignoring evidence that does not quite fit . Minerologists , for example , sometimes assume , as a temporary working hypothesis , a symmetrical crystalline structure even when they know that the structure is , in fact , asymmetrical . Such an oversimplified working hypothesis not only reduces information-processing demands ( as does , for example , the focus-gambling strategy of Bruner et al . 1956 ) but also serves as a framework within which the anomalous data can be organized and against which they can form a pattern that suggests either a systematic modification or an alternative . Preferring an explanation ? however flawed ? over no explanation Furthermore , in Karmiloff-Smith 's studies , the temporary inability to generate an alternative also had another consequence . When the initial theory was generated in phase 2 , it did in fact explain some of the data . More to the point , perhaps , it was the only theory available to the child ; the child had not yet been able to generate a theory that could account for all of @ @ @ @ @ @ @ @ @ @ did not reflect the rejection of a new theory of better ( or even equal ) explanatory value in favor of the old theory , because there was no new theory . Instead , it might have reflected a preference for an explanation that did account for some of the data ( albeit // in an imperfect way ) over a state of affairs in which there was no explanation for any of the data . Preferring a theory because its competitors have been found wanting Klahr and his colleagues found that subjects were less skeptical of selfgenerated hypotheses rather than other-generated hypotheses ? which would seem , on the surface at least , to reflect a confirmation or belief bias . However , this conclusion also is open to question . In one of the tasks , Schunn and Klahr ( 1992 , 1993 ) asked subjects to discover the function of an unknown command ( delta ) in a computer device that directed a " milk truck " to execute a sequence of actions associated with a dairy delivery route . Subjects generated and ran programs to test hypotheses @ @ @ @ @ @ @ @ @ @ of a computer-controlled robot tank called " BigTrak " that could be programmed to do several things , including going forward and backward and rotating left and right ( Klahr , Fay , and Dunbar 1993 ) . Programming was done by entering the instructions with various keys . The subjects ' task was to discover how the repeat key ( RPT ) worked . There were two global hypotheses : The correct " N-role : selector " hypothesis was that a command of RPT N repeated the previous N instructions once . However , most subjects generated the " N-role : counter " hypothesis according to which RPT N meant that either the entire program or the single instruction preceding RPT would be repeated N times . Klahr et al . ( 1993 ) represent the subjects ' hypothesis space in terms of frames . The two major frames that corresponded to the two global hypotheses were the " N-role : counter " frame and the " N-role : selector " frame . In terms of the earlier discussion , a frame might be thought of as analogous to a @ @ @ @ @ @ @ @ @ @ selector " hypothesis was the correct one . ) Each major frame consisted of a local hypothesis about four attributes ( such as the type of element to be repeated , the boundaries of the repeated element , etc . ) . The experiment space included the results of various experiments . Using the milk-truck task , Schunn and Klahr ( 1993 ) found that when subjects tested hypotheses generated by someone else rather than by themselves , they tested more programs and did so over significantly more time even though they rated self-generated and other-generated hypotheses as being comparably plausible . That is , they tested self-generated hypotheses less rigorously ? a finding compatible with a confirmation bias . However , Schunn and Klahr ( 1993 ) also report that Koehler found that self-generated hypotheses were given lower confidence ratings than othergenerated hypotheses because , Koehler argued , the process of hypothesis generation forces the individual to consider more alternative hypotheses . // In a word , whether subjects are more rigorous in assessing self- rather than other-generated hypotheses is not clear . Using the BigTrak task , Klahr , @ @ @ @ @ @ @ @ @ @ were more likely to retain self-generated hypotheses rather than other-generated hypotheses in the face of negative evidence ? a finding that would seem also to reflect a belief bias . However , " belief bias " connotes a situation in which a subject 's belief leads her to ignore or distort disconfirming data , and there is an alternative explanation for Klahr et al's. finding that turns on Koehler 's point : It may be that to produce a selfgenerated hypothesis , a subject contrasts various possible hypotheses and evaluates them in the context of the evidence to be explained . The hypothesis that is then presented as self-generated is one that has already been evaluated favorably with respect to its competitors . Therefore , when a self-generated hypothesis is confronted with anomalous evidence , the evidence has diminished effect because to take it seriously would mean to impugn the target hypothesis in favor of one of its competitors when the competitors have already been evaluated and found wanting . In contrast , an other-generated hypothesis may be one that the subject has not previously evaluated with respect to its competitors @ @ @ @ @ @ @ @ @ @ more compelling than its competitors . Therefore , when the target is other-generated , the subsequent presentation of disconfirming evidence might make it easier to reject the target because the subject has not already decided that it is more convincing than its competitors . In short , the stronger commitment to a self-generated theory might reflect a prior ( favorable ) assessment of it in relation to the alternatives rather than the sort of commitment that simply prevents the subject from questioning something that she herself has generated . Dunbar and Klahr ( 1989 ) also observed third- to sixth-graders learning how the RPT key worked and concluded that there were several developmental differences . The first is that children and adults proposed different hypotheses : children were more likely to propose partially specified ( ambiguous ) hypotheses rather than fully specified hypotheses . " Second , the children did not abandon their current frame and search the Hypothesis space for a new frame , or use the results of experiment space search to induce a new frame . Third , the children did not attempt to check whether their hypotheses @ @ @ @ @ @ @ @ @ @ that there was earlier evidence against their current hypothesis , they said that the device usually worked according to their theory " ( Dunbar and Klahr 1989 , 132 ) . However , the second conclusion needs to be qualified . Karmiloff-Smith ( 1984 ) found that children did eventually do the analog of abandoning their current frame and either searching for or inducing a new frame . The difference is that in Karmiloff-Smith 's // studies , the tasks were less esoteric and the mechanisms ( for example , hidden weights , balance beams , physical forces , etc. ) could be apprehended proprioceptively . In addition , the third conclusion suggests the sort of reluctance to relinquish a current hypothesis that is compatible with a confirmation bias . However , it could have been instead that the children found their current hypotheses less compelling than it had been in the light of anomalous evidence but that they were unable ( at least temporarily ) to generate an alternative that would account for the initial data as well as the anomalous data . In short , in the absence of @ @ @ @ @ @ @ @ @ @ clinging to one 's initial theory may reflect either or both of two things : a preference for a flawed explanation over no explanation at all and a temporary inability to formulate a new competing theory . In the same vein , a commitment to a self-generated theory might reflect the fact that it has already been evaluated with respect to its competitors and found to be more compelling than them . In a word , although a standard conclusion in the cognitive literature is that people , including children , exhibit a confirmation bias , the data thought to demonstrate such a bias are open to alternative interpretations . In the studies reported here , when subjects were presented with anomalous or disconfirming data , direct measures were used to assess whether such data made subjects less committed to the existing theory . In addition , when subjects were asked to choose between an old theory and its replacement , they were typically provided with the replacement ; they did not have to generate it on their own . A Conflated Term The second reason why conclusions about confirmation bias @ @ @ @ @ @ @ @ @ @ the various referents of " confirmation bias " are not always clearly distinguished , so what might be genuine confirmation bias on one reading would not be on another . The term " confirmation bias " has been used to account for several different conclusions , including the following : ? People often do not accurately perceive data unless their theory predicts that the data should be there ( e.g. , Chapman and Chapman ' s 1967 , 1969 work on illussory correlations ) . ? People can not describe what disconfirming results would look like ( D. Kuhn et al . 1988 ) . ? People can not ( or do not ) generate or seek disconfirming rather than confirming tests or evidence ( Mynatt et al . 1977 ; Bruner , Goodnow , and Austin 1956 ; Wason 1960 ) . // ? When faced with disconfirming data , instead of relinquishing their theories , people continue to maintain them by modifying them to take account of the disconfirming results ( D. Kuhn et al . 1988 ) . ? In testing their hypotheses , people do not adequately @ @ @ @ @ @ @ @ @ @ , Mynatt et al . 1977 , Dunbar and Klahr 1989 ) . By way of illustrating the sort of problem that the conflation of referents can result in , consider a subject who , in response to disconfirming data , modifies her explanation to take account of the data . If by " confirmation bias " one means that disconfirming data are filtered out , then the subject 's behavior would not reflect a confirmation bias ; she would have discerned the disconfirming data . However , if " confirmation bias " is taken to mean modifying rather than rejecting a hypothesis in the face of disconfirming data , then such behavior would be treated as reflecting a confirmation bias . This chapter does not deal with situations in which theoretical commitments cause one to filter out or distort data that do exist or to " see " data that are merely illusory . Such situations are indeed examples of something that genuinely deserves to be called " confirmation bias . " Rather , my discussion will focus on situations in which people are treated as reasoning in a flawed @ @ @ @ @ @ @ @ @ @ fact merely relying on theory or mechanism information in a way that is scientifically legitimate . An Incomplete Account of Scientific Inquiry Finally , the third reason why conclusions about confirmation bias in cognitive tasks might not be warranted is that many studies of confirmation bias are based on incomplete or misleading descriptions of scientific inquiry and , in consequence , ignore the importance of considerations that involve theory or mechanism information . They therefore label as " confirmation bias " behavior that is in fact congruent with sound scientific practice . Much of the psychological research relevant to the question of confirmation bias was influenced by the approach of sir Karl Popper ( 1959 ) . Psychologists have often interpreted Popper as having argued that the strategies or tests for confirming a theory are distinct from the strategies for disconfirming or falsifying it , and further that in testing a theory , disconfirming strategies provide conclusive evidence whereas confirming strategies do not . Therefore , when testing a theory , scientists ought to generate tests that disconfirm it rather than tests that confirm it . Central to Popper 's falsificationist @ @ @ @ @ @ @ @ @ @ : a particular result either disconfirms the hypothesis or else it does not . // Relevant Research Some of the research relevant to the issue of disconfirmation ( for example , D. Kuhn et al . 1988 , Klahr and Dunbar 1988 , Karmiloff-Smith and Inhelder 1974/1975 ) has already been described . Additional relevant research is the work of Mynatt et al . ( 1977 , 1978 ) and of Wason ( 1960 ) . Mynatt et al . ' s ( 1977 ) work was motivated explicitly by Popper 's approach . They asked whether " subjects tend to select situations for testing their hypotheses which allow only confirmatory observations rather than selecting situations which allow alternative hypotheses to be tested " and whether " subjects who obtain direct falsifying evidence change hypotheses . " To answer their questions , Mynatt et al . presented undergraduates with two computer screens on which were displayed figures of various shapes ( triangle , square , or disk ) and levels of brightness ( I will refer to these levels as black versus gray ) . A particle could be " fired @ @ @ @ @ @ @ @ @ @ . The subject 's task was to generate a hypothesis to describe the motion of the particle . In fact , all gray figures repelled the particle because a circular , nonvisible boundary extended 4.2 cm. from the geometric center of the gray figures . However , the task was contrived to suggest that it was shape that mattered by having a black triangle located within the nonvisible boundary surrounding a gray disk . Thus the gray triangle and the black triangle both repelled the particle , but the gray triangle did so because it was gray , while the black triangle did so because it was within the boundary of a gray disk . The analysis focused on those subjects who hypothesized that triangularity was the cause . After generating their hypotheses , subjects were presented with ten pairs of screens and told to choose one member of each pair to have the particle fired at . The particle was not actually fired , however . For some pairs Mynatt et al . identified certain pair members as " confirmatory , " " disconfirmatory , " or " providing evidence @ @ @ @ @ @ @ @ @ @ three terms were treated as mutually exclusive . In terms of this discussion , it is important to note that , within Mynatt et al . ' s framework , confirmatory and disconfirmatory choices were stipulated to involve different screens . A free response phase followed in which the particle was actually fired . Table 3.1 shows the ten pairs of screens along with the symbols that designated various pair members as " confirming , " etc. , a triangle hypothesis . ( Recall that I am substituting the terms " gray " and " black " for the brightness designations 0.5 and 1.0 . ) Mynatt et al . ' s results were straightforward . For the paired-screen choices , the tendency to choose screens stipulated to be " confirmatory " rather than screens that " suggested an alternative " was significantly greater than chance and was present early on : 15 of the 20 subjects chose the confirmatory rather than the alternative screen in pair I. FurDisconfirming // thermore , during the free-response phase of the study , those subjects who chose the " falsifying " screen ( 5B @ @ @ @ @ @ @ @ @ @ have a final hypothesis that was correct or partially correct . From the data on paired-screen choices , Mynatt et al . concluded that " subjects failed to consider alternative hypotheses " and instead showed a preference for " confirmatory " screens , which , they said , indicated that " confirmation bias ... may be a general cognitive process " ( 1977 , 93 ) . From the free-response data , they concluded that subjects could use falsi fying data once they obtained it . In a subsequent study ( Mynatt et al . 1978 ) , subjects were shown 27 objects , only some of which repelled the particle . The angle of deflection was determined by angle of incidence , brightness , and size . Subjects rea soned out loud . Almost always , subjects seemed to be seeking confirma tion ( for example , " My pet hypothesis is ... , so I 'm going to start trying to figure out if that 's feasible " ) ( Mynatt et al . 1978 , 401 ) . Furthermore , when tests yielded disconfirming data , the hypothesis @ @ @ @ @ @ @ @ @ @ 37 percent of the time . Mynatt et al . see the small number of hypothesis rejections as additional evidence of confirmation bias . Wason 's ( 1960 ) rule-learning task illustrates similar points . Wason gave his subjects three numbers ( 2 , 4 , 6 ) and told them to identify the rule to which the numbers conformed ( Wason 1977 ) . To do this , subjects were to generate ( and receive feedback on ) other three-number series that might // or might not be instances of the rule . The correct rule was " numbers in increasing order of magnitude , " and few subjects generated it . But what was more interesting was the way subjects tested their hypotheses . The overwhelming tendency was to test series that were consistent with the particular hypothesis subjects were considering and to avoid generating series that ran counter to their own hypotheses . For example , one subject tested the series 8 , 10 , 12 in order to test the hypothesis that the rule was " even numbers increasing in twos . " That is , as @ @ @ @ @ @ @ @ @ @ for testing incompatible alternative hypotheses . Furthermore , when subjects received feedback that their rule was incorrect , in more than half the cases , the rule was maintained , " even though some other attribute , e.g. , order " may have been tested ( Wason 1977 , 309 ) . As in Mynatt et al . ' s task , subjects responded to disconfirming data by maintaining ( albeit in modified form ) their initial , disconfirmed hypothesis . An Alternative Analysis of Scientific Inquiry and Confirmation Bias Return now to the general claim that the view of scientific inquiry reflected in many studies of confirmation bias describes scientific inquiry in a way that is misleading as well as incomplete . Given a misleading description of scientific inquiry , it is difficult to decide whether laymen ? or even scientists , for that matter ? do in fact demonstrate a confirmation bias . In discussing this claim , it is important to distinguish among four phenomena relevant to the assessment of confirmation bias : the strategies or tests carried out to evaluate a hypothesis , the actual results generated @ @ @ @ @ @ @ @ @ @ motivation is for carrying out a particular test , and how the subject deals with anomalous results . Confirmation versus disconfirmation : a false distinction In cognitive psychology , one of Popper 's legacies is that confirmation and disconfirmation are often treated as involving distinct strategies ; tests are said to be either confirming or disconfirming . Furthermore , disconfirming strategies are treated as being preferable to the " biased " strategies of confirmation ( see , e.g. , Evans 1982 , Gilhooly 1982 ) . In Mynatt et al . ' s task , this is reflected by the fact that the three types of pair members that subjects could choose to test ( stipulated to be confirmatory , disconfirmatory , and suggestive of an alternative ) were treated as being mutually exclusive . However , more recent work by philosophers of science ( Boyd 1985 ; T. S. Kuhn 1970 ; Putnam 1962 , 1974 ) has demonstrated that these strategies are not mutually exclusive ; that confirmation , disconfirmation , and generating evidence for alternatives all involve carrying out- the same // sorts of tests . The same @ @ @ @ @ @ @ @ @ @ Briefly , the argument is this : When scientists seek to confirm a hypothesis , if they are well-trained , they typically take into account plausible alternative hypotheses in order to rule them out by way of making the target hypothesis more convincing . Similarly , when scientists seek to disconfirm a hypothesis , they again take into account plausible alternative hypotheses in order to demonstrate that it is in fact one of the alternatives rather than the target hypothesis that provides the better account . That is , the formal aspects of confirmation and disconfirmation are the same ; both involve taking into account plausible alternative hypotheses . I will illustrate this point with two sorts of examples because both occur in the literature on disconfirmation . The first involves a causal claim . In terms of the terminology from the previous chapters , this example represents theoretically rich situations . The second example involves a claim about the properties of a set , and thus constitutes an example of a theoretically impoverished situation . Testing a causal claim Consider first research designed to confirm the causal hypothesis that drug @ @ @ @ @ @ @ @ @ @ hypothesis , one would need to rule out ( at least ) the plausible alternative hypothesis that it is the body 's own immune system that eventually gets rid of the virus . Therefore , to test this hypothesis , one would need two groups of subjects : generally healthy and generally rundown . Then , within each group , some subjects would receive drug x and some would not . One could then establish whether it was general health or treatment with drug x that was affecting the course of colds . If general health were found to have a negligible effect , then it would be ruled out as a serious alternative hypothesis . That is , the results would help confirm the target hypothesis . But notice that the same test could also yield results that disconfirmed the target hypothesis : If general health were found to have an effect and drug x not , then the hypothesis that drug x cures colds would be disconfirmed . In short , the test generated to confirm the hypothesis could potentially yield results that were either confirmatory or disconfirmatory . @ @ @ @ @ @ @ @ @ @ . To disconfirm the hypothesis that drug x cures colds , one would need to examine cases in which the hypothesis is likely to go wrong , that is , cases suggested by a plausible alternative , such as the operation of the body 's own immune system . To do this , one would use the same design and systematically vary both general health and treatment with drug x in order to measure which of the variables was affecting the course of colds . If general health were found to have a substantial effect and drug x not , then the // results would disconfirm the target hypothesis . But if drug x did have an effect and general health did not , then the results would tend to confirm the hypothesis that drug x is effective . That is , tests to confirm and tests to disconfirm both would involve taking into account plausible alternative hypotheses . At first glance it might seem that one would not need to consider alernative hypotheses in order to test a target hypothesis ? at least if one could rely on direct experimental @ @ @ @ @ @ @ @ @ @ example , for testing the effectiveness of drug x , one could , if circumstances permitted , simply give the drug to half the afflicted population and withold it from the other half , without controlling for the subjects ' general health . However , when this contrastive strategy is carried out well , it is combined with random assignment of a representative sample , in this case random assignment of afflicted subjects to the treatment and control groups . And the reason random assignment is so crucial is precisely because of the assumption that , with a large enough sample , random assignment will control for alternative hypotheses and thus permit them to be ruled out . For example , one assumes that with random assignment from a representative sample , the proportion of subjects in good general health will be roughly comparable in both treatment and control groups . ( Indeed , with random sampling , one assumes that the two groups will be roughly comparable on all sorts of variables , including even those that have not yet been identified as being relevant . ) However , as @ @ @ @ @ @ @ @ @ @ issue of matching arises , and the question of which variables to match on ( that is , the question of alternative hypotheses ) again becomes a concern that has to be explicitly dealt with . Even when random sampling is possible , the question of alternative , or at least additional , explanatory causal variables is also a concern in deciding the more basic question of which population is the representative one from which a random sample should be drawn . The question of whether to test the effectiveness of drug x by drawing a sample from a population in which all the subjects have roughly the same level of general health or by sampling without controlling for level of health depends on one 's beliefs about whether general health provides an alternative interpretation for the effects of the drug ( or at least interacts with the effects of the drug ) and depends as well on the samples to which one wants to generalize the results . Testing a claim about properties of a set The drug example dealt with two possible causes because the general point had to @ @ @ @ @ @ @ @ @ @ concerned with identifying causes . However , in many studies of disconfirmation , the hypothesis in question // concerns the properties of a set of stimuli ; the hypotheses are of the form " As are Bs . " For example , all triangles repel ( Mynatt et al . 1978 ) , " members of the target category are red circles " ( Bruner et al . 1956 ) , and " instances that follow the rule are any increasing series " ( Wason 1960 ) . Nevertheless , with this sort of statement as well the same points apply : good confirmation and disconfirmation strategies require the same test strategies , and each test strategy can yield potentially confirming or disconfirming results . Recall that in Mynatt et al . ' s ( 1977 ) task , the " triangularity hypothesis " that the task was contrived to suggest " included hypotheses with at least some mention of triangularity but no mention of brightness . " To test this hypothesis ( whether to confirm or disconfirm ) , one would have to test two sorts of shapes : nontriangles @ @ @ @ @ @ @ @ @ @ either confirming or disconfirming results . For example , if one tested a square and found that it too repelled , then the hypothesis that only triangles repel would be disconfirmed . But if the square did not repel , then one would be closer to having tested all the nontriangles , thereby getting additional confirmatory evidence . Analogously , if a subject were testing the rule that the series 2 , 4 , 6 exemplified the rule " increasing intervals of two , " then the series 3 , 5 , 7 could yield either confirmatory results or disconfirmatory results , depending on which rule the experimenter had stipulated to be correct . These issues will be relevant in experiments 14 and 15 . Tests versus results If tests to confirm and tests to disconfirm do not involve distinct , mutually exclusive strategies , then what distinguishes hypotheses that are confirmed from those that are disconfirmed ? It is the results of tests , not the tests themselves , that distinguish hypotheses that are confirmed from those that are not , and any test can potentially yield either confirmatory or @ @ @ @ @ @ @ @ @ @ the triangle hypothesis ) or not repel ( disconfirming the hypothesis ) . A nontriangle can either repel ( disconfirming the triangle hypothesis ) or not repel ( thereby providing confirmatory evidence ) . ( Similarly , either drug x or the body 's own immune system can have the greater effect on colds . ) Working from the perspective of decision theory , Klayman and Ha ( 1987 ) have made an argument compatible with the present one that turns on the distinction between tests and results . They argue that many behaviors thought to reflect confirmation bias are better understood as reflecting a general " positive-test strategy , " according to which one tests those instances that are expected to fit the hypothesized rule rather than those expected not to fit . For example , in Mynatt et al . ' s ( 1977 ) task , if one held the hypothesis that triangles repel , then a positive test strategy // would consist of firing the particle only at triangles . That is , Klayman &; Ha 's positive-test strategy is an example of confirmation bias in that @ @ @ @ @ @ @ @ @ @ one 's hypothesis ; it is only part of an appropriate test because it does not include a test of nontriangles as well as triangles . However , Klayman and Ha demonstrate that even the biased positive-test strategy does not always yield confirmatory results . Specifically , they demonstrate that when one is investigating a relatively rare phenomenon , then the positive-test strategy is likely to discover instances that are expected to conform to the hypothesized rule but do not , and thus that falsify the hypothesis . Consider Klayman and Ha 's example : if very few students do well in a graduate program , then carrying out a positive-test strategy ( that is , sampling students who have the characteristics thought to predict success in the program and who have already been admitted ) is very likely to detect students who have the characteristics thought to lead to success but who in fact do not do well in the program . That is , a positive test strategy can detect instances that disconfirm the rule . ( Furthermore , in this case a positive-test strategy is a more efficient @ @ @ @ @ @ @ @ @ @ much larger number of students who are never admitted to the program because they do not have the characteristics thought to predict success . ) Baron was also invoking the distinction between tests and results when he noted that " when we choose a question , ... we do not know in advance what the answer will be " ( 1985 , 131 ) . However , it is worth noting that , even if one thinks in terms of Klayman and Ha 's positive-test strategy , considering alternative hypotheses will still improve the liklihood of detecting instances that disconfirm the target rule . To return to the example above , imagine that the characteristics thought to predict a student 's success in a graduate program include undergraduate grades and quality of letters of reference . Now imagine that in reality these characteristics matter only if the student also received her undergraduate training in a good undergraduate program . If one has this alternative hypothesis in mind , one will be even more likely to detect a disconfirming instance than if one does not , because one will probably be more @ @ @ @ @ @ @ @ @ @ is , to examine the records of students who have good undergraduate grades and letters of reference but who were trained in poor undergraduate programs . Because these students are especially likely to do poorly , choosing to examine their records will make it more likely that one will disconfirm the target rule that it is only undergraduate grades and letters of reference that predict success . ( Of course , the suppresseed premise here is that efficiency is desirable , so testing all graduate students is not an option . ) Consider the issue of disconfirming results with respect to another finding from Mynatt et al . ' s ( 1977 ) research : how can one reconcile the Disconfirming and Anomalous Evidence 65 argument that confirmation and disconfirmation involve the same tests with the finding that subjects who chose the " falsifying " screen ( 5B , a black triangle ) during the free-response phase ( when feedback was provided ) were more likely than those who did not choose it to have a final hypothesis that was correct or partially correct ? Note first that the result of @ @ @ @ @ @ @ @ @ @ does not merely disconfirm the triangle hypothesis ; it also suggests an alternative based on shade . That is , data that falsify and data that suggest an alternative are not mutually exclusive , although they were treated as such in Mynatt et al . ' s studies . Second , testing the black triangle is useful not because of the test itself but because of its results . Testing a black triangle yields evidence that disconfirms the triangle hypothesis , but testing a gray square or a gray disk would also have yielded disconfirming results because both gray figures , though not triangles , would also have repelled the particle . In short , although the black triangle is stipulated to be a disconfirming test while the gray square and gray disk are described as merely providing evidence for an alternative , in fact all three tests would have disconfirmed the triangle hypothesis and would have suggested the alternative of shade . Again , data that falsify and data that suggest an alternative are not mutually exclusive . Why , then , did subjects who chose screen 5B perform better @ @ @ @ @ @ @ @ @ @ , it is important to recall that the black triangle , though stipulated to be merely disconfirmatory , also in fact suggested the alternative shade hypothesis . Therefore , an important question ( not addressed in the study ) would be whether subjects who chose the black triangle ( 5B ) ( stipulated to be disconfirmatory ) performed any better than subjects who chose either the gray square ( 2B ) or the gray disk ( 9B ) ( which also suggested an alternative ) . That is , was there something special about a test stipulated to be " disconfirmatory " ; or was it useful simply because it suggested an alternative ? In addition , consider that , because of the way the task was contrived , the results of testing a black triangle disconfirmed the initial hypothesis ( and added confirmatory evidence to an alternative ) only if the subject generated an initial hypothesis based on triangles and also considered an alternative based on shade . If a subject considered a different ( " incorrect " ) alternative , then choosing the same black triangle might not have @ @ @ @ @ @ @ @ @ @ suggests the alternative of shade only if the subject is already considering the shade alternative before she chooses the screen ( or else is astute enough to realize , after choosing the screen , that the results suggest the alternative of shade ) . In short , these data show that if a subject happens to be considering the correct alternative , either at the outset or after the data suggest // it , then she can make use of data that confirm that the alternative is correct . This finding certainly demonstrates that subjects do take account of data . However , this finding does not demonstrate that there is a special kind of falsifying test nor does it demonstrate that it is this test ( rather than the results of the test and the astuteness of the subject in recognizing what the results suggest ) that propels a subject toward the correct hypothesis . In short , because tests to confirm and tests to disconfirm involve the same strategies , the real measure of whether subjects are open to having their hypothesis disconfirmed is not whether they choose a @ @ @ @ @ @ @ @ @ @ measure is whether they take into account plausible alternative hypotheses ( either by controlling for them or by recognizing them when they are suggested by the results of the tests ) . However , because of the way many hypothesis-testing tasks are structured , it is not possible to determine from the data whether subjects were considering plausible alternatives because the tasks were designed so that questions of plausibility did not arise : in Mynatt et al . ' s task , because genuinely causal relations were not at issue , the correct hypothesis that gray figures repelled was just as plausible as , for example , that figures repelled only if they were in close proximity to another figure . This is in marked contrast to causal claims , in which questions of plausibility play a big role ( an issue to be discussed in the next section ) . Klahr and Dunbar 's ( 1988 ) work is also relevant to the question of what an appropriate test is and to the distinction between tests and results . Klahr and Dunbar found that in their study , subjects sought @ @ @ @ @ @ @ @ @ @ two important points about this . One is that in terms of the framework suggested by Klayman and Ha ( 1987 ) , this was a reasonable strategy . The other is that although subjects often searched for confirming evidence , their search frequently yielded results that were disconfirming and " although adults did not abandon their hypothesis on the basis of a single disconfirming instance , they did attempt to understand inconsistencies " ( 1987 , 137 ) . That is , the subjects did not simply ignore the disconfirming data . Critical confirmation versus straw-person confirmation ' Finally , it is important to note that although confirmation , disconfirmation , and controlling for an alternative hypothesis all involve the same strategies or predictive tests , nevertheless there are certainly several senses in which someone might be said to have a confirmation bias . In the motivational sense , one might carry out a particular test in the fervent hope that the actual results of the test will constitute confirmatory evidence . Furthermore , a motivation to confirm can make it more difficult to genDisconfirming and Anomalous Evidence 67 erate @ @ @ @ @ @ @ @ @ @ out or distort those test results that happen to be disconfirming . However , a confirmation bias might also consist , not in choosing a " confirmatory " testing strategy ( since genuinely " confirmatory " and genuinely " disconfirmatory " strategies are the same ) , but rather in testing the target hypothesis against alternative hypotheses that are implausible and therefore unlikely to be true , that is , in testing a target hypothesis against an alternative that is in fact a straw person . True confirmation bias depends not on formal strategies but rather on estimates of the plausibility of the alternative hypotheses that are seen as potential rivals . And plausibility estimates ordinarily depend on information about theory or causal mechanism . Consider an extreme example : Imagine that on the basis of school records from several large cities in the Northeast , a researcher formulates the hypothesis that boys from father-absent homes do not do well in school because they lack a male role model . A plausible alternative hypothesis would be that the causal factor is not the absence of a male role model but rather @ @ @ @ @ @ @ @ @ @ family headed by a female . Imagine further that , instead of testing the plausible alternative hypothesis , the researcher tries to muster supporting data by documenting that the same relation ( between absence of a father and poor school performance ) also obtains in several large cities in the Midwest . This test would be an example of straw-person confirmation : it would rule out the unlikely alternative that absence of a father produces poor school performance only in large cities in the Northeast , but it would leave untested the plausible alternative that it is really poverty rather than the absence of a role model that is the culprit . In many studies of disconfirmation , it is impossible to tell whether subjects were engaging in straw-person confirmation , because the tasks were designed so that issues of plausibility did not arise . For example , in Mynatt et al . ' s task the tacit premise is that there is only one alternative to the triangle hypothesis ' that subjects consider , namely shade . But , of course , subjects could easily have considered others ( for @ @ @ @ @ @ @ @ @ @ on whether it was physically close to another of a different shade , etc . ) . In Mynatt et al . ' s task , unless a subject was prescient , there was no way of deciding that some alternatives were plausible and others not . The objects that repelled the particle had nothing to do with genuinely causal relations , such as electromagnetic forces . They were arbitrarily chosen , noncausal figures . The experimenters could just as reasonably have stipulated that black rather than gray objects would be the repellers or that an object would repel only if it were close to another of the same shade . Similarly , the rule of " numbers in increasing order of magnitude " was equally arbitrary and therefore // no more or less plausible than the alternatives the subjects themselves generated . I mention this to point out that because these sorts of tasks were theoretically impoverished , there was no opportunity to study a very important way in which true confirmation bias operates , namely , by leading one to test a target hypothesis against implausible rather than plausible @ @ @ @ @ @ @ @ @ @ , there was no basis for distinguishing hypotheses that subjects considered plausible from those that they considered implausible in the way in which plausible hypotheses are typically identified in scientific inquiry . ( Of course , there is a way in which uncritical confirmation could have occurred even in this task : the alternative hypotheses could have been irrelevant to the task as it is usually construed . For example , " I want to see whether it matters if the window in the interview room is open or closed . " However , this sort of construal is probably rare . ) In Klahr and Dunbar 's task , there was a sense in which issues of plausibility were dealt with . Given how programming tasks are usually structured , there were only two reasonable hypotheses : the " N-role : counter " frame and the " N-role : selector " frame . Of these , the " N-role : counter " frame was the more plausible hypothesis . And in fact this is the working hypothesis that subjects typically chose first . A Corollary about Inferring Motive Some of @ @ @ @ @ @ @ @ @ @ motivations in various cognitive tasks . However , recall that any particular test can yield results that are potentially confirmatory or disconfirmatory . Thus in carrying out any particular test , one can fervently hope for confirmatory rather than disconfirmatory results . However , irrespective of one 's hopes , the tests for confirmation and for disconfirmation are the same . Therefore , if the only information the researcher has is that a particular test was carried out , one can not infer whether , in carrying out the test , the subject 's motivational aim ( or hope ) was to gather confirmatory or disconfirmatory results . In many of the tasks described above , the subjects were not asked to verbalize whether their motivation was to acquire confirmatory results that ruled out an alternative or disconfirmatory results in favor of an alternative . Therefore , in these tasks , conclusions about whether or not subjects held a confirmation bias ( in the sense of hoping for confirmatory results ) could not be drawn . As an example of how inferring motivation on the basis of testing strategy can be @ @ @ @ @ @ @ @ @ @ Tweney study . In that study the authors draw a sharp distinction between " disconfirming a triangle hypothesis " and " providing evidence for an Disconfirming and Anomalous Evidence 69 alternative to a triangle hypothesis . " And they treat the former as being the more scientifically sophisticated of the two strategies . However , in terms of my earlier argument , seeking evidence for an alternative hypothesis is in fact exactly one of the strategies that scientists rely on when they aim to disconfirm a target hypothesis . That is , these two activities need not reflect two different motivational aims . And in terms of the information sought , the different activities converge . Articulating or Modifying Working Hypotheses The following sections discuss another reason why it is sometimes difficult to decide whether subjects are exhibiting a confirmation bias , namely that often , though not always , it is scientifically legitimate to deal with anomalous evidence not by rejecting the hypothesis but by treating it as a working hypothesis to be modified in order to accommodate the evidence . As already noted in chapter 2 , in the @ @ @ @ @ @ @ @ @ @ that hypotheses are supposed to be tested in an all-or-nothing way : the hypothesis is supposed to be treated as having been either confirmed or ( outright ) disconfirmed . The result is that correct performance consists of treating the anomalous evidence as warranting outright rejection of the target hypothesis rather than as calling merely for its modification or elaboration to take account of new data . That is , because of the way the tasks are structured , this approach ignores a crucial aspect of scientific inquiry : the ways in which scientists learn about a phenomenon by successive approximation . Often , when a precisely formulated hypothesis is refuted by data or a less precisely formulated one is faced with unanticipated data , it is rational for scientists to adopt a version of the hypothesis reformulated to account for those data rather than to reject the hypothesis as altogether a mistake . Recall as well that in the case of precisely formulated hypotheses , interpreting anomalous data as requiring theory modification in this way is a special case of treating the data as disconfrrmatooy . The rest of this @ @ @ @ @ @ @ @ @ @ following argument : Hypothesis modification can be scientifically legitimate because it can involve specifying more precisely which of the many variables operating in a situation might be constraining the effectiveness of the target cause . Viewed from a different perspective , it can involve specifying more precisely the situations in which a mechanism will produce an expected covariation . However , some modifications are more likely to be scientifically legitimate than others : some preserve the real insights of the original hypothesis ; others are ad hoc attempts to save it from outright disconfirmation . Therefore , the question of when theory // modification is scientifically legitimate has implications for the question of confirmation bias . Causal relations involve many variables , some unspecified In many cognitive tasks , part of the reason anomalous evidence can be treated as outright disconfirming rather than as modifying or elaborating is that the hypotheses ( or at least the ones the experimenter , if not necessarilly the subject , has in mind ) involve a small number of variables and can therefore be specified in a very circumscribed way . For example , in @ @ @ @ @ @ @ @ @ @ that the experimenters aim to induce is a simple one : all and only triangles repel . ( And the " correct " alternative ? that all and only gray figures repel ? is equally simple . ) That is , because each hypothesis is based on only one variable , a single triangle that does not repel is a sufficient reason for rejecting the triangle hypothesis . The problem with this sort of approach is that , although the experimenter may have it in mind that only shape and shade are important , the subject can be ( and often is ) thinking of several other variables ( location on the screen , proximity to other figures , etc. ) that might also be playing a role ( and in addition , the hypotheses they consider are often less precise working hypotheses ) ( Koslowski and Maqueda 1993 ; see experiments 14 and 15 , chapter 11 ) . The result is that a single anomalous instance need not call for outright rejection of the subject 's hypothesis . For example , if the subject is considering screen location as @ @ @ @ @ @ @ @ @ @ repel might indicate not that triangles in general do not repel but that triangles do not repel when they are located in that quadrant of the screen . And this mimics real life in the empirical , rather than the logical , world . Hypotheses are almost never as precise as they could be in principle because , for any hypothesis , there are , in principle numerous conditions that could be specified ( but typically are not ) as being either relevant or irrelevant to the hypothesis . That is , even when they are formulated in an apparently precise way , many hypotheses are working hypotheses in which numerous potentially relevant and irrelevant variables are not specified and may not even be known . For example , a working hypothesis might be that drug x cures colds . Such a hypothesis would not ( and possibly could not ) specify that drug x might cure colds only in certain doses , only if administered intravenously rather than orally , etc. ; or that its effectiveness might be not at all affected by type of virus , nutritional status , @ @ @ @ @ @ @ @ @ @ variables can be identified as likely to be relevant ( or irrelevant ) beforehand by relying on the results of previous research and existing theoretical expectations , some can he discovered to be relevant ( or irrelevant ) only after additional // evidence ( including anomalous evidence ) has been gathered . For example , if drug x is found to be ineffective in people below a certain age , this suggests that the patient 's age is a relevant variable . Conversely , if it is found to be effective at all ages , this suggests that the patient 's age is not relevant . What this means in practice is that it is very easy ( and often appropriate ) to elaborate an imprecise theory or to modify ( rather than to reject outright ) a more precise theory by invoking an additional variable as a constraint on the target factor ( drug x works but not for certain age groups ) . Thus , although any particular , very specific hypothesis ( a local hypothesis , in Klahr and Dunbar 's 1988 terminology ) can be either significantly @ @ @ @ @ @ @ @ @ @ many cases ( and probably the cases employed in psychological studies ) the appropriate response to anomalous data is modification rather than outright rejection . Such modifications allow one to maintain the basic working hypothesis ( Klahr and Dunbar 's global hypothesis ) but they also enable one to further articulate the working hypothesis , that is , to specify it more precisely in a way that takes account of the anomalies . Therefore , to focus only on confirmation and outright disconfirmation is to ignore the important activity of modification or articulation . Unless there is an alternative theory that can explain not only the instances in which drug x does not cure colds but also the instances in which it does ( and which suggested the hypothesis in the first place ) , then it may make sense to keep the theory that drug x does cure colds but to treat it as a working hypothesis to be modified so that it is seen as applying in only certain situations . ( By way of underlining the importance of modification rather than outright rejection in many situations , consider @ @ @ @ @ @ @ @ @ @ posited , as a working hypothesis , a perfectly spherical earth , found some disconfirming measurements , and in consequence rejected rather than modified the perfect-sphere hypothesis in favor of the flat alternative . ) Within Klahr and Dunbar 's ( 1988 ) system , hypothesis change can occur either within a frame or by changing frames . When hypothesis change occurs within a frame , there are only minor differences between adjacent hypotheses ; subjects change the values of only one or a few of the attributes . However , when a subject generates a different frame , there are large differences between two hypotheses ; subjects change the values of all four attributes in the frame . Klahr and Dunbar use this finding to reinterpret Mynatt et al . ' s ( 1978 ) data . They suggest that Mynatt et al . ' s " subjects were exploring frames and switching frames after they had exhausted all possible values of the frame . In fact , Mynatt et al . ( 1978 ) note that many hypotheses were minor variations on a previous hypothesis ? which is congruent @ @ @ @ @ @ @ @ @ @ were also occasional large differences in adjacent hypotheses ? indicating a switch to a new frame " ( Klahr and Dunbar 1988 , 41 ) . Klahr and Dunbar 's description of Mynatt et al . ' s subjects as exploring hypotheses within a frame is analogous to my suggestion that Mynatt et al . ' s subjects could be construed not as mechanically seeking confirming evidence but rather as refining and testing the limits of the working hypothesis ( the frame ) that they were currently considering and as relying on the disconfirming evidence to explain the exceptions and in some cases to suggest an alternative . Finally , to elaborate a point suggested in the preceding chapter , rejecting an explanation ( even an incorrect explanation ) when there is no viable alternative with which to replace it is to leave oneself with no framework within which to organize the data ? be it the " confirming " data that suggested the hypothesis in the first place or the anomalous data calling it into question . If nothing else , such a framework , by providing a way of @ @ @ @ @ @ @ @ @ @ it might also make it easier to detect a situation in which the anomalous data suggest an alternative because they form a pattern ( as such data did in the Karmiloff-Smith and Inhelder 1974/1975 study . ) In short , rejecting a hypothesis ( especially a global hypothesis ) outright at the first sign of anomalous data is not always efficient . Rejecting it might be methodologically unwise because the hypothesis might be basically correct . And rejecting it in the absence of an alternative might make it harder to apprehend a pattern in the anomalous data that could suggest an alternative . Disconfirming covariation but ignoring mechanism The fact that there are often many causal variables operating in a situation is also relevant to the suggestion , mentioned briefly in chapter 2 , that it is often reasonable to maintain an explanation in the face of disconfirming evidence if the evidence disconfirms the covariation component of the explanation but leaves the mechanism component intact . In this regard , consider the finding of Kuhn et al . ( 1988 ) that it was more difficult to disconfirm subjects ' causal @ @ @ @ @ @ @ @ @ @ difference in difficulty have indicated that subjects were allowing their theoretical beliefs to override information about covariation ? If so , might this have reflected a confirmation bias ? I suggest that the results are ambiguous , because of the nature of the anomalous evidence that subjects were presented with . Kuhn et al . disconfirmed ( and confirmed ) subjects ' beliefs about which foods did and did not covary with colds . However , as Kuhn et al . note , there is some evidence from subjects ' justifications that their beliefs about covariation were accompanied by beliefs about mechanism ( sometimes // explicitly referred to by Kuhn et al . as beliefs about mechanism and sometimes , I argued in chapter 2 , coded as " intuition " ) . This is important because it is beliefs about mechanism that in part determine assessments of plausibility . Subjects found their beliefs about covariation plausible because , in many cases , the beliefs were accompanied by a belief in a mechanism that explained how the covariation was brought about . ( " Orange juice makes you healthier because it @ @ @ @ @ @ @ @ @ @ Kuhn et al . disconfirmed subjects ' beliefs , the anomalous or disconfirming evidence dealt only with the covariation component of the subject 's belief . For example , if the subject 's belief was that type of juice covaries with colds , the disconfirming evidence was simply that the two did not always covary . Thus the disconfirming evidence left intact the belief about the mechanism ( " lots of vitamins " ) that had been expected to bring about covariation . This left subjects with the possibility that the mechanism would continue to operate and that the expected covariations would continue to obtain but not , for some reason , in the particular situation described in the experiment . And given the many variables that can be causally relevant to a situation , this was not unreasonable . One can imagine thinking , for example , that there might be something about the children at this particular school that made it difficult for type of juice to have the expected effect but that in other schools or for other groups of children , type of juice would indeed covary @ @ @ @ @ @ @ @ @ @ Kuhn et al . ' s finding that it is harder to disconfirm a causal belief than a noncausal belief is that in the former case two components need to be replaced : a belief about covariation and a belief about the mechanism that accounts for the covariation . However , in the latter case , when the belief in the covariation is undermined , there is no additional belief about mechanism to be dealt with . Kuhn et al . make roughly the same point when they conclude that when evaluating data that disconfirm a causal belief , subjects do not distinguish the disconfirming evidence that shows that covariation does not obtain from the theoretical belief according to which the covariation ought to obtain . The difference between their approach and the approach taken here is that Kuhn et al . treat subjects ' concern with mechanism as an obstacle that interferes with their ability to assess anomalous covariation ( or noncovariation ) data . In contrast , on the approach taken here , taking account of the mechanism is reasonable ; it means taking account of all , rather @ @ @ @ @ @ @ @ @ @ , in terms of the point made in the preceding section , this is often reasonable . By way of analogy , consider what would happen if data came to light that , on the surface , seemed to disconfirm the hypothesis that penicillin cures bacterial infections . Imagine , for example , that several ( even hundreds of ) people with bacterial infections were treated with penicillin and // nevertheless failed to improve . I suggest that , even if the number of such subjects was very large , one would nevertheless be reluctant to reject the hypothesis that penicillin cures bacterial infections . As a first step , one might question the validity of the data by asking about some of the many variables that could have interfered with the operation of the penicillin . ( Could that particular batch of penicillin have been defective , improperly stored ? Could the dosage have been inadequate ? ) But , even if the data were judged to be valid , I suggest that , again like T. S. Kuhn ' s ( 1970 ) scientists , one would not leap @ @ @ @ @ @ @ @ @ @ try to treat the hypothesis as a working hypothesis to be modified to take account of the disconfirming data , and one would cast about for possible variables that might have prevented the penicillin from bringing about the expected covariation in this situation . One might wonder , for example , whether the subjects were afflicted with a new strain of bacteria that is resistant to penicillin or whether their general nutritional status was so poor that even penicillin could not be effective . That is , one would certainly not accept the hypothesis in its current form , but one would also not altogether reject it in light of the disconfirming data ; one would modify it . In a word , as noted in chapter 2 , one might well conclude , as Kuhn et al . ' s subjects did , that the hypothesis " was right with respect to those instances that conformed to the covariation pattern but was wrong with respect to those instances that did not " ( 1988 , 126 ) . As we have seen earlier , there are often so many variables @ @ @ @ @ @ @ @ @ @ about one situation in which it does not still leaves the possibility that it will operate in other situations . ( However , as I argue below , one would also probably try to specify what it was about the various instances that made the hypothesis not applicable to them . ) More to the point , I would argue that such an approach is reasonable . For most people , a belief in the efficacy of penicillin includes some notion , however rudimentary , that the mechanism by which penicillin works is that it makes it difficult for germs to survive and reproduce . Without data that suggest that this mechanism is incorrect and ought to be relinquished , it is reasonable to expect that the mechanism would continue to operate , that is , that penicillin would continue to kill germs , though perhaps not bacteria of this particular sort or in these particular patients . Such an approach would be especially reasonable given the many variables that can operate in a situation to limit the effectiveness of medication ( for example , dosage , nutritional status of patients @ @ @ @ @ @ @ @ @ @ relation to Kuhn et al . ' s finding that some subjects in the colds study did not acknowledge the disconfirming evidence until after they had articulated a modified theory to account for the evidence . For example , after having first claimed that type of condiment // would make no difference , a ninth-grader responded to the evidence that type of condiment did covary with colds by suggesting , in one of his early responses , that mustard has more ingredients than catsup and this makes it good for one 's health and then that mustard is used on things that are either hot or cold while catsup is used only on hot things . Only after doing this did the subject make reference to the covariation evi-dence . As Kuhn et al . note , " It appears almost as if they are not willing to acknowledge the implications of the evidence unless they have a compat ible theory in place that can provide an explanation of this evidence " ( 1988 , 83 ) . I would argue that when subjects adopt this strategy , it is because @ @ @ @ @ @ @ @ @ @ and not the mechanism component , of their beliefs and they see no reason to relinquish their beliefs because the mechanism component has not been replaced . When they are finally able , on their own , to generate a replacement for their intially proposed mechanism that enables them to treat the anomalous data as more than a fluke , then they treat those data as being harder to dismiss . ( However , I would also argue that the very fact that they were trying to generate a modified replacement for the mechanism component indicates that they were , at least tacitly , acknowl edging the disconfirming evidence all along and treating it as cause for concern . The fact that they did not explicitly mention it until they were able to generate their own replacement mechanism does not necessarilly mean that they were thinking neither about it nor about its problematic implications for the explanation . ) I am not arguing here that even sixth-graders have a precise under-standing of how it is that different types of foods cure colds . I am arguing that they have some rudimentary @ @ @ @ @ @ @ @ @ @ and that the mechanism probably has something to do with the immune system or with an undifferentiated notion of general health . And some support for this is that when Kuhn et al . ( 1988 ) used material that was more neutral , namely sports balls , sub jects were more likely to treat anomalous covariation evidence as calling the hypothesis into question . ( Note also that this argument is analogous to the point made in chap-ter 2 regarding Kuhn et al . ' s sports-balls study . " Most " subjects identified color as causally irrelevant to bounce and did not suspend this belief when presented with data in which color and , for example , texture were confounded so that both covaried with bounce . In terms of the present argument and in light of some of the justifications given by the subjects , such as that rough texture makes the balls heavier , I would suggest that subjects did not suspend their belief that color was irrelevant , because , although the anomalous evidence demonstrated that color was one of the factors that covaried with bounce @ @ @ @ @ @ @ @ @ @ the process by which differences in color could produce differences in bounce . ) As already noted , experiment 13 , chapter 10 , suggests that disconfirming evidence that deals with the mechanism component as well as the covariation component of a belief is more compelling than disconfirming evidence that deals with covariation alone . To return to the question of theory modification and elaboration , if additional possible causes are likely to exist that might restrict the application of , and therefore provide a way of modifying or elaborating an explanation , then an obvious problem arises : how does one decide when modification or elaboration is warranted or when , instead , outright rejection would be more appropriate ? This question is addressed in the following section . Theoretically motivated modifications versus ad hoc modifications The question of when theory modification rather than outright rejection is appropriate is not trivial : in noncontrived situations , there are often so many potentially causal variables that can restrict a belief that , in the face of anomalous data , an explanation can invariably be modified by invoking one of the variables @ @ @ @ @ @ @ @ @ @ as expected in a particular situation . ( Similarly , there are often so many situations in which a mechanism is expected to produce an effect that learning about one situation in which the effect does not obtain still leaves the possibility that the mechanism will operate in other situations . ) The result is that in principle one can always respond to anomalous data simply by modifying a hypothesis to account for it . However , in practice there are limits on the extent to which some modifications are seen as warranted ; there is no question that explanations sometimes ought to be altogether rejected rather than merely modified , given the evidence . The tension between modifications that are seen as warranted and those that are not is reflected in the distinction between theory modification , which is treated as a legitimate response to anomalous data , and what is often pejoratively called " ad hoc theorizing , " which is seen as an unwarranted attempt to " patch up " a theory in the face of anomalous data when the theory in fact ought to be discarded . @ @ @ @ @ @ @ @ @ @ rejecting an explanation is based on several factors . Many of these have to do with the explanation itself , such as the nature and amount of evidence that supports it and the extent to which one 's commitment to it has emotional components . However , the decision to modify rather than to reject is also often based on the structure of the anomalous data itself and on one 's ( sometimes only tacit ) theory about how this structure makes it more // or less difficult for a variation of the explanation to accommodate the anomalies . An important consideration that distinguishes warranted from unwarranted modifications ( though by no means the only one ) involves information about mechanism . Briefly , modifications are theoretically motivated rather than ad hoc when there are plausible mechanisms to explain the anomalous data while maintaining the basic explanatory strategy of the original hypothesis . For example , if one learns that a drug aimed at curing colds is not effective for the elderly and that there is a mechanism that might account for this ( namely that the elderly metabolize it too @ @ @ @ @ @ @ @ @ @ the hypothesis that it is effective but to modify it by explaining how the drug 's effectiveness is constrained by metabolism . That is , the mechanism that accounts for the anomaly also refines our understanding of how the target factor operates by explaining why it will not operate in certain situations . As an extension of this point , if the anomalies seem to form a pattern ( for example , if the patients for whom drug x is not effective all share a common feature , such as a chronic illness like diabetes or high blood pressure ) , then even if there is no plausible mechanism currently known that can explain the anomalies , the pattern formed by the common feature might suggest that one will eventually be discovered . ( One can imagine discovering , for example , that the stress on the body induced by chronic illness interferes with the way the drug is absorbed . ) That is , a pattern in the anomalies might refine our understanding of how the drug works by helping us discover one of the mechanisms that constrains the drug @ @ @ @ @ @ @ @ @ @ mechanisms motivate modification rather than outright rejection of a theory illustrates a point familiar from the philosophy of science concerning the distinction between justified and ad hoc modifications to a theory in the face of anomalous data . Theoretically motivated modifications are seen as appropriate because they represent a strategy for " fine-tuning " or amplifying our understanding of the relevant causal factor(s) . Because they add to our understanding of when a relevant causal factor fails to operate , they tell us something about the conditions that must be being satisfied when the causal factor does operate . A modification based either on a hypothesis about the causal mechanisms that brought the anomalies about or on a pattern in the anomalies ( which might suggest art underlying , undiscovered mechanism ) would be seen as more likely to be warranted in that it would add to our understanding of when and how the operation of the causal factor is affected by other variables . In contrast , modification would be seen as less likely to be warranted when the anomalies do not form a pattern , that is , when @ @ @ @ @ @ @ @ @ @ idiosyncratic rather than common features and/or when there is no causal mechanism that can account for the anomalies . For example , suppose that there were three sizable groups for whom the drug did not work . The obvious next step would be to try to identify what the members of the groups had in common that distinguished them from the people for whom the drug did work . Next suppose it was discovered that , relative to the people for whom the drug was effective , the only differences were that one group consisted of people who were more likely to drive Chryslers than Fords , another group consisted of people more likely to own IBMs than Macs , and the third group consisted of people more likely to wear single-breasted coats than double-breasted coats . Suppose also that there are no known mechanisms that could explain how these three factors could interfere with the drug 's effectiveness . In such a situation , the lack of a common pattern among the three groups and the lack of mechanisms to explain the anomalous groups would make it difficult to refine @ @ @ @ @ @ @ @ @ @ some ) of the anomalous individuals happened , for example , to be more likely to wear single-breasted rather than double-breasted coats could easily be merely a fluke . Of course , if the three groups for whom the drug was not effective were all discovered to have some fourth factor in common or if mechanisms came to be discovered that could explain how each of these factors could have interfered with the drug 's effectiveness , then that would be a different story . However , without a systematic pattern ( that is , a commonality ) among the anomalous instances , the anomalies do little to help us refine our theory . Instead , they detract from the theory 's overall credibility rather than help to specify it more precisely . They suggest that in those cases in which the drug seemed to cure colds , perhaps it was really the body 's own immune system that was working . This in turn might lead one to discover that the anomalies actually did have something in common ( namely a poorly functioning immune system ) , but the discovery @ @ @ @ @ @ @ @ @ @ hypothesis that the drug cured colds in favor of the hypothesis that it was the body 's own immune system that was responsible . In this case , insofar as we discerned a pattern or commonality in the anomalious groups , our discovery would call the target account into question . ( And , as suggested earlier , such a pattern might be easier to detect with the original hypothesis in place as a framework within which to organize the anomalous data . ) As we will see in experiment 11 , chapter 9 , in evaluating anomalies to an explanation , subjects do rely on information both about mechanism and about patterns formed by common features . The importance of theoretically motivated hypothesis modification is related to the notion that science involves bootstrapping . The strategy of // modifying a hypothesis if anomalies to it form a pattern or if there are mechanisms to explain them is a strategy that can be used to discover additional variables that can add to our knowledge of the phenomenon by articulating more precisely the situations in which it obtains . However , such @ @ @ @ @ @ @ @ @ @ patterns actually do reflect mechanisms rather than coincidence and only if the mechanisms invoked to explain the anomalies are approximately correct . Furthermore , in the case of complex phenomena , one can imagine that even if the anomalies have nothing in common , it might still make sense to preserve the explanation by modifying it because if a large number of variables are causally related to the phenomenon , it might well be that there are many different restrictions that constrain the target and that each restriction produces a distinct type of anomaly . That is , the strategy in question is not an algorithm ; it is at best a first step . Subsequent steps must examine additional evidence . In light of the above discussion , consider again the frequent conclusion that one type of evidence for a confirmation bias is that in the face of some anomalous data , subjects modify rather than reject their theories . On the view being taken here , such a modification strategy would constitute a confirmation bias only if the modification were nontheoretically motivated or ad hoc , that is , @ @ @ @ @ @ @ @ @ @ nor proposed a mechanism to account for them . However , in the typical study of how subjects respond to anomalous evidence , the distinction between theoretically motivated and nontheoretically motivated modification does not arise , and as a result , such studies may provide a misleading picture of the situations in which subjects are reasoning in a scientifically legitimate way . To return to Mynatt et al . ' s ( 1978 ) task , the premise was that there were basically two viable hypotheses that the subject would consider : the target triangle hypothesis and the alternative based on shade . Thus the assumption was that reasonable behavior would consist of treating anomalous evidence as warranting rejecting the hypothesis in favor of the alternative rather than as calling for its modification or elaboraion . However , in this task , subjects do consider hypotheses other than simple shape and shade ( Koslowski and Maqueda 1993 ; see experiments 14 and 15 , chapter 11 ) . Furthermore , since the task does not involve genuine causal relations , there is no reason for subjects to think that any single @ @ @ @ @ @ @ @ @ @ . And in consequence , there is also no reason to believe that hypothesis modification or elaboration , rather than rejection , would be inappropriate . For example , if a particular triangle did not repel and that triangle were near a gray circle , then given the structure of the task , there would be no reason to assume it would be inappropriate to modify                     