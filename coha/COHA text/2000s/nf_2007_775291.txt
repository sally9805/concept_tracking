@@775291

Who 's Doing Your Thinking for You ? // Recommendations make life a lot easier . Want to know what movie to rent ? The traditional way was to ask a friend or to see whether reviewers gave it a thumbs-up. // Nowadays people are looking for Internet guidance drawn from the behavior of the masses . Some of these " preference engines " are simple lists of what 's most popular . The New York Times lists the " most emailed articles . " iTunes lists the top downloaded songs . Del.icio.us lists the most popular Internet bookmarks . These simple filters often let surfers zero in on the greatest hits . // Some recommendation software goes a step further and tries to tell you what people like you enjoyed . Amazon.com tells you that people who bought The Da Vinci Code also bought Holy Blood , Holy Grail . Netflix gives you recommendations that are contingent on the movies that you yourself have recommended in the past . This is truly " collaborative filtering , " because your ratings of movies help Netflix make better recommendations @ @ @ @ @ @ @ @ @ @ to you . The Internet is a perfect vehicle for this service because it 's really cheap for an Internet retailer to keep track of customer behavior and to automatically aggregate , analyze , and display this information for subsequent customers . // Of course , these algorithms are n't perfect . A bachelor buying a one-time gift for a baby could , for example , trigger the program into recommending more baby products in the future . Wal-Mart had to apologize when people who searched for Martin Luther King : I Have a Dream were told they might also appreciate a Planet of the Apes DVD collection . Amazon.com similarly offended some customers who searched for " abortion " and were asked " Did you mean adoption ? " The adoption question was generated automatically simply because many past customers who searched for abortion had also searched for adoption . // Still , on net , collaborative filters have been a huge boon for both consumers and retailers . At Netflix , nearly two-thirds of the rented films are recommended by the site . And recommended films are rated half @ @ @ @ @ @ @ @ @ @ ) than films that people rent outside the recommendation system . // While lists of most-emailed articles and best-sellers tend to concentrate usage , the great thing about the more personally tailored recommendations is that they diversify usage . Netflix can recommend different movies to different people . As a result , more than 90 percent of the titles in its 50,000-movie catalog are rented at least monthly . Collaborative filters let sellers access what Chris Anderson calls the " long tail " of the preference distribution . The Netflix recommendations let its customers put themselves in rarefied market niches that used to be hard to find . // The same thing is happening with music . At Pandora.com , users can type in a song or an artist that they like and almost instantaneously the website starts streaming song after song in the same genre . Do you like Cyndi Lauper and Smash Mouth ? Voila , Pandora creates a Lauper/Smash Mouth radio station just for you that plays these artists plus others that sound like them . As each song is playing , you have the option of teaching @ @ @ @ @ @ @ @ @ @ I really like this song " or " Do n't play this type of song again . " // It 's amazing how well this site works for both me and my kids . It not only plays music that each of us enjoys , but it also finds music that we like by groups we 've never heard of . For example , because I told Pandora that I like Bruce Springsteen , it created a radio station that started playing the Boss and other well-known artists , but after a few songs it had me grooving to " Now " by Keaton Simons ( and because of on-hand quick links , it 's easy to buy the song or album on iTunes or Amazon ) . This is the long tail in action because there 's no way a nerd like me would have come across this guy on my own . A similar preference system lets Rhapsody.com play more than 90 percent of its catalog of a million songs every month . // MSNBC.com has recently added its own " recommended stories " feature . It uses a @ @ @ @ @ @ @ @ @ @ most recently read and uses automated text analysis to predict what new stories you 'll want to read . It 's surprising how accurate a sixteen-story history can be in kickstarting your morning reading . It 's also a bit embarrassing : in my case American Idol articles are automatically recommended . // Still , Chicago law professor Cass Sunstein worries that there 's a social cost to exploiting the long tail . The more successful these personalized filters are , the more we as a citizenry are deprived of a common experience . Nicholas Negroponte , MIT professor and guru of media technology , sees in these " personalized news " features the emergence of the " Daily Me "  --  news publications that expose citizens only to information that fits with their narrowly preconceived preferences . Of course , self-filtering of the news has been with us for a long time . Vice President Cheney only watches Fox News . Ralph Nader reads Mother Jones . The difference is that now technology is creating listener censorship that is diabolically more powerful . Websites like Excite.com and Zatso.net started to @ @ @ @ @ @ @ @ @ @ and " a personalized newscast . " The goal is to create a place " where you decide what 's the news . " Google News allows you to personalize your newsgroups . Email alerts and RSS feeds allow you now to select " This Is the News I Want . " If we want , we can now be relieved of the hassle of even glancing at those pesky news articles about social issues that we 'd rather ignore . // All of these collaborative filters are examples of what James Surowiecki called " The Wisdom of Crowds . " In some contexts , collective predictions are more accurate than the best estimate that any member of the group could achieve . For example , imagine that you offer a $100 prize to a college class for the student with the best estimate of the number of pennies in a jar . The wisdom of the group can be found simply by calculating their average estimate . It 's been shown repeatedly that this average estimate is very likely to be closer to the truth than any of the individual @ @ @ @ @ @ @ @ @ @ too low  --  but collectively the high and low estimates tend to cancel out . Groups can often make better predictions than individuals . // On the TV show Who Wants to Be a Millionaire , " asking the audience " produces the right answer more than 90 percent of the time ( while phoning an individual friend produces the right answer less than two-thirds of the time ) . Collaborative filtering is a kind of tailored audience polling . People who are like you can make pretty accurate guesses about what types of music or movies you 'll like . Preference databases are powerful ways to improve personal decision making . // eHarmony Sings a New Tune // There is a new wave of prediction that utilizes the wisdom of crowds in a way that goes beyond conscious preferences . The rise of eHarmony is the discovery of a new wisdom of crowds through Super Crunching . Unlike traditional dating services that solicit and match people based on their conscious and articulated preferences , eHarmony tries to find out what kind of person you are and then matches you with @ @ @ @ @ @ @ @ @ @ looks at a large database of information to see what types of personalities actually are happy together as couples . // Neil Clark Warren , eHarmony 's founder and driving force , studied more than 5,000 married people in the late 1990s . Warren patented a predictive statistical model of compatibility based on twenty-nine different variables related to a person 's emotional temperament , social style , cognitive mode , and relationship skills . // eHarmony 's approach relies on the mother of Super Crunching techniques  --  the regression . A regression is a statistical procedure that takes raw historical data and estimates how various causal factors influence a single variable of interest . In eHarmony 's case the variable of interest is how compatible a couple is likely to be . And the causal factors are twenty-nine emotional , social , and cognitive attributes of each person in the couple . // The regression technique was developed more than 100 years ago by Francis Galton , a cousin of Charles Darwin . Galton estimated the first regression line way back in 1877 . Remember Orley Ashenfelter 's simple equation to @ @ @ @ @ @ @ @ @ @ a regression . Galton 's very first regression was also agricultural . He estimated a formula to predict the size of sweet pea seeds based on the size of their parent seeds . Galton found that the offspring of large seeds tended to be larger than the offspring of average or small seeds , but they were n't quite as large as their large parents . // Galton calculated a different regression equation and found a similar tendency for the heights of sons and fathers . The sons of tall fathers were taller than average but not quite as tall as their fathers . In terms of the regression equation , this means that the formula predicting a son 's height will multiply the father 's height by some factor less than one . In fact , Galton estimated that every additional inch that a father was above average only contributed two-thirds of an inch to the son 's predicted height . // He found the pattern again when he calculated the regression equation estimating the relationship between the IQ of parents and children . The children of smart parents were @ @ @ @ @ @ @ @ @ @ their folks . The very term " regression " does n't have anything to do with the technique itself . Dalton just called the technique a regression because the first things that he happened to estimate displayed this tendency  --  what Galton called " regression toward mediocrity "  --  and what we now call " regression toward the mean . " // The regression literally produces an equation that best fits the data . Even though the regression equation is estimated using historical data , the equation can be used to predict what will happen in the future . Dalton 's first equation predicted seed and child size as a function of their progenitors ' size . Orley Ashenfelter 's wine equation predicted how temperature and rain would impact wine quality . // eHarmony produced a formula to predict preference . Unlike the Netflix or Amazon preference engines , the eHarmony regression is trying to match compatible people by using personality and character traits that people may not even know they have or be able to articulate . Indeed , eHarmony might match you with someone that you might never have @ @ @ @ @ @ @ @ @ @ of crowds that goes beyond the conscious choices of individual members to see what works at unconscious , hidden levels . // eHarmony is not alone in trying to use data-driven matching . Perfectmatch matches users based on a modified version of the Myers-Briggs personality test . In the 1940s , Isabel Briggs Myers and her mother Katharine Briggs developed a test based on psychiatrist Carl Jung 's theory of personality types . The Myers-Briggs test classifies people into sixteen different basic types . Perfectmatch uses this M-B classification to pair people who have personalities that historically have the highest probability of forming lasting relationships . // Not to be outdone , True.com collects data from its clients on ninety-nine relationship factors and feeds the results into a regression formula to calculate the compatibility index score between any two members . In essence , True.com will tell you the likelihood you will get along with anyone else . // While all three services crunch numbers to make their compatibility predictions , their results are markedly different . eHarmony believes in finding people who are a lot like you . " What @ @ @ @ @ @ @ @ @ @ " is to find somebody whose intelligence is a lot like yours , whose ambition is a lot like yours , whose energy is a lot like yours , whose spirituality is a lot like yours , whose curiosity is a lot like yours . It was a similarity model . " // Perfectmatch and True.com in contrast look for complementary personalities . " We all know , not just in our heart of hearts , but in our experience , that sometimes we 're attracted to , indeed get along better with , somebody different from us , " says Pepper Schwartz , the empiricist behind Perfectmatch . " So the nice thing about the Myers-Briggs was it 's not just characteristics , but how they fit together . " // This disagreement over results is n't the way data-driven decision making is supposed to work . The data should be able to adjudicate whether similar or complementary people make better matches . It 's hard to tell who 's right , because the industry keeps its analysis and the data on which the analysis is based a tightly held @ @ @ @ @ @ @ @ @ @ studies ( on taxicab tipping , affirmative action , and concealed handguns ) that anyone can freely download from the Internet , the data behind the matching rules at the Internet dating services are proprietary . // Mark Thompson , who developed Yahoo ! Personals , says it 's impractical to apply social science standards to the market . " The peer-review system is not going to apply here , " Thompson says . " We had two months to develop the system for Yahoo ! We literally worked around the clock . We did studies on 50,000 people . " // The matching sites , meanwhile , are starting to compete on validating their claims . True.com emphasizes that it is the only site which had its methodology certified by an independent auditor . True.com 's chief psychologist James Houran is particularly dismissive of eHarmony 's data claims . " I 've seen no evidence they even conducted any study that forms the basis of their test , " Houran says . " If you 're touting that you 're doing something scientific . . . you inform the academic @ @ @ @ @ @ @ @ @ @ evidence that their matching system works . It sponsored a Harris poll suggesting that eHarmony is now producing about ninety marriages a day ( that 's over 30,000 a year ) . This is better than nothing , but it 's only a modest success because with more than five million members , these marriages represent about only a 1 percent chance that your $50 fee will produce a walk down the aisle . The competitors are quick to dismiss the marriage number . Yahoo ! ' s Thompson has said you have a better chance of finding your future spouse if you " go hang out at the Safeway . " // eHarmony also claims that it has evidence that its married couples are in fact more compatible . Its researchers presented last year to the American Psychological Society their finding that married couples who found each other through eHarmony were significantly happier than couples married for a similar length of time who met by other means . There are some serious weaknesses with this study , but the big news for me is that the major matching sites are @ @ @ @ @ @ @ @ @ @ 're Super Crunching to prove that their algorithms got it right . // The matching algorithms of these services are n't , however , completely data-driven . All the services rely at least partially on the conscious preferences of their clients ( regardless of whether these preferences are valid predictors of compatibility ) . eHarmony allows clients to discriminate on the race of potential mates . Even though it 's only acting on the wishes of its clients , matching services that discriminate by race may violate a statute dating back to the Civil War that prohibits race discrimination in contracting . Think about it . eHarmony is a for-profit company that takes $50 from black clients and refuses to treat them the same ( match them with the same people ) as some white clients . A restaurant would be in a lot of trouble if it refused to seat Hispanic customers in a section where customers had stated a preference to have " Anglos only . " // eHarmony has gotten into even more trouble for its refusal to match same sex couples . The founder 's wife and @ @ @ @ @ @ @ @ @ @ " eHarmony is meant for everybody . We do not discriminate in any way . " This is clearly false . They would refuse to match two men even if , based on their answers to the company 's 436 questions , the computer algorithm picked them to be the most compatible . There 's a sad irony here . eHarmony , unlike its competitors , insists that similar people are the best matches . When it comes to gender , it insists that opposites attract . Out of the top ten matching sites , eHarmony is the only one that does n't offer same-sex matching . // Why is eHarmony so out of step ? Its refusal to match gay and lesbian clients , even in Massachusetts where same-sex marriage is legal , seems counter to the company 's professed goal of helping people find lasting and satisfying marriage partners . Warren is a self-described " passionate Christian " who for years worked closely with James Dobson 's Focus on the Family . eHarmony is only willing to facilitate certain types of legal marriages regardless of what the statistical algorithm @ @ @ @ @ @ @ @ @ @ public , it is possible that eHarmony puts a normative finger on the scale to favor certain clients . //                     